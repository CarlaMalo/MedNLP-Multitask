{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fd9d00",
   "metadata": {},
   "source": [
    "# Task 3: Pre-trained Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a4e26",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4021cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import utils.task3_baseline_utils as base_utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528fb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53400d1",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ebe730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features available:\n",
      "['text', 'inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'id', 'metadata', 'status', 'event_timestamp', 'metrics']\n",
      "\n",
      "Format of 'prediction' column:\n",
      "List({'label': Value('string'), 'score': Value('float64')})\n",
      "\n",
      "Dataset length:  4966\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"argilla/medical-domain\", split=\"train\")\n",
    "\n",
    "print(\"Features available:\")\n",
    "print(dataset.column_names)\n",
    "print(\"\\nFormat of 'prediction' column:\")\n",
    "print(dataset.features['prediction'])\n",
    "print(\"\\nDataset length: \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a2363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e100bcd",
   "metadata": {},
   "source": [
    "View labels and imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8e5183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Unique labels and counts: ------------\n",
      "Allergy / Immunology 7\n",
      "Autopsy 8\n",
      "Bariatrics 18\n",
      "Cardiovascular / Pulmonary 371\n",
      "Chiropractic 14\n",
      "Consult - History and Phy. 516\n",
      "Cosmetic / Plastic Surgery 27\n",
      "Dentistry 27\n",
      "Dermatology 29\n",
      "Diets and Nutritions 10\n",
      "Discharge Summary 108\n",
      "ENT - Otolaryngology 96\n",
      "Emergency Room Reports 75\n",
      "Endocrinology 19\n",
      "Gastroenterology 224\n",
      "General Medicine 259\n",
      "Hematology - Oncology 90\n",
      "Hospice - Palliative Care 6\n",
      "IME-QME-Work Comp etc. 16\n",
      "Lab Medicine - Pathology 8\n",
      "Letters 23\n",
      "Nephrology 81\n",
      "Neurology 223\n",
      "Neurosurgery 94\n",
      "Obstetrics / Gynecology 155\n",
      "Office Notes 50\n",
      "Ophthalmology 83\n",
      "Orthopedic 355\n",
      "Pain Management 61\n",
      "Pediatrics - Neonatal 70\n",
      "Physical Medicine - Rehab 21\n",
      "Podiatry 47\n",
      "Psychiatry / Psychology 53\n",
      "Radiology 273\n",
      "Rheumatology 10\n",
      "SOAP / Chart / Progress Notes 166\n",
      "Sleep Medicine 20\n",
      "Speech - Language 9\n",
      "Surgery 1088\n",
      "Urology 156\n"
     ]
    }
   ],
   "source": [
    "labels = [x[0]['label'] for x in dataset_df.loc[:,\"prediction\"]]\n",
    "labels = [x[1:] for x in labels] # remove whitespace before the label\n",
    "unique_labels = list(sorted(set(labels)))\n",
    "label_counts = {}\n",
    "for l in labels:\n",
    "    if l not in label_counts.keys():\n",
    "        label_counts[l] = 0\n",
    "    label_counts[l] += 1\n",
    "    \n",
    "print(\" Unique labels and counts: \".center(50, '-'))\n",
    "for l in unique_labels:\n",
    "    print(l, label_counts[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2662769",
   "metadata": {},
   "source": [
    "## Text-Length Based Filtering\n",
    "\n",
    "Some samples contain extremely short texts (e.g. a few characters), which are\n",
    "unlikely to be informative for document-level classification.\n",
    "\n",
    "We remove samples with fewer than 40 characters **before** splitting the data,\n",
    "and report how many samples are filtered out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1ac742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size : 4966\n",
      "Removed samples      : 16\n",
      "Removed ratio        : 0.32%\n",
      "Final dataset size   : 4950\n"
     ]
    }
   ],
   "source": [
    "# Minimum character threshold\n",
    "MIN_CHARS = 40\n",
    "\n",
    "initial_len = len(dataset_df)\n",
    "\n",
    "short_text_idx = [\n",
    "    i for i, t in enumerate(dataset_df[\"text\"])\n",
    "    if len(str(t)) < MIN_CHARS\n",
    "]\n",
    "\n",
    "dataset_df = dataset_df.drop(index=short_text_idx).reset_index(drop=True)\n",
    "\n",
    "removed_len = len(short_text_idx)\n",
    "final_len = len(dataset_df)\n",
    "\n",
    "print(f\"Initial dataset size : {initial_len}\")\n",
    "print(f\"Removed samples      : {removed_len}\")\n",
    "print(f\"Removed ratio        : {removed_len / initial_len:.2%}\")\n",
    "print(f\"Final dataset size   : {final_len}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865dfd6",
   "metadata": {},
   "source": [
    "## Stratified Train/Test Split\n",
    "\n",
    "- To ensure a fair evaluation under severe class imbalance, we use a\n",
    "**stratified** train/test split. \n",
    "\n",
    "- This preserves the label distribution\n",
    "across splits and is required for reliable macro-F1 evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9432f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test split: 0.7, 0.3\n",
      "Train set length: 3464\n",
      "Test set length : 1486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts = dataset_df[\"text\"].tolist()\n",
    "labels = [x[0][\"label\"] for x in dataset_df[\"prediction\"]]\n",
    "\n",
    "split = 0.7\n",
    "test_size = 1 - split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=test_size,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train/test split: {split}, {round(1-split,1)}\")\n",
    "print(\"Train set length:\", len(train_texts))\n",
    "print(\"Test set length :\", len(test_texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62361f",
   "metadata": {},
   "source": [
    "# Subtask 1: Baseline\n",
    "\n",
    "Build and tune a strong classical baseline appropriate to the task (e.g., TF IDF + Logistic Regression / Linear SVM or XGBoost for classification/NER). Record metrics as the anchor row of a single results table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483789df",
   "metadata": {},
   "source": [
    "\n",
    "This subtask implements a reproducible TF-IDF + linear baseline with:\n",
    "- stratified train/test split (already done- same data set also used for subtask 2 and 3)\n",
    "- configurable text preprocessing\n",
    "- shared feature space across ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e5519",
   "metadata": {},
   "source": [
    "## 1.1 Text Preprocessing + Tokenization + Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d4564",
   "metadata": {},
   "source": [
    "### Generate Medical Boilerplate Stopwords for Optional Use\n",
    "\n",
    "- Apply solely on the specific trainset to avoid information leakage in test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90d4cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. PROCEDURE  (count=921)\n",
      "1. ANESTHESIA  (count=908)\n",
      "2. PREOPERATIVE DIAGNOSIS  (count=818)\n",
      "3. POSTOPERATIVE DIAGNOSIS  (count=757)\n",
      "4. PHYSICAL EXAMINATION  (count=689)\n",
      "5. IMPRESSION  (count=680)\n",
      "6. HISTORY OF PRESENT ILLNESS  (count=647)\n",
      "7. HEENT  (count=609)\n",
      "8. ALLERGIES  (count=608)\n",
      "9. PAST MEDICAL HISTORY  (count=578)\n",
      "Saved 133 custom stopwords to ./Task3/utils_files/custom_stopwords.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing_enhanced import get_specific_stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Extract candidate capitalized phrases from training data only\n",
    "capital_phrases = get_specific_stopwords(\n",
    "    pd.DataFrame({\"text\": train_texts}),\n",
    "    min_stopword_len=6\n",
    ")\n",
    "\n",
    "# Count phrase frequencies\n",
    "unique_terms, counts = np.unique(capital_phrases, return_counts=True)\n",
    "\n",
    "phrase_stats = np.vstack((unique_terms, counts)).T\n",
    "phrase_stats = phrase_stats[np.argsort(-counts.astype(int), kind=\"stable\")]\n",
    "\n",
    "# Inspect top phrases (optional)\n",
    "for i in range(min(10, len(phrase_stats))):\n",
    "    print(f\"{i}. {phrase_stats[i, 0]}  (count={phrase_stats[i, 1]})\")\n",
    "\n",
    "# Frequency threshold for custom stopwords\n",
    "MIN_STOPWORD_FREQUENCY = 30\n",
    "\n",
    "custom_stopwords = phrase_stats[\n",
    "    phrase_stats[:, 1].astype(int) >= MIN_STOPWORD_FREQUENCY\n",
    "][:, 0]\n",
    "\n",
    "# Save stopwords to CSV\n",
    "import os\n",
    "STOPWORD_PATH = \"./Task3/utils_files\"\n",
    "os.makedirs(STOPWORD_PATH, exist_ok=True)\n",
    "STOPWORD_PATH = os.path.join(STOPWORD_PATH, \"custom_stopwords.csv\")\n",
    "\n",
    "pd.DataFrame(custom_stopwords).to_csv(\n",
    "    STOPWORD_PATH,\n",
    "    sep=\",\",\n",
    "    header=False,\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(custom_stopwords)} custom stopwords to {STOPWORD_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de8b8f",
   "metadata": {},
   "source": [
    "### Selection of Processing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886fac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocessing] Loaded 133 stopwords from ./Task3/utils_files/custom_stopwords.csv\n",
      "Running PROCESS_CONFIG_1: {'enable': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to Task3/results/logistic_regression1.csv\n",
      "\n",
      "Running PROCESS_CONFIG_2: {'enable': True, 'lowercase': True, 'lemmatize': False}\n",
      "Saved results to Task3/results/logistic_regression2.csv\n",
      "\n",
      "Running PROCESS_CONFIG_3: {'enable': True, 'lowercase': True, 'lemmatize': True}\n",
      "Saved results to Task3/results/logistic_regression3.csv\n",
      "\n",
      "Running PROCESS_CONFIG_4: {'enable': True, 'lowercase': True, 'lemmatize': False, 'remove_stopwords': True}\n",
      "Saved results to Task3/results/logistic_regression4.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing_enhanced import preprocess_text, load_stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# configs\n",
    "PROCESS_CONFIG_1 = {\n",
    "    \"enable\": False,\n",
    "}\n",
    "PROCESS_CONFIG_2 = {\n",
    "    \"enable\": True,\n",
    "    \"lowercase\": True,  \n",
    "    \"lemmatize\": False,  \n",
    "}\n",
    "PROCESS_CONFIG_3 = {\n",
    "    \"enable\": True,\n",
    "    \"lowercase\": True,  \n",
    "    \"lemmatize\": True,  \n",
    "}\n",
    "PROCESS_CONFIG_4 = {\n",
    "    \"enable\": True,\n",
    "    \"lowercase\": True,  \n",
    "    \"lemmatize\": False,  \n",
    "    \"remove_stopwords\": True,  #  \n",
    "}\n",
    "\n",
    "PROCESS_CONFIGS = [\n",
    "    PROCESS_CONFIG_1,\n",
    "    PROCESS_CONFIG_2,\n",
    "    PROCESS_CONFIG_3,\n",
    "    PROCESS_CONFIG_4,\n",
    "]\n",
    "\n",
    "CUSTOM_STOPWORDS = load_stopwords(STOPWORD_PATH)\n",
    "\n",
    "X_cache = {}\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words='english',ngram_range=(1,3), max_df=0.75,min_df=5, use_idf=True, smooth_idf=True,sublinear_tf=True, max_features=1000)\n",
    "\n",
    "\n",
    "\n",
    "for idx, config in enumerate(PROCESS_CONFIGS, start=1):\n",
    "\n",
    "    print(f\"Running PROCESS_CONFIG_{idx}: {config}\")\n",
    "\n",
    "    # ---------- Text preprocessing ----------\n",
    "    train_texts_proc = pd.Series(train_texts).apply(\n",
    "        lambda x: preprocess_text(\n",
    "            x,\n",
    "            custom_stopwords=CUSTOM_STOPWORDS,\n",
    "            **config\n",
    "        )\n",
    "    )\n",
    "    test_texts_proc = pd.Series(test_texts).apply(\n",
    "        lambda x: preprocess_text(\n",
    "            x,\n",
    "            custom_stopwords=CUSTOM_STOPWORDS,\n",
    "            **config\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "    X_train_proc = tfidf.fit_transform(train_texts_proc)\n",
    "    X_test_proc  = tfidf.transform(test_texts_proc)\n",
    "\n",
    "    # save cache for later use\n",
    "    X_cache[idx] = {\n",
    "        \"X_train\": X_train_proc,\n",
    "        \"X_test\": X_test_proc,\n",
    "    }\n",
    "\n",
    "    # ---------- Logistic Regression ----------\n",
    "    lr = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    lr.fit(X_train_proc, train_labels)\n",
    "    preds = lr.predict(X_test_proc)\n",
    "\n",
    "    # ---------- Save results ----------\n",
    "    output_path = f\"Task3/results/logistic_regression{idx}.csv\"\n",
    "\n",
    "    base_utils.store_model_metrics_manual(\n",
    "        test_labels,\n",
    "        preds,\n",
    "        output_path\n",
    "    )\n",
    "    print(f\"Saved results to {output_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0e127f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR + raw</th>\n",
       "      <td>0.304909</td>\n",
       "      <td>0.350606</td>\n",
       "      <td>0.366863</td>\n",
       "      <td>0.350606</td>\n",
       "      <td>0.407846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + lowercase</th>\n",
       "      <td>0.306662</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>0.368757</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>0.409055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + lower+lemm</th>\n",
       "      <td>0.304990</td>\n",
       "      <td>0.351952</td>\n",
       "      <td>0.366790</td>\n",
       "      <td>0.351952</td>\n",
       "      <td>0.407849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + lower+stopword</th>\n",
       "      <td>0.307340</td>\n",
       "      <td>0.353297</td>\n",
       "      <td>0.367273</td>\n",
       "      <td>0.353297</td>\n",
       "      <td>0.407856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     f1_weighted  accuracy  precision    recall  f1_macro\n",
       "model                                                                    \n",
       "LR + raw                0.304909  0.350606   0.366863  0.350606  0.407846\n",
       "LR + lowercase          0.306662  0.352624   0.368757  0.352624  0.409055\n",
       "LR + lower+lemm         0.304990  0.351952   0.366790  0.351952  0.407849\n",
       "LR + lower+stopword     0.307340  0.353297   0.367273  0.353297  0.407856"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RESULT_PATHS = {\n",
    "    \"LR + raw\": \"Task3/results/logistic_regression1.csv\",\n",
    "    \"LR + lowercase\": \"Task3/results/logistic_regression2.csv\",\n",
    "    \"LR + lower+lemm\": \"Task3/results/logistic_regression3.csv\",\n",
    "    \"LR + lower+stopword\": \"Task3/results/logistic_regression4.csv\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for model_name, path in RESULT_PATHS.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"model\"] = model_name\n",
    "    rows.append(df)\n",
    "\n",
    "summary_df = pd.concat(rows, ignore_index=True).set_index(\"model\")\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a3c2e",
   "metadata": {},
   "source": [
    "- Lowercasing slightly improves macro-F1, while adding stopword removal increases weighted F1 at the cost of macro-F1.\n",
    "\n",
    "- Since macro-F1 equally weights all classes and better reflects minority-class performance, we can select LR + lowercase as the primary text preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445af6ae",
   "metadata": {},
   "source": [
    "## 1.2 Linear Baseline Models Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the selected Vectors\n",
    "X_train_proc= X_cache[2][\"X_train\"]\n",
    "X_test_proc= X_cache[2][\"X_test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0b582",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa9e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import utils.task3_baseline_utils as base_utils\n",
    "\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lr.fit(X_train_proc, train_labels)\n",
    "preds = lr.predict(X_test_proc)\n",
    "\n",
    "base_utils.store_model_metrics_manual(\n",
    "    test_labels,\n",
    "    preds,\n",
    "    \"Task3/results/logistic_regression.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4efc0",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f315b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(\n",
    "    C=0.01, # TODO comparable to LR result but may not be optimal, \n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "svm.fit(X_train_proc, train_labels)\n",
    "preds = svm.predict(X_test_proc)\n",
    "\n",
    "base_utils.store_model_metrics_manual(\n",
    "    test_labels,\n",
    "    preds,\n",
    "    \"Task3/results/linear_svm.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726f7b7",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c44e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(\n",
    "    loss=\"hinge\",\n",
    "    alpha=1e-2,\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "sgd.fit(X_train_proc, train_labels)\n",
    "preds = sgd.predict(X_test_proc)\n",
    "\n",
    "base_utils.store_model_metrics_manual(\n",
    "    test_labels,\n",
    "    preds,\n",
    "    \"Task3/results/sgd.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6696b",
   "metadata": {},
   "source": [
    "### Multinomial NB Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3347d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(\n",
    "    alpha=0.1  # Laplace smoothing, default is fine\n",
    ")\n",
    "\n",
    "nb.fit(X_train_proc, train_labels)\n",
    "preds = nb.predict(X_test_proc)\n",
    "\n",
    "base_utils.store_model_metrics_manual(\n",
    "    test_labels,\n",
    "    preds,\n",
    "    \"Task3/results/naive_bayes.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5b1f4",
   "metadata": {},
   "source": [
    "## 1.4 Baseline Anchor Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e786e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9fda0_row0_col4, #T_9fda0_row1_col2, #T_9fda0_row3_col0, #T_9fda0_row3_col1, #T_9fda0_row3_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9fda0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9fda0_level0_col0\" class=\"col_heading level0 col0\" >f1_weighted</th>\n",
       "      <th id=\"T_9fda0_level0_col1\" class=\"col_heading level0 col1\" >accuracy</th>\n",
       "      <th id=\"T_9fda0_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_9fda0_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_9fda0_level0_col4\" class=\"col_heading level0 col4\" >f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9fda0_level0_row0\" class=\"row_heading level0 row0\" >LR</th>\n",
       "      <td id=\"T_9fda0_row0_col0\" class=\"data row0 col0\" >0.306662</td>\n",
       "      <td id=\"T_9fda0_row0_col1\" class=\"data row0 col1\" >0.352624</td>\n",
       "      <td id=\"T_9fda0_row0_col2\" class=\"data row0 col2\" >0.368757</td>\n",
       "      <td id=\"T_9fda0_row0_col3\" class=\"data row0 col3\" >0.352624</td>\n",
       "      <td id=\"T_9fda0_row0_col4\" class=\"data row0 col4\" >0.409055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9fda0_level0_row1\" class=\"row_heading level0 row1\" >Linear SVM</th>\n",
       "      <td id=\"T_9fda0_row1_col0\" class=\"data row1 col0\" >0.312957</td>\n",
       "      <td id=\"T_9fda0_row1_col1\" class=\"data row1 col1\" >0.334455</td>\n",
       "      <td id=\"T_9fda0_row1_col2\" class=\"data row1 col2\" >0.382745</td>\n",
       "      <td id=\"T_9fda0_row1_col3\" class=\"data row1 col3\" >0.334455</td>\n",
       "      <td id=\"T_9fda0_row1_col4\" class=\"data row1 col4\" >0.342539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9fda0_level0_row2\" class=\"row_heading level0 row2\" >SGD-SVM</th>\n",
       "      <td id=\"T_9fda0_row2_col0\" class=\"data row2 col0\" >0.248406</td>\n",
       "      <td id=\"T_9fda0_row2_col1\" class=\"data row2 col1\" >0.279273</td>\n",
       "      <td id=\"T_9fda0_row2_col2\" class=\"data row2 col2\" >0.320415</td>\n",
       "      <td id=\"T_9fda0_row2_col3\" class=\"data row2 col3\" >0.279273</td>\n",
       "      <td id=\"T_9fda0_row2_col4\" class=\"data row2 col4\" >0.280720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9fda0_level0_row3\" class=\"row_heading level0 row3\" >Naive_Bayes</th>\n",
       "      <td id=\"T_9fda0_row3_col0\" class=\"data row3 col0\" >0.346255</td>\n",
       "      <td id=\"T_9fda0_row3_col1\" class=\"data row3 col1\" >0.379542</td>\n",
       "      <td id=\"T_9fda0_row3_col2\" class=\"data row3 col2\" >0.363805</td>\n",
       "      <td id=\"T_9fda0_row3_col3\" class=\"data row3 col3\" >0.379542</td>\n",
       "      <td id=\"T_9fda0_row3_col4\" class=\"data row3 col4\" >0.252265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb0718872b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RESULT_PATHS = {\n",
    "    \"LR\": \"Task3/results/logistic_regression.csv\",\n",
    "    \"Linear SVM\": \"Task3/results/linear_svm.csv\",\n",
    "    \"SGD-SVM\": \"Task3/results/sgd.csv\",\n",
    "    \"Naive_Bayes\": \"Task3/results/naive_bayes.csv\",\n",
    "\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for model_name, path in RESULT_PATHS.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"model\"] = model_name\n",
    "    rows.append(df)\n",
    "\n",
    "summary_df = pd.concat(rows, ignore_index=True).set_index(\"model\")\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "summary_df.style.apply(highlight_max, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bfe64",
   "metadata": {},
   "source": [
    "### Brief Summary of SubTask 1:\n",
    "\n",
    "- Logistic Regression achieves the highest macro-F1, showing superior balance across minority classes.\n",
    "\n",
    "- Naive_Bayes offers the best weighted-F1 accuracy and recall, reflecting strong performance on frequent classes\n",
    "\n",
    "TF-IDF + Logistic Regression achieves the highest macro-F1, making it the **most balanced** baseline; we therefore use it as the anchor model for comparison with transformer-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b11ace",
   "metadata": {},
   "source": [
    "# Subtask 2: Encoder track. \n",
    "\n",
    "Evaluate (a) an out-of-the-box encoder with frozen features + linear head (no encoder training), \n",
    "\n",
    "then (b) supervised fine-tuning (SFT) or continual pre-training (CPT) of a base BERT with the same task head. Record both results in one table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723ffe2",
   "metadata": {},
   "source": [
    "- The data split and preprocessing are fixed same as SubTask 1.\n",
    "- Macro-F1 is the primary metric.\n",
    "- Weighted Entropy Loss is used in training to overcome data imbalance.\n",
    "    + $w_i  \\propto 1/\\sqrt{n_i}$ instead of $w_i  \\propto 1/n_i$ is used for SFT training for numerical stability. \n",
    "    + Frozen Encoder favors $w_i  \\propto 1/n_i$ rather than $w_i  \\propto 1/\\sqrt{n_i}$ in terms of macro-F1.\n",
    "- CPT of Encoder is followed by a linear head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eddaf72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import utils.task3_baseline_utils as base_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48084852",
   "metadata": {},
   "source": [
    "### Label Loading (Shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978d621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of labels: 40\n",
      "21  Nephrology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246336/2276401393.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_weights_sqrt = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n"
     ]
    }
   ],
   "source": [
    "# train_labels / test_labels are string labels from the stratified split\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_enc = label_encoder.fit_transform(train_labels)\n",
    "test_labels_enc  = label_encoder.transform(test_labels)\n",
    "\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "# Compute class weights from training labels (for imbalanced data)\n",
    "class_counts = np.bincount(train_labels_enc)\n",
    "class_weights = 1.0 / class_counts   # 1/ni may be more agressive\n",
    "class_weights_sqrt = 1.0 / np.sqrt(class_counts)   # 1/sqrt(ki) may be less agressive\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "class_weights_sqrt = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "\n",
    "print(\"Num of labels:\", num_labels)\n",
    "print(test_labels_enc[0], test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69318be1",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb41654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Dataset + DataLoaders\n",
    "# -------------------------\n",
    "\n",
    "# Sample both head and tail for long texts\n",
    "def encode_head_tail(tokens, max_len):\n",
    "    if len(tokens) <= max_len:\n",
    "        return tokens\n",
    "    half = max_len // 2\n",
    "    return tokens[:half] + tokens[-half:]\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_enc, tokenizer, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels_enc\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "\n",
    "        # 1) Tokenize to tokens (NOT ids yet)\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        # 2) Apply head-tail sampling if needed\n",
    "        tokens = encode_head_tail(tokens, self.max_len - 2)   # -2 to leave space for [CLS] and [SEP]\n",
    "        # 3) Add special tokens\n",
    "        tokens = [self.tokenizer.cls_token] + tokens + [self.tokenizer.sep_token]\n",
    "        # 4) Convert tokens to ids\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        # 5) Build attention mask\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        # 6) Pad to max_len\n",
    "        pad_len = self.max_len - len(input_ids)\n",
    "        if pad_len > 0:\n",
    "            input_ids += [self.tokenizer.pad_token_id] * pad_len\n",
    "            attention_mask += [0] * pad_len\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941ca46",
   "metadata": {},
   "source": [
    "### Model (Encoder + Linear Head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4afaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Encoder + Linear Head\n",
    "# -------------------------\n",
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_labels):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = nn.Linear(encoder.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Forward through encoder, take [CLS] token representation\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_emb = out.last_hidden_state[:, 0]  # [CLS]\n",
    "        logits = self.classifier(cls_emb)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668919a0",
   "metadata": {},
   "source": [
    "### Trainer and Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb65c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict once\n",
    "def get_predictions(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            logits = model(\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                batch[\"attention_mask\"].to(device),\n",
    "            )\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e44a1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Run one episode\n",
    "# -------------------------\n",
    "def run_one_setting(\n",
    "    model,\n",
    "    train_loader,\n",
    "    epochs,\n",
    "    lr,\n",
    "    device=\"cuda\",\n",
    "    weight=class_weights,\n",
    "):\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(\n",
    "                batch[\"input_ids\"].to(device),\n",
    "                batch[\"attention_mask\"].to(device),\n",
    "            )\n",
    "            loss = loss_fn(logits, batch[\"labels\"].to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        print(\n",
    "            f\"[TRAIN] Epoch {ep+1}/{epochs} | loss = {avg_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe57b72",
   "metadata": {},
   "source": [
    "### Training and Evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78914c",
   "metadata": {},
   "source": [
    "Two types of weights are evaluated.\n",
    "\n",
    "* 1- Cross Entropy weighted by $w_i  \\propto 1/n_i$ - More agreesive. \n",
    "* 2- Cross Entropy weighted by $w_i  \\propto 1/\\sqrt{n_i}$ - Less agreesive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b0f229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Encoder: BioClinicalBERT with 1/sqrt(n) weighted loss\n",
      "================================================================================\n",
      "[TRAIN] Epoch 1/5 | loss = 3.2989\n",
      "[TRAIN] Epoch 2/5 | loss = 2.7029\n",
      "[TRAIN] Epoch 3/5 | loss = 2.3793\n",
      "[TRAIN] Epoch 4/5 | loss = 2.1619\n",
      "[TRAIN] Epoch 5/5 | loss = 2.0189\n",
      "\n",
      "[TEST] BioClinicalBERT metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro            model\n",
      "0     0.234745  0.276581   0.346473  0.276581  0.279637  BioClinicalBERT\n",
      "\n",
      "================================================================================\n",
      "Encoder: PubMedBERT with 1/sqrt(n) weighted loss\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/5 | loss = 3.3445\n",
      "[TRAIN] Epoch 2/5 | loss = 2.5025\n",
      "[TRAIN] Epoch 3/5 | loss = 2.0833\n",
      "[TRAIN] Epoch 4/5 | loss = 1.8137\n",
      "[TRAIN] Epoch 5/5 | loss = 1.6876\n",
      "\n",
      "[TEST] PubMedBERT metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro       model\n",
      "0     0.259149  0.303499   0.373509  0.303499  0.319811  PubMedBERT\n"
     ]
    }
   ],
   "source": [
    "## Less Agressive Wegihts\n",
    "\n",
    "from utils.task3_baseline_utils import store_model_metrics_manual\n",
    "# -------------------------\n",
    "# Loop over encoders\n",
    "# -------------------------\n",
    "\n",
    "ENCODERS = {\n",
    "    \"BioClinicalBERT\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    \n",
    "} # Add more if needed:     \"BERT-base\": \"bert-base-uncased\", ...\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MAX_LEN = 512\n",
    "BATCH_TRAIN = 16 # \n",
    "BATCH_EVAL = 16\n",
    "\n",
    "# Use raw text for more semantic representation\n",
    "train_text_list = train_texts\n",
    "test_text_list  = test_texts\n",
    "ALL_RESULTS = []\n",
    "ALL_TRAIN_CURVES = {}\n",
    "\n",
    "for enc_name, enc_id in ENCODERS.items():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Encoder: {enc_name} with 1/sqrt(n) weighted loss\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(enc_id)\n",
    "    encoder = AutoModel.from_pretrained(enc_id)\n",
    "\n",
    "    # Freeze encoder\n",
    "    for p in encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    model = EncoderClassifier(encoder, num_labels)\n",
    "\n",
    "    train_ds = TextDataset(train_text_list, train_labels_enc, tokenizer, MAX_LEN)\n",
    "    test_ds  = TextDataset(test_text_list,  test_labels_enc,  tokenizer, MAX_LEN)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_EVAL,  shuffle=False)\n",
    "\n",
    "    # -------- Train --------\n",
    "    train_losses = run_one_setting(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        epochs=5,\n",
    "        lr=1e-3, # Linear head updates can have larger lr\n",
    "        device=DEVICE,\n",
    "        weight=class_weights_sqrt,\n",
    "    )\n",
    "\n",
    "    ALL_TRAIN_CURVES[enc_name] = train_losses\n",
    "\n",
    "    # -------- Test evaluation (THIS was the missing explicit block) --------\n",
    "    preds = get_predictions(model, test_loader, device=DEVICE)\n",
    "    pred_labels = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    results_path = f\"Task3/results/subtask2_{enc_name}_frozen_sqrt.csv\"\n",
    "\n",
    "    base_utils.store_model_metrics_manual(\n",
    "        y_true=test_labels,\n",
    "        y_pred=pred_labels,\n",
    "        results_path=results_path,\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(results_path)\n",
    "    df[\"model\"] = enc_name\n",
    "    ALL_RESULTS.append(df)\n",
    "\n",
    "    print(f\"\\n[TEST] {enc_name} metrics:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2863608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Encoder: BioClinicalBERT with 1/n weighted loss\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/5 | loss = 3.3487\n",
      "[TRAIN] Epoch 2/5 | loss = 2.6958\n",
      "[TRAIN] Epoch 3/5 | loss = 2.3668\n",
      "[TRAIN] Epoch 4/5 | loss = 2.1743\n",
      "[TRAIN] Epoch 5/5 | loss = 2.0148\n",
      "\n",
      "[TEST] BioClinicalBERT metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro            model\n",
      "0     0.260154  0.298116   0.332039  0.298116  0.275624  BioClinicalBERT\n",
      "\n",
      "================================================================================\n",
      "Encoder: PubMedBERT with 1/n weighted loss\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/5 | loss = 3.3770\n",
      "[TRAIN] Epoch 2/5 | loss = 2.5146\n",
      "[TRAIN] Epoch 3/5 | loss = 2.0808\n",
      "[TRAIN] Epoch 4/5 | loss = 1.7907\n",
      "[TRAIN] Epoch 5/5 | loss = 1.6352\n",
      "\n",
      "[TEST] PubMedBERT metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro       model\n",
      "0     0.295005  0.313594   0.378437  0.313594  0.327976  PubMedBERT\n"
     ]
    }
   ],
   "source": [
    "## More Agressive Wegihts\n",
    "\n",
    "from utils.task3_baseline_utils import store_model_metrics_manual\n",
    "# -------------------------\n",
    "# Loop over encoders\n",
    "# -------------------------\n",
    "\n",
    "ENCODERS = {\n",
    "    \"BioClinicalBERT\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    \n",
    "} # Add more if needed:     \"BERT-base\": \"bert-base-uncased\", ...\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MAX_LEN = 512\n",
    "BATCH_TRAIN = 16 # \n",
    "BATCH_EVAL = 16\n",
    "\n",
    "# Use raw text for more semantic representation\n",
    "train_text_list = train_texts\n",
    "test_text_list  = test_texts\n",
    "ALL_RESULTS = []\n",
    "ALL_TRAIN_CURVES = {}\n",
    "\n",
    "for enc_name, enc_id in ENCODERS.items():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Encoder: {enc_name} with 1/n weighted loss\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(enc_id)\n",
    "    encoder = AutoModel.from_pretrained(enc_id)\n",
    "\n",
    "    # Freeze encoder\n",
    "    for p in encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    model = EncoderClassifier(encoder, num_labels)\n",
    "\n",
    "    # Tokenize by each Encoder\n",
    "    train_ds = TextDataset(train_text_list, train_labels_enc, tokenizer, MAX_LEN)\n",
    "    test_ds  = TextDataset(test_text_list,  test_labels_enc,  tokenizer, MAX_LEN)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_EVAL,  shuffle=False)\n",
    "\n",
    "    # -------- Train --------\n",
    "    train_losses = run_one_setting(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        epochs=5,\n",
    "        lr=1e-3, # Linear head updates can have larger lr\n",
    "        device=DEVICE,\n",
    "        weight=class_weights,\n",
    "    )\n",
    "\n",
    "    ALL_TRAIN_CURVES[enc_name] = train_losses\n",
    "\n",
    "    # -------- Test evaluation (THIS was the missing explicit block) --------\n",
    "    preds = get_predictions(model, test_loader, device=DEVICE)\n",
    "    pred_labels = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    results_path = f\"Task3/results/subtask2_{enc_name}_frozen.csv\"\n",
    "\n",
    "    base_utils.store_model_metrics_manual(\n",
    "        y_true=test_labels,\n",
    "        y_pred=pred_labels,\n",
    "        results_path=results_path,\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(results_path)\n",
    "    df[\"model\"] = enc_name\n",
    "    ALL_RESULTS.append(df)\n",
    "\n",
    "    print(f\"\\n[TEST] {enc_name} metrics:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014c1bd",
   "metadata": {},
   "source": [
    "## (b) Encoder SFT\n",
    "\n",
    "The interface above can be reused for LoRA-based fine-tuning by:\n",
    "- injecting LoRA into `encoder`\n",
    "- setting `freeze_encoder=False`\n",
    "- reducing epochs (e.g. 3)\n",
    "\n",
    "This ensures encoder selection precedes fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16929e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Full SFT Encoder: BioClinicalBERT\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/3 | loss = 3.4264\n",
      "[TRAIN] Epoch 2/3 | loss = 2.6019\n",
      "[TRAIN] Epoch 3/3 | loss = 1.8833\n",
      "\n",
      "[TEST] BioClinicalBERT Full SFT metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro                model\n",
      "0     0.280933  0.345895   0.404606  0.345895  0.342471  BioClinicalBERT_SFT\n",
      "\n",
      "================================================================================\n",
      "Full SFT Encoder: PubMedBERT\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Epoch 1/3 | loss = 3.4678\n",
      "[TRAIN] Epoch 2/3 | loss = 2.5266\n",
      "[TRAIN] Epoch 3/3 | loss = 1.7318\n",
      "\n",
      "[TEST] PubMedBERT Full SFT metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro           model\n",
      "0     0.297582  0.370121   0.408609  0.370121  0.407413  PubMedBERT_SFT\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Full SFT: Encoder + Linear Head\n",
    "# =========================\n",
    "\n",
    "\n",
    "# Run Full SFT for each encoder\n",
    "ENCODERS = {\n",
    "    \"BioClinicalBERT\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    \n",
    "} # Add more if needed:     \"BERT-base\": \"bert-base-uncased\", ...\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MAX_LEN = 512\n",
    "BATCH_TRAIN = 16 # \n",
    "BATCH_EVAL = 16\n",
    "\n",
    "# Use raw text for more semantic representation\n",
    "train_text_list = train_texts\n",
    "test_text_list  = test_texts\n",
    "ALL_RESULTS = []\n",
    "ALL_TRAIN_CURVES = {}\n",
    "\n",
    "for enc_name, enc_id in ENCODERS.items():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Full SFT Encoder: {enc_name}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(enc_id)\n",
    "    encoder = AutoModel.from_pretrained(enc_id)\n",
    "\n",
    "    # IMPORTANT: Full fine-tuning (do NOT freeze encoder)\n",
    "    for p in encoder.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    model = EncoderClassifier(encoder, num_labels)\n",
    "\n",
    "    # Tokenize by each Encoder\n",
    "    train_ds = TextDataset(train_text_list, train_labels_enc, tokenizer, MAX_LEN)\n",
    "    test_ds  = TextDataset(test_text_list,  test_labels_enc,  tokenizer, MAX_LEN)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_EVAL,  shuffle=False)\n",
    "\n",
    "    # -------- Train (Full SFT) --------\n",
    "    train_losses = run_one_setting(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        epochs=3,\n",
    "        lr=1e-5,      # standard SFT LR\n",
    "        device=DEVICE,\n",
    "        weight=class_weights_sqrt,\n",
    "    )\n",
    "\n",
    "    ALL_TRAIN_CURVES[f\"{enc_name}_SFT\"] = train_losses\n",
    "\n",
    "    # -------- Final test evaluation --------\n",
    "    preds = get_predictions(model, test_loader, device=DEVICE)\n",
    "    pred_labels = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    results_path = f\"Task3/results/subtask2_{enc_name}_SFT.csv\"\n",
    "\n",
    "    base_utils.store_model_metrics_manual(\n",
    "        y_true=test_labels,\n",
    "        y_pred=pred_labels,\n",
    "        results_path=results_path,\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(results_path)\n",
    "    df[\"model\"] = f\"{enc_name}_SFT\"\n",
    "    ALL_RESULTS.append(df)\n",
    "\n",
    "    print(f\"\\n[TEST] {enc_name} Full SFT metrics:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec482d8",
   "metadata": {},
   "source": [
    "## Continual PreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ede46",
   "metadata": {},
   "source": [
    "###  PubMedBERT outperforms BioClinicalBERT in previous task, so it is chosen to be the CPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73420d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MLMDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca2ecaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "ENCODER_NAME = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "DEVICE = \"cuda\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 8        # CPT requires high MEM\n",
    "EPOCHS = 2            # Not too much\n",
    "LR = 5e-5             # CPT LR smaller, safer\n",
    "MLM_PROB = 0.15      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f09f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/task3-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Load tokenizer & model (MLM head!)\n",
    "# -------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(ENCODER_NAME)\n",
    "model = AutoModelForMaskedLM.from_pretrained(ENCODER_NAME)\n",
    "model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba32da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Dataset & DataLoader\n",
    "# -------------------------\n",
    "\n",
    "# MLM is self-supervised, and won't see the labels, so add also the test dataset\n",
    "mlm_texts = train_text_list + test_text_list\n",
    "mlm_dataset = MLMDataset(\n",
    "    texts=mlm_texts,   # \n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=MLM_PROB\n",
    ")\n",
    "\n",
    "mlm_loader = DataLoader(\n",
    "    mlm_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d655a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Optimizer\n",
    "# -------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afc95e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPT Epoch 1: 100%|| 619/619 [01:18<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPT] Epoch 1/2 | MLM loss = 1.4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPT Epoch 2: 100%|| 619/619 [01:17<00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPT] Epoch 2/2 | MLM loss = 1.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CPT training loop\n",
    "# -------------------------\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(mlm_loader, desc=f\"CPT Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(mlm_loader)\n",
    "    print(f\"[CPT] Epoch {epoch+1}/{EPOCHS} | MLM loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4acf61e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Task3/models/pubmedbert_cpt/tokenizer_config.json',\n",
       " 'Task3/models/pubmedbert_cpt/special_tokens_map.json',\n",
       " 'Task3/models/pubmedbert_cpt/vocab.txt',\n",
       " 'Task3/models/pubmedbert_cpt/added_tokens.json',\n",
       " 'Task3/models/pubmedbert_cpt/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "CPT_OUTPUT_DIR = \"Task3/models/\"\n",
    "os.makedirs(CPT_OUTPUT_DIR, exist_ok=True)\n",
    "CPT_OUTPUT_DIR = os.path.join(CPT_OUTPUT_DIR, \"pubmedbert_cpt\")\n",
    "\n",
    "model.save_pretrained(CPT_OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(CPT_OUTPUT_DIR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72eb872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Task3/models/pubmedbert_cpt and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPT Frozen] Epoch 1/5 | train loss = 3.2245\n",
      "[CPT Frozen] Epoch 2/5 | train loss = 2.2280\n",
      "[CPT Frozen] Epoch 3/5 | train loss = 1.8224\n",
      "[CPT Frozen] Epoch 4/5 | train loss = 1.5918\n",
      "[CPT Frozen] Epoch 5/5 | train loss = 1.4544\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CPT Evaluation Pipeline\n",
    "# =========================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# -------------------------\n",
    "# Paths\n",
    "# -------------------------\n",
    "\n",
    "CPT_MODEL_DIR = CPT_OUTPUT_DIR\n",
    "\n",
    "RESULTS_PATH  = \"Task3/results\"\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "RESULTS_PATH = os.path.join(RESULTS_PATH, \"pubmedbert_cpt.csv\")\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "# -------------------------\n",
    "# Load CPT encoder\n",
    "# -------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(CPT_MODEL_DIR)\n",
    "encoder = AutoModel.from_pretrained(CPT_MODEL_DIR)\n",
    "\n",
    "# Freeze encoder\n",
    "for p in encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# -------------------------\n",
    "# Encoder + Linear Head\n",
    "# -------------------------\n",
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_labels):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = nn.Linear(\n",
    "            encoder.config.hidden_size,\n",
    "            num_labels\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        cls_emb = outputs.last_hidden_state[:, 0]\n",
    "        logits = self.classifier(cls_emb)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = EncoderClassifier(encoder, num_labels)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# -------------------------\n",
    "# DataLoaders (reuse Dataset)\n",
    "# -------------------------\n",
    " \n",
    "train_ds = TextDataset(train_text_list, train_labels_enc, tokenizer, MAX_LEN)\n",
    "test_ds  = TextDataset(test_text_list,  test_labels_enc,  tokenizer, MAX_LEN)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_EVAL,  shuffle=False)\n",
    "\n",
    "# -------------------------\n",
    "# Loss & Optimizer\n",
    "# -------------------------\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_sqrt)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3  # head-only LR\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Train Linear Head\n",
    "# -------------------------\n",
    "EPOCHS = 5\n",
    "model.train()\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(\n",
    "            batch[\"input_ids\"].to(DEVICE),\n",
    "            batch[\"attention_mask\"].to(DEVICE),\n",
    "        )\n",
    "        loss = loss_fn(\n",
    "            logits,\n",
    "            batch[\"labels\"].to(DEVICE)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(\n",
    "        f\"[CPT Frozen] Epoch {ep+1}/{EPOCHS} | \"\n",
    "        f\"train loss = {total_loss / len(train_loader):.4f}\"\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Final Evaluation on Test\n",
    "# -------------------------\n",
    "model.eval()\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        logits = model(\n",
    "            batch[\"input_ids\"].to(DEVICE),\n",
    "            batch[\"attention_mask\"].to(DEVICE),\n",
    "        )\n",
    "        preds.extend(\n",
    "            torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        )\n",
    "\n",
    "pred_labels = label_encoder.inverse_transform(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cc02f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CPT Frozen Encoder] Test metrics:\n",
      "   f1_weighted  accuracy  precision    recall  f1_macro                  model\n",
      "0     0.318718  0.372813   0.398117  0.372813  0.362386  PubMedBERT_CPT_Frozen\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "base_utils.store_model_metrics_manual(\n",
    "    y_true=test_labels,\n",
    "    y_pred=pred_labels,\n",
    "    results_path=RESULTS_PATH\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Print results\n",
    "# -------------------------\n",
    "df = pd.read_csv(RESULTS_PATH)\n",
    "df[\"model\"] = \"PubMedBERT_CPT_Frozen\"\n",
    "\n",
    "print(\"\\n[CPT Frozen Encoder] Test metrics:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed914d5",
   "metadata": {},
   "source": [
    "## Summary of SubTask-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8229956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8a1ef_row0_col4, #T_8a1ef_row1_col2, #T_8a1ef_row2_col0, #T_8a1ef_row2_col1, #T_8a1ef_row2_col3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8a1ef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8a1ef_level0_col0\" class=\"col_heading level0 col0\" >f1_weighted</th>\n",
       "      <th id=\"T_8a1ef_level0_col1\" class=\"col_heading level0 col1\" >accuracy</th>\n",
       "      <th id=\"T_8a1ef_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_8a1ef_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_8a1ef_level0_col4\" class=\"col_heading level0 col4\" >f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8a1ef_level0_row0\" class=\"row_heading level0 row0\" >BaseLR (TF-IDF)</th>\n",
       "      <td id=\"T_8a1ef_row0_col0\" class=\"data row0 col0\" >0.304909</td>\n",
       "      <td id=\"T_8a1ef_row0_col1\" class=\"data row0 col1\" >0.350606</td>\n",
       "      <td id=\"T_8a1ef_row0_col2\" class=\"data row0 col2\" >0.366863</td>\n",
       "      <td id=\"T_8a1ef_row0_col3\" class=\"data row0 col3\" >0.350606</td>\n",
       "      <td id=\"T_8a1ef_row0_col4\" class=\"data row0 col4\" >0.407846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a1ef_level0_row1\" class=\"row_heading level0 row1\" >PubMedBERT (SFT)</th>\n",
       "      <td id=\"T_8a1ef_row1_col0\" class=\"data row1 col0\" >0.297582</td>\n",
       "      <td id=\"T_8a1ef_row1_col1\" class=\"data row1 col1\" >0.370121</td>\n",
       "      <td id=\"T_8a1ef_row1_col2\" class=\"data row1 col2\" >0.408609</td>\n",
       "      <td id=\"T_8a1ef_row1_col3\" class=\"data row1 col3\" >0.370121</td>\n",
       "      <td id=\"T_8a1ef_row1_col4\" class=\"data row1 col4\" >0.407413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a1ef_level0_row2\" class=\"row_heading level0 row2\" >PubMedBERT (CPT  Frozen)</th>\n",
       "      <td id=\"T_8a1ef_row2_col0\" class=\"data row2 col0\" >0.318718</td>\n",
       "      <td id=\"T_8a1ef_row2_col1\" class=\"data row2 col1\" >0.372813</td>\n",
       "      <td id=\"T_8a1ef_row2_col2\" class=\"data row2 col2\" >0.398117</td>\n",
       "      <td id=\"T_8a1ef_row2_col3\" class=\"data row2 col3\" >0.372813</td>\n",
       "      <td id=\"T_8a1ef_row2_col4\" class=\"data row2 col4\" >0.362386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a1ef_level0_row3\" class=\"row_heading level0 row3\" >PubMedBERT (Frozen)</th>\n",
       "      <td id=\"T_8a1ef_row3_col0\" class=\"data row3 col0\" >0.295005</td>\n",
       "      <td id=\"T_8a1ef_row3_col1\" class=\"data row3 col1\" >0.313594</td>\n",
       "      <td id=\"T_8a1ef_row3_col2\" class=\"data row3 col2\" >0.378437</td>\n",
       "      <td id=\"T_8a1ef_row3_col3\" class=\"data row3 col3\" >0.313594</td>\n",
       "      <td id=\"T_8a1ef_row3_col4\" class=\"data row3 col4\" >0.327976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f21edb01840>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RESULT_PATHS = {\n",
    "    # -------------------------\n",
    "    # Classical baselines\n",
    "    # -------------------------\n",
    "    \"BaseLR (TF-IDF)\": \"Task3/results/logistic_regression.csv\",\n",
    "    # -------------------------\n",
    "    # Encoder baselines (Subtask 2)\n",
    "    # -------------------------\n",
    "    # \"BioClinicalBERT (Frozen)\": \"Task3/results/subtask2_BioClinicalBERT_frozen.csv\",\n",
    "    # \"BioClinicalBERT (SFT)\": \"Task3/results/subtask2_BioClinicalBERT_SFT.csv\",\n",
    "    \"PubMedBERT (Frozen)\": \"Task3/results/subtask2_PubMedBERT_frozen.csv\",\n",
    "    \"PubMedBERT (SFT)\": \"Task3/results/subtask2_PubMedBERT_SFT.csv\",\n",
    "\n",
    "    # -------------------------\n",
    "    # CPT\n",
    "    # -------------------------\n",
    "    \"PubMedBERT (CPT  Frozen)\": \"Task3/results/pubmedbert_cpt.csv\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "\n",
    "for model_name, path in RESULT_PATHS.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"model\"] = model_name\n",
    "    rows.append(df)\n",
    "\n",
    "summary_subtask2 = (\n",
    "    pd.concat(rows, ignore_index=True)\n",
    "      .set_index(\"model\")\n",
    "      .sort_values(\"f1_macro\", ascending=False)\n",
    ")\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "summary_subtask2.style.apply(highlight_max, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a8cbf",
   "metadata": {},
   "source": [
    "### Brief Conclusion of SubTask 2:\n",
    "\n",
    "- TF-IDF + Logistic Regression achieves the highest macro-F1, indicating that the task is dominated by sparse lexical cues rather than dense semantic representations.\n",
    "\n",
    "- Supervised fine-tuning improves frozen encoder's performance, but still fails to outperform classical baselines on minority classes.\n",
    "\n",
    "- Continual pre-training stabilizes representations but does not alter the decision structure, suggesting that label overlap is the primary bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecee196",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task3-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
