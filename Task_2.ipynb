{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2340435",
   "metadata": {},
   "source": [
    "# Task 2: Data Exploration and Processing\n",
    "\n",
    "## Step 1: Manual data inspection and NER classifier by spaCy\n",
    "- Investigate which standard and potential new NER types are most prominent in your data set (i.e., manual data inspection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45545326",
   "metadata": {},
   "source": [
    "The NER that we think that are prominent in our data set is DATE, BODY_PART, DOSAGE, MEASUREMENT, DRUG and SYMPTOM. \n",
    "\n",
    "DATE is a **standard NER in spacCy** and other NERs are medicine domain specific. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf5702",
   "metadata": {},
   "source": [
    "## Step 2: Apply the standard NER classifier of spaCyto your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4cb76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4127fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f457d37",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392028f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4966\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1: Load Dataset\n",
    "# ============================\n",
    "dataset = load_dataset(\"argilla/medical-domain\", split=\"train\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad783949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our NER schema =  ['DISEASE', 'BODY_PART', 'PROCEDURE', 'FINDING', 'SYMPTOM']\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 2: Define Entity Schema\n",
    "# ================================================\n",
    "# Our final gold-label schema\n",
    "CUSTOM_LABELS = [\n",
    "\n",
    "    \"DISEASE\", \"BODY_PART\", \"PROCEDURE\", \"FINDING\", \"SYMPTOM\"\n",
    "]\n",
    "\n",
    "print(\"Our NER schema = \", CUSTOM_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded: core_web_md\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 3: Load spaCy baseline NER model\n",
    "# ============================\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"spaCy model loaded:\", nlp.meta[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f45d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample_for_annotation.csv with 2 sentences\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 4: Pick N samples manually\n",
    "# =========================================\n",
    "\n",
    "SEED = 42 \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "N_SAMPLES = 2   # select a proper number to contain 100 ground-truth NERs \n",
    "sampled_texts = []\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    row = dataset[np.random.randint(0, len(dataset))]\n",
    "    text = row[\"text\"] if \"text\" in row else row[\"content\"]\n",
    "    sent = row[\"text\"] if i==0 else None\n",
    "    sampled_texts.append(text)\n",
    "\n",
    "df_samples = pd.DataFrame({\"text\": sampled_texts})\n",
    "df_samples.to_csv(\"sample_for_annotation.csv\", index=False)\n",
    "\n",
    "print(\"Saved sample_for_annotation.csv with\", len(df_samples), \"sentences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c1289",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35f24",
   "metadata": {},
   "source": [
    "\n",
    "### Generate Templates for Manual Annotation. \n",
    "\n",
    "The annotation format should be: \n",
    "\n",
    "{\"sample_id\": 0, \n",
    "\n",
    "\"sentence_id\": 0, \n",
    "\n",
    "\"text\": \"REASON FOR THE CONSULT:,  Nonhealing right ankle stasis ulcer.,HISTORY\", \n",
    "\n",
    "\"annotation\": \"[[\"Nonhealing\",\"FINDING\"],[\"right ankle\",\"BODY_PART\"],[\"stasis ulcer\",\"DISEASE\"]]\"\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c697b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 sentences: 83\n",
      "Sample 1 sentences: 89\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Generate train/test annotation template JSONL with ratio control\n",
    "# ============================================\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "INPUT_CSV = \"sample_for_annotation.csv\"\n",
    "TRAIN_OUTPUT = \"train_annotation_template.jsonl\"\n",
    "TEST_OUTPUT  = \"test_annotation_template.jsonl\"\n",
    "\n",
    "# ================================\n",
    "# Parameters: control split ratio\n",
    "# ================================\n",
    "TRAIN_RATIO = 0.60     # first 60% for training（sample 0）\n",
    "TEST_RATIO  = 0.30     # first 30% for evaluation/test（sample 1）\n",
    "\n",
    "# ================================\n",
    "\n",
    "# 1. Load samples: only column \"text\"\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df[\"sample_id\"] = df.index  # auto-index\n",
    "\n",
    "# 2. Load spaCy for sentence splitting\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Buckets\n",
    "train_items = []\n",
    "test_items = []\n",
    "\n",
    "# ===========================\n",
    "# Split sentences per sample\n",
    "# ===========================\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    sample_id = int(row[\"sample_id\"])\n",
    "    full_text = str(row[\"text\"])\n",
    "    doc = nlp(full_text)\n",
    "\n",
    "    # Extract sentences\n",
    "    sents = [s.text.strip() for s in doc.sents if len(s.text.strip()) > 0]\n",
    "    total = len(sents)\n",
    "\n",
    "    if sample_id == 0:\n",
    "        # sample 0 → train sample\n",
    "        cutoff = int(total * TRAIN_RATIO)\n",
    "        selected = sents[:cutoff]\n",
    "\n",
    "        for i, text in enumerate(selected):\n",
    "            train_items.append({\n",
    "                \"sample_id\": sample_id,\n",
    "                \"sentence_id\": i,\n",
    "                \"text\": text,\n",
    "                \"annotation\": []\n",
    "            })\n",
    "\n",
    "    elif sample_id == 1:\n",
    "        # sample 1 → test sample\n",
    "        cutoff = int(total * TEST_RATIO)\n",
    "        selected = sents[:cutoff]\n",
    "\n",
    "        for i, text in enumerate(selected):\n",
    "            test_items.append({\n",
    "                \"sample_id\": sample_id,\n",
    "                \"sentence_id\": i,\n",
    "                \"text\": text,\n",
    "                \"annotation\": []\n",
    "            })\n",
    "\n",
    "print(\"Sample 0 sentences:\", len([s for s in nlp(df.loc[0, \"text\"]).sents]))\n",
    "print(\"Sample 1 sentences:\", len([s for s in nlp(df.loc[1, \"text\"]).sents]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d519d",
   "metadata": {},
   "source": [
    "### (1) Manual Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf3736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Text Preview ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ADMISSION\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " DIAGNOSES:,1.  Atypical chest pain.,2.  Nausea.,3.  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vomiting\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".,4.  Diabetes.,5.  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hypokalemia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".,6.  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diarrhea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".,7.  Panic and depression.,8.  Hypertension.,DISCHARGE DIAGNOSES:,1.  Serotonin syndrome secondary to high doses of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Prozac\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".,2.  Atypical chest pain with myocardial infarction ruled out.,3.  Diabetes mellitus.,4.  Hypertension.,5.  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Diarrhea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " resolved.,ADMISSION SUMMARY: , The patient is a \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    53-year-old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " woman with history of hypertension, diabetes, and depression.  Unfortunately her husband left her \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10 days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " prior to admission and she developed severe anxiety and depression.  She was having chest pains along with significant vomiting and diarrhea.  Of note, she had a nuclear stress test performed in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    February of this year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", which was normal.  She was readmitted to the hospital to rule out myocardial infarction and for further evaluation.,ADMISSION PHYSICAL: , Significant for her being afebrile.  Apparently there was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " temperature registered mildly high at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    100\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ".  Her blood pressure was \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    140/82\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", heart rate \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    83\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", oxygen saturation was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    100%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       ".  She was tearful.  HEART:  Heart sounds were regular.  LUNGS:  Clear.  ABDOMEN:  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Soft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".  Apparently there were some level of restlessness and acathexia.  She was also pacing.,ADMISSION LABS:  ,Showed \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CBC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " with a white count of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    16.9\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", hematocrit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    46.9\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", platelets \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    318,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ".  She had \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    80%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " neutrophils, no bands.  \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    05/02\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " came out negative.  Chemistry panel shows sodium \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    138\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", potassium \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3.5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", creatinine \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.6\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", calcium \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    8.3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", lactate \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.9\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", ALT was \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    39\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", AST 38, total bilirubin \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.6\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ".  Her initial CK came out at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    922\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ".  CK-MB was low.  \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Troponin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.04\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ".  She had a normal amylase and lipase.  Previous TSH few days prior was normal.  Chest x-ray was negative.,HOSPITAL COURSE:,1.  Serotonin syndrome.  After reevaluation of the patient including evaluation of the lab abnormalities it was felt that she likely had serotonin syndrome with obvious restlessness, increased bowel activity, agitation, and elevated white count and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CPK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".  She did not have fever, </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Manual Evaluation of Standard NER\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "# 1. Load sample text file\n",
    "df_samples = pd.read_csv(\"sample_for_annotation.csv\")\n",
    "\n",
    "# 2. Extract second row text\n",
    "# sample_for_annotation.csv has:\n",
    "# row 0: header \"text\"\n",
    "# row 1: sample 1 -> this is the train sample for further NER extention \n",
    "# row 2: sample 2  -> this is the test sample\n",
    "test_text = df_samples.iloc[1][\"text\"]\n",
    "\n",
    "print(\"=== Test Text Preview ===\")\n",
    "\n",
    "# 3. Load spaCy model (baseline or your updated one)\n",
    "nlp = spacy.load(\"en_core_web_md\")   # or: spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# 4. Run NER on the full document\n",
    "doc = nlp(test_text[:2000])\n",
    "\n",
    "# 5. Render using displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24f233",
   "metadata": {},
   "source": [
    "- Observation: Some NERs don't make sense. E.g., Vomitting -> PERSON, Hypokalemia -> PERSON, Diarrhea -> PERSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c109e22",
   "metadata": {},
   "source": [
    "### Automatic Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f0360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 annotated sentences\n",
      "\n",
      "===== Baseline spaCy NER Evaluation =====\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 score:  0.0000\n",
      "\n",
      "Macro Precision: 0.0\n",
      "Macro Recall:    0.0\n",
      "Macro F1:        0.0\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: ADMISSION DIAGNOSES:,1.\n",
      "Gold: set()\n",
      "Pred: {(0, 9, 'ORG')}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Step 6: Standard NER evaluation\n",
    "# =========================================\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# ===================================================\n",
    "# 1. Load JSONL annotations\n",
    "# ===================================================\n",
    "jsonl_path = \"test_annotation_complete.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        data.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load baseline spaCy NER\n",
    "# ===================================================\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# ===================================================\n",
    "# 3. Convert annotations to character-level spans\n",
    "# ===================================================\n",
    "\n",
    "def find_span(text, phrase):\n",
    "    \"\"\"\n",
    "    Locate (start, end) in the sentence.\n",
    "    If multiple choices, take the first one.\n",
    "    Retrun None if not found。\n",
    "    \"\"\"\n",
    "    start = text.lower().find(phrase.lower())\n",
    "    if start == -1:\n",
    "        return None\n",
    "    return (start, start + len(phrase))\n",
    "\n",
    "gold_spans = []\n",
    "pred_spans = []\n",
    "labels = []   # For all ground-truth annotion in the test\n",
    "\n",
    "for item in data:\n",
    "    text = item[\"text\"]\n",
    "    ann_list = item[\"annotation\"]  # [[\"ankle\",\"BODY_PART\"], ...]\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    # -------- gold spans --------\n",
    "    gold = []\n",
    "    for phrase, label in ann_list:\n",
    "        span = find_span(text, phrase)\n",
    "        if span is not None:\n",
    "            gold.append((span[0], span[1], label))\n",
    "            labels.append(label)\n",
    "        # else:\n",
    "        #     print(\"Warning: phrase not found:\", phrase)\n",
    "\n",
    "    gold_spans.append(gold)\n",
    "\n",
    "    # -------- predicted spans --------\n",
    "    pred = []\n",
    "    for ent in doc.ents:\n",
    "        pred.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    pred_spans.append(pred)\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "# ===================================================\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for g_spans, p_spans in zip(gold_spans, pred_spans):\n",
    "\n",
    "    #  (start,end,label) precise matching\n",
    "    g_set = set(g_spans)\n",
    "    p_set = set(p_spans)\n",
    "\n",
    "    # True positives\n",
    "    for span in g_set:\n",
    "        if span in p_set:\n",
    "            true_labels.append(span[2])\n",
    "            pred_labels.append(span[2])\n",
    "        else:\n",
    "            true_labels.append(span[2])\n",
    "            pred_labels.append(\"NONE\")  # missed\n",
    "\n",
    "    # False positives\n",
    "    for span in p_set:\n",
    "        if span not in g_set:\n",
    "            true_labels.append(\"NONE\")     # if no gold annotation\n",
    "            pred_labels.append(span[2])    # wrong\n",
    "\n",
    "# ===================================================\n",
    "# 5. Evaluate macro and micro F1\n",
    "# ===================================================\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    true_labels, pred_labels, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Baseline spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "    true_labels, pred_labels, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 6. Show some error cases\n",
    "# ===================================================\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "\n",
    "for i, (g, p, item) in enumerate(zip(gold_spans, pred_spans, data)):\n",
    "    g_set = set(g)\n",
    "    p_set = set(p)\n",
    "    if g_set != p_set:\n",
    "        print(\"Text:\", item[\"text\"])\n",
    "        print(\"Gold:\", g_set)\n",
    "        print(\"Pred:\", p_set)\n",
    "        print(\"-\" * 50)\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26c084",
   "metadata": {},
   "source": [
    "## Step 4: Extend the standard NER types using the NER Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b2181",
   "metadata": {},
   "source": [
    "### (1) Training Extended NER model with >100 manual annoatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e19587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Overlapping entity problems found =====\n"
     ]
    }
   ],
   "source": [
    "# Make sure there is no overlapping entity problems in the training sample\n",
    "# \n",
    "# import json\n",
    "\n",
    "path = \"train_annotation_complete.jsonl\"\n",
    "\n",
    "def spans_overlap(a, b):\n",
    "    return not (a[1] <= b[0] or b[1] <= a[0])\n",
    "\n",
    "bad = []\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        text = obj[\"text\"]\n",
    "        anns = obj[\"annotation\"]  # [[phrase,label],...]\n",
    "\n",
    "        spans = []\n",
    "        for phrase, label in anns:\n",
    "            start = text.lower().find(phrase.lower())\n",
    "            if start == -1:\n",
    "                continue\n",
    "            end = start + len(phrase)\n",
    "            spans.append((start, end, phrase, label))\n",
    "\n",
    "        # check overlapping\n",
    "        for i in range(len(spans)):\n",
    "            for j in range(i+1, len(spans)):\n",
    "                a = spans[i]\n",
    "                b = spans[j]\n",
    "                if spans_overlap(a, b):\n",
    "                    bad.append((obj[\"sentence_id\"], text, a, b))\n",
    "\n",
    "print(\"===== Overlapping entity problems found =====\")\n",
    "for sid, text, a, b in bad:\n",
    "    print(f\"\\nSentence {sid}: {text}\")\n",
    "    print(\"  ->\", a)\n",
    "    print(\"  ->\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d44df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 83 annotated sentences\n",
      "Custom NER labels: ['DISEASE', 'BODY_PART', 'FINDING', 'PROCEDURE', 'SYMPTOM']\n",
      "Example: ('REASON FOR THE CONSULT:,  Nonhealing right ankle stasis ulcer.,HISTORY', {'entities': [(26, 36, 'FINDING'), (37, 48, 'BODY_PART'), (49, 61, 'DISEASE')]})\n",
      "Epoch 1/35 Loss: {'ner': 776.6243955492973}\n",
      "Epoch 2/35 Loss: {'ner': 269.1503838092831}\n",
      "Epoch 3/35 Loss: {'ner': 131.03240305900363}\n",
      "Epoch 4/35 Loss: {'ner': 118.2530930648993}\n",
      "Epoch 5/35 Loss: {'ner': 100.19835169207909}\n",
      "Epoch 6/35 Loss: {'ner': 97.1271987649484}\n",
      "Epoch 7/35 Loss: {'ner': 82.98269231236071}\n",
      "Epoch 8/35 Loss: {'ner': 72.80680198597149}\n",
      "Epoch 9/35 Loss: {'ner': 69.08256673266408}\n",
      "Epoch 10/35 Loss: {'ner': 76.26185814248626}\n",
      "Epoch 11/35 Loss: {'ner': 84.33463708266237}\n",
      "Epoch 12/35 Loss: {'ner': 57.12673094169406}\n",
      "Epoch 13/35 Loss: {'ner': 90.96536032401447}\n",
      "Epoch 14/35 Loss: {'ner': 81.35185837419314}\n",
      "Epoch 15/35 Loss: {'ner': 70.72291469472322}\n",
      "Epoch 16/35 Loss: {'ner': 65.06937428147856}\n",
      "Epoch 17/35 Loss: {'ner': 62.1372214201923}\n",
      "Epoch 18/35 Loss: {'ner': 53.03455202833165}\n",
      "Epoch 19/35 Loss: {'ner': 54.08536817521397}\n",
      "Epoch 20/35 Loss: {'ner': 49.548771409455725}\n",
      "Epoch 21/35 Loss: {'ner': 38.1142055916981}\n",
      "Epoch 22/35 Loss: {'ner': 30.888697165078256}\n",
      "Epoch 23/35 Loss: {'ner': 18.504382837480208}\n",
      "Epoch 24/35 Loss: {'ner': 17.139075137070733}\n",
      "Epoch 25/35 Loss: {'ner': 7.350393216502474}\n",
      "Epoch 26/35 Loss: {'ner': 10.709552308696432}\n",
      "Epoch 27/35 Loss: {'ner': 7.201755912021696}\n",
      "Epoch 28/35 Loss: {'ner': 5.782317648383557}\n",
      "Epoch 29/35 Loss: {'ner': 3.809793454098669}\n",
      "Epoch 30/35 Loss: {'ner': 3.9834114163493206}\n",
      "Epoch 31/35 Loss: {'ner': 1.0624665617843474}\n",
      "Epoch 32/35 Loss: {'ner': 4.456026047329064}\n",
      "Epoch 33/35 Loss: {'ner': 4.769753641713513}\n",
      "Epoch 34/35 Loss: {'ner': 1.9896911501702093}\n",
      "Epoch 35/35 Loss: {'ner': 4.13057998146086}\n",
      "Model saved to output_medical_ner\n",
      "\n",
      "Test sentence: He is also a former cigarette smoker, quit several years ago.\n",
      "Predicted NER: []\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# =======================================================\n",
    "# 1. Load annotated JSONL\n",
    "# =======================================================\n",
    "\n",
    "json_path = \"train_annotation_complete.jsonl\"\n",
    "data = []\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# =======================================================\n",
    "# 2. Your custom labels\n",
    "# =======================================================\n",
    "\n",
    "CUSTOM_LABELS = [\"DISEASE\", \"BODY_PART\", \"FINDING\", \"PROCEDURE\", \"SYMPTOM\"]\n",
    "print(\"Custom NER labels:\", CUSTOM_LABELS)\n",
    "\n",
    "# =======================================================\n",
    "# 3. Prepare training data\n",
    "# =======================================================\n",
    "\n",
    "def find_span(text, phrase):\n",
    "    start = text.lower().find(phrase.lower())\n",
    "    if start == -1:\n",
    "        return None\n",
    "    return (start, start + len(phrase))\n",
    "\n",
    "training_examples = []\n",
    "\n",
    "for item in data:\n",
    "    text = item[\"text\"]\n",
    "    labels = item[\"annotation\"]  # [[\"hypertension\",\"DISEASE\"], ...]\n",
    "\n",
    "    entities = []\n",
    "    for phrase, label in labels:\n",
    "        span = find_span(text, phrase)\n",
    "        if span:\n",
    "            entities.append((span[0], span[1], label))\n",
    "\n",
    "    training_examples.append((text, {\"entities\": entities}))\n",
    "\n",
    "print(\"Example:\", training_examples[0])\n",
    "\n",
    "# =======================================================\n",
    "# 4. Initialize blank model for spaCy 3.8+\n",
    "# =======================================================\n",
    "\n",
    "nlp = spacy.blank(\"en\")         \n",
    "ner = nlp.add_pipe(\"ner\")       \n",
    "\n",
    "# Add custom labels\n",
    "for label in CUSTOM_LABELS:\n",
    "    ner.add_label(label)\n",
    "\n",
    "# =======================================================\n",
    "# 5. Training loop\n",
    "# =======================================================\n",
    "\n",
    "n_iter = 35\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    random.shuffle(training_examples)\n",
    "    losses = {}\n",
    "\n",
    "    batches = minibatch(training_examples, size=compounding(4.0, 32.0, 1.5))\n",
    "\n",
    "    for batch in batches:\n",
    "        examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in batch]\n",
    "        nlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_iter} Loss: {losses}\")\n",
    "\n",
    "# =======================================================\n",
    "# 6. Save model\n",
    "# =======================================================\n",
    "\n",
    "output_dir = \"output_medical_ner\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Model saved to\", output_dir)\n",
    "\n",
    "# =======================================================\n",
    "# 7. Quick sanity check\n",
    "# =======================================================\n",
    "\n",
    "test_text = random.choice(data)[\"text\"]\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"\\nTest sentence:\", test_text)\n",
    "print(\"Predicted NER:\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229beae",
   "metadata": {},
   "source": [
    "### (2) Extended NER evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d2a3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 annotated sentences\n",
      "\n",
      "===== Extended spaCy NER Evaluation =====\n",
      "Precision: 0.1667\n",
      "Recall:    0.1667\n",
      "F1 score:  0.1667\n",
      "\n",
      "Macro Precision: 0.3333\n",
      "Macro Recall:    0.0734\n",
      "Macro F1:        0.1127\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: Nausea.,3.\n",
      "Gold: {(0, 6, 'SYMPTOM')}\n",
      "Pred: set()\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Extended NER evaluation with test sample\n",
    "# =========================================\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# ===================================================\n",
    "# 1. Load JSONL annotations for test\n",
    "# ===================================================\n",
    "jsonl_path = \"test_annotation_complete.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        data.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load Extended spaCy NER\n",
    "# ===================================================\n",
    "nlp = spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# ===================================================\n",
    "# 3. Convert annotations to character-level spans\n",
    "# ===================================================\n",
    "\n",
    "def find_span(text, phrase):\n",
    "    \"\"\"\n",
    "    Locate (start, end) in the sentence.\n",
    "    If multiple choices, take the first one.\n",
    "    Retrun None if not found。\n",
    "    \"\"\"\n",
    "    start = text.lower().find(phrase.lower())\n",
    "    if start == -1:\n",
    "        return None\n",
    "    return (start, start + len(phrase))\n",
    "\n",
    "gold_spans = []\n",
    "pred_spans = []\n",
    "labels = []   # For all ground-truth annotion in the test\n",
    "\n",
    "for item in data:\n",
    "    text = item[\"text\"]\n",
    "    ann_list = item[\"annotation\"]  # [[\"ankle\",\"BODY_PART\"], ...]\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    # -------- gold spans --------\n",
    "    gold = []\n",
    "    for phrase, label in ann_list:\n",
    "        span = find_span(text, phrase)\n",
    "        if span is not None:\n",
    "            gold.append((span[0], span[1], label))\n",
    "            labels.append(label)\n",
    "        # else:\n",
    "        #     print(\"Warning: phrase not found:\", phrase)\n",
    "\n",
    "    gold_spans.append(gold)\n",
    "\n",
    "    # -------- predicted spans --------\n",
    "    pred = []\n",
    "    for ent in doc.ents:\n",
    "        pred.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    pred_spans.append(pred)\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "# ===================================================\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for g_spans, p_spans in zip(gold_spans, pred_spans):\n",
    "\n",
    "    #  (start,end,label) precise matching\n",
    "    g_set = set(g_spans)\n",
    "    p_set = set(p_spans)\n",
    "\n",
    "    # True positives\n",
    "    for span in g_set:\n",
    "        if span in p_set:\n",
    "            true_labels.append(span[2])\n",
    "            pred_labels.append(span[2])\n",
    "        else:\n",
    "            true_labels.append(span[2])\n",
    "            pred_labels.append(\"NONE\")  # missed\n",
    "\n",
    "    # False positives\n",
    "    for span in p_set:\n",
    "        if span not in g_set:\n",
    "            true_labels.append(\"NONE\")     # if no gold annotation\n",
    "            pred_labels.append(span[2])    # wrong\n",
    "\n",
    "# ===================================================\n",
    "# 5. Evaluate macro and micro F1\n",
    "# ===================================================\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    true_labels, pred_labels, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Extended spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "    true_labels, pred_labels, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 6. Show some error cases\n",
    "# ===================================================\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "\n",
    "for i, (g, p, item) in enumerate(zip(gold_spans, pred_spans, data)):\n",
    "    g_set = set(g)\n",
    "    p_set = set(p)\n",
    "    if g_set != p_set:\n",
    "        print(\"Text:\", item[\"text\"])\n",
    "        print(\"Gold:\", g_set)\n",
    "        print(\"Pred:\", p_set)\n",
    "        print(\"-\" * 50)\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e318e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 83 annotated sentences\n",
      "\n",
      "===== Extended spaCy NER Evaluation =====\n",
      "Precision: 0.9848\n",
      "Recall:    0.9848\n",
      "F1 score:  0.9848\n",
      "\n",
      "Macro Precision: 0.8333\n",
      "Macro Recall:    0.825\n",
      "Macro F1:        0.8291\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: Multiple wound cultures have repeatedly grown Pseudomonas, Enterococcus, and Stenotrophomonas in the past.\n",
      "Gold: {(77, 93, 'FINDING'), (46, 57, 'FINDING'), (59, 71, 'FINDING'), (9, 23, 'PROCEDURE')}\n",
      "Pred: {(77, 93, 'FINDING'), (46, 57, 'FINDING'), (9, 23, 'PROCEDURE')}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Extended NER evaluation with training sample \n",
    "# =========================================\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# ===================================================\n",
    "# 1. Load JSONL annotations for test\n",
    "# ===================================================\n",
    "jsonl_path = \"train_annotation_complete.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        data.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# ===================================================\n",
    "# 2. Load Extended spaCy NER\n",
    "# ===================================================\n",
    "nlp = spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# ===================================================\n",
    "# 3. Convert annotations to character-level spans\n",
    "# ===================================================\n",
    "\n",
    "def find_span(text, phrase):\n",
    "    \"\"\"\n",
    "    Locate (start, end) in the sentence.\n",
    "    If multiple choices, take the first one.\n",
    "    Retrun None if not found。\n",
    "    \"\"\"\n",
    "    start = text.lower().find(phrase.lower())\n",
    "    if start == -1:\n",
    "        return None\n",
    "    return (start, start + len(phrase))\n",
    "\n",
    "gold_spans = []\n",
    "pred_spans = []\n",
    "labels = []   # For all ground-truth annotion in the test\n",
    "\n",
    "for item in data:\n",
    "    text = item[\"text\"]\n",
    "    ann_list = item[\"annotation\"]  # [[\"ankle\",\"BODY_PART\"], ...]\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    # -------- gold spans --------\n",
    "    gold = []\n",
    "    for phrase, label in ann_list:\n",
    "        span = find_span(text, phrase)\n",
    "        if span is not None:\n",
    "            gold.append((span[0], span[1], label))\n",
    "            labels.append(label)\n",
    "        # else:\n",
    "        #     print(\"Warning: phrase not found:\", phrase)\n",
    "\n",
    "    gold_spans.append(gold)\n",
    "\n",
    "    # -------- predicted spans --------\n",
    "    pred = []\n",
    "    for ent in doc.ents:\n",
    "        pred.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    pred_spans.append(pred)\n",
    "\n",
    "# ===================================================\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "# ===================================================\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for g_spans, p_spans in zip(gold_spans, pred_spans):\n",
    "\n",
    "    #  (start,end,label) precise matching\n",
    "    g_set = set(g_spans)\n",
    "    p_set = set(p_spans)\n",
    "\n",
    "    # True positives\n",
    "    for span in g_set:\n",
    "        if span in p_set:\n",
    "            true_labels.append(span[2])\n",
    "            pred_labels.append(span[2])\n",
    "        else:\n",
    "            true_labels.append(span[2])\n",
    "            pred_labels.append(\"NONE\")  # missed\n",
    "\n",
    "    # False positives\n",
    "    for span in p_set:\n",
    "        if span not in g_set:\n",
    "            true_labels.append(\"NONE\")     # if no gold annotation\n",
    "            pred_labels.append(span[2])    # wrong\n",
    "\n",
    "# ===================================================\n",
    "# 5. Evaluate macro and micro F1\n",
    "# ===================================================\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    true_labels, pred_labels, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Extended spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "    true_labels, pred_labels, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 6. Show some error cases\n",
    "# ===================================================\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "\n",
    "for i, (g, p, item) in enumerate(zip(gold_spans, pred_spans, data)):\n",
    "    g_set = set(g)\n",
    "    p_set = set(p)\n",
    "    if g_set != p_set:\n",
    "        print(\"Text:\", item[\"text\"])\n",
    "        print(\"Gold:\", g_set)\n",
    "        print(\"Pred:\", p_set)\n",
    "        print(\"-\" * 50)\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08530c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
