{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed65dff4",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "Update part 1 with new labels\n",
    "\n",
    "Check if 3.1 runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2340435",
   "metadata": {},
   "source": [
    "# Task 2: Data Exploration and Processing\n",
    "\n",
    "## 1. Manual data inspection\n",
    "- Investigate which standard and potential new NER types are most prominent in your data set (i.e., manual data inspection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45545326",
   "metadata": {},
   "source": [
    "Following visual inspection, some of the prominent NERs found are: DATE, BODY_PART, DOSAGE, MEASUREMENT, DRUG and SYMPTOM. \n",
    "\n",
    "Examples:\n",
    " 1. DATE: 12/20/2005, 1/19/96\n",
    " 2. BODY_PART: nose, abdomen, knee\n",
    " 3. DOSAGE:  10/40 mg one a day, 0.25 micrograms a day, 50 mg twice a day, 10 ml\n",
    " 4. MEASUREMENT: 3.98 kg, 8mm, pulse of 84, blood pressure 108/65\n",
    " 5. DRUG:  Vytorin, Rocaltrol, Carvedilol, Cozaar,  Lasix\n",
    " 6. SYMPTOM: erythematous, chest pain, constipated\n",
    "\n",
    "Where, DATE is a **standard NER in spacy** and the remaining ones fall in the medicine domain category. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf5702",
   "metadata": {},
   "source": [
    "## 2. Apply the standard NER classifier of spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4cb76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4127fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af4584a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f457d37",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "392028f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features available\n",
      "['text', 'inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'id', 'metadata', 'status', 'event_timestamp', 'metrics']\n",
      "Format of 'prediction' column\n",
      "List({'label': Value('string'), 'score': Value('float64')})\n",
      "Dataset length:  4966\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1: Load Dataset\n",
    "# ============================\n",
    "dataset = load_dataset(\"argilla/medical-domain\", split=\"train\")\n",
    "print(\"Features available\")\n",
    "print(dataset.column_names)\n",
    "print(\"Format of 'prediction' column\")\n",
    "print(dataset.features['prediction'])\n",
    "print(\"Dataset length: \", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5f52b",
   "metadata": {},
   "source": [
    "### Filter such that we keep only samples pertaining to 'Surgery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a8beaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/4966 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4966/4966 [00:00<00:00, 14060.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_slimmed = dataset.filter(\n",
    "\tlambda row: (\n",
    "\t\tisinstance(row[\"text\"], str)\n",
    "        and row[\"text\"] != ''\n",
    "\t\tand 'Surgery' in str(row[\"prediction\"][0])\n",
    "\t)\n",
    ")\n",
    "dataset = dataset_slimmed\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad783949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our NER schema =  ['SYMPTOM', 'BODY_PART', 'DISEASE', 'DRUG', 'ROUTE']\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 2: Define Entity Schema\n",
    "# ================================================\n",
    "# Our final gold-label schema\n",
    "CUSTOM_LABELS = ['SYMPTOM', 'BODY_PART', 'DISEASE', 'DRUG', 'ROUTE']\n",
    "\n",
    "print(\"Our NER schema = \", CUSTOM_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98f45d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unannotated_samples.csv with 3 sentences\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3: Pick N samples manually\n",
    "# =========================================\n",
    "PATH_TO_ANNOTATIONS = \"ner/samples/\"\n",
    "SEED = 42 \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "N_SAMPLES = 3   # select a proper number to contain 100 ground-truth NERs \n",
    "sampled_texts = []\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "\trow = dataset[np.random.randint(0, len(dataset))]\n",
    "\ttext = row[\"text\"]\n",
    "\tsampled_texts.append(text)\n",
    "\n",
    "df_samples = pd.DataFrame({\"text\": sampled_texts})\n",
    "df_samples.to_csv(PATH_TO_ANNOTATIONS + \"unannotated_samples.csv\", index=False)\n",
    "\n",
    "print(\"Saved unannotated_samples.csv with\", len(df_samples), \"sentences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c1289",
   "metadata": {},
   "source": [
    "## 3. Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35f24",
   "metadata": {},
   "source": [
    "### Perform manual annotations, then split into train/test \n",
    "\n",
    " The annotation format is: \n",
    "\n",
    "\t{\n",
    "\t\t\"classes\": List(labels), \n",
    "\t\t\"annotations\": List(\n",
    "\t\t\t[str(text), dict(\"entities\": List(List(start idx, end idx, class)))]\n",
    "\t\t)\n",
    "\t}\n",
    "Where each item in \"annotations\" is a sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78713c24",
   "metadata": {},
   "source": [
    "#### Manual Annotations (with AI assistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba636a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.annotations_utils as utils_ann # ChatGPT API called to identify keywords/phrases associated with entities\n",
    "\n",
    "unannotated_samples_path = PATH_TO_ANNOTATIONS + \"unannotated_samples.csv\"\n",
    "df = pd.read_csv(unannotated_samples_path, header=0)\n",
    "text = df['text'].to_list()\n",
    "num_examples_per_label = 30\n",
    "annotations = utils_ann.chatgpt_annotate_text(CUSTOM_LABELS, text, num_examples_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7561c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Label: SYMPTOM =======\n",
      "[0, 'pain']\n",
      "[1, 'deformity']\n",
      "[2, 'dysfunction']\n",
      "[3, 'atrophy']\n",
      "[4, 'flexible talus']\n",
      "[5, 'motion changes']\n",
      "[6, 'sensation changes']\n",
      "[7, 'bleeding']\n",
      "[8, 'infection']\n",
      "[9, 'swelling']\n",
      "[10, 'muscular dystrophy']\n",
      "[11, 'hematoma']\n",
      "[12, 'thinning']\n",
      "[13, 'resection']\n",
      "[14, 'inflammation']\n",
      "[15, 'weakness']\n",
      "[16, 'sensitivity']\n",
      "[17, 'numbness']\n",
      "[18, 'impaired function']\n",
      "[19, 'low mobility']\n",
      "[20, 'tenderness']\n",
      "[21, 'ache']\n",
      "[22, 'limited motion']\n",
      "[23, 'stiffness']\n",
      "[24, 'difficulty']\n",
      "[25, 'irritation']\n",
      "[26, 'complications']\n",
      "[27, 'malalignment']\n",
      "[28, 'protrusion']\n",
      "[29, 'increased risk']\n",
      "====== Label: BODY_PART ======\n",
      "[0, 'foot']\n",
      "[1, 'arm']\n",
      "[2, 'forearm']\n",
      "[3, 'elbow']\n",
      "[4, 'mandible']\n",
      "[5, 'maxilla']\n",
      "[6, 'leg']\n",
      "[7, 'shoulder']\n",
      "[8, 'talocalcaneal joint']\n",
      "[9, 'extremity']\n",
      "[10, 'muscle']\n",
      "[11, 'thigh']\n",
      "[12, 'spine']\n",
      "[13, 'sinus']\n",
      "[14, 'upper limb']\n",
      "[15, 'arm']\n",
      "[16, 'heel']\n",
      "[17, 'lower surface']\n",
      "[18, 'biceps']\n",
      "[19, 'nerve']\n",
      "[20, 'foot arch']\n",
      "[21, 'vein']\n",
      "[22, 'artery']\n",
      "[23, 'bone']\n",
      "[24, 'palate']\n",
      "[25, 'buttock']\n",
      "[26, 'cavity']\n",
      "[27, 'genial tubercle']\n",
      "[28, 'mental foramina']\n",
      "[29, 'soft tissue']\n",
      "======= Label: DISEASE =======\n",
      "[0, 'end-stage renal disease']\n",
      "[1, 'myotonic muscular dystrophy']\n",
      "[2, 'planovalgus']\n",
      "[3, 'mandibular atrophy']\n",
      "[4, 'maxillary atrophy']\n",
      "[5, 'facial deformity']\n",
      "[6, 'masticatory dysfunction']\n",
      "[7, 'acquired deformity']\n",
      "[8, 'vertical talus']\n",
      "[9, 'implant failure']\n",
      "[10, 'hip fracture']\n",
      "[11, 'infection']\n",
      "[12, 'anterior mandibular atrophy']\n",
      "[13, 'arthrodesis indication']\n",
      "[14, 'release complications']\n",
      "[15, 'mandibular deficiency']\n",
      "[16, 'surgical failure']\n",
      "[17, 'hemorrhage']\n",
      "[18, 'graft complications']\n",
      "[19, 'suture complications']\n",
      "[20, 'pneumonia']\n",
      "[21, 'urinary infection']\n",
      "[22, 'anesthetic reaction']\n",
      "[23, 'scarring']\n",
      "[24, 'paralysis risk']\n",
      "[25, 'neuralgia']\n",
      "[26, 'edema']\n",
      "[27, 'stump neuroma']\n",
      "[28, 'fatigue syndrome']\n",
      "[29, 'hypoxia']\n",
      "======== Label: DRUG =========\n",
      "[0, 'Marcaine']\n",
      "[1, 'Ancef']\n",
      "[2, 'Xylocaine']\n",
      "[3, 'source anesthetics']\n",
      "[4, 'epinephrine']\n",
      "[5, 'Prolene']\n",
      "[6, 'Vicryl']\n",
      "[7, 'Monocryl']\n",
      "[8, 'citrate plasma']\n",
      "[9, 'normal saline']\n",
      "[10, 'AlloDerm']\n",
      "[11, 'nestim']\n",
      "[12, 'antibiotic']\n",
      "[13, 'anesthetic']\n",
      "[14, 'collagen']\n",
      "[15, 'suture']\n",
      "[16, 'antiseptic']\n",
      "[17, 'silibinin']\n",
      "[18, 'metronidazole']\n",
      "[19, 'bupivacaine']\n",
      "[20, 'sclerotherapy']\n",
      "[21, 'renatec']\n",
      "[22, 'analgesic']\n",
      "[23, 'dexmedetomidine']\n",
      "[24, 'riluzole']\n",
      "[25, 'lidocaine']\n",
      "[26, 'NSAIDs']\n",
      "[27, 'anticoagulant']\n",
      "[28, 'sedation']\n",
      "[29, 'tetrahydrocannabinol']\n",
      "======== Label: ROUTE ========\n",
      "[0, 'nasal intubation']\n",
      "[1, 'oral administration']\n",
      "[2, 'injection']\n",
      "[3, 'catheter']\n",
      "[4, 'intravenous']\n",
      "[5, 'local infiltration']\n",
      "[6, 'isotope']\n",
      "[7, 'topical']\n",
      "[8, 'oral']\n",
      "[9, 'venous']\n",
      "[10, 'subcutaneous']\n",
      "[11, 'epidural']\n",
      "[12, 'peritoneal']\n",
      "[13, 'gastrostomy']\n",
      "[14, 'nebulization']\n",
      "[15, 'intramuscular']\n",
      "[16, 'transdermal']\n",
      "[17, 'sciatic']\n",
      "[18, 'sublingual']\n",
      "[19, 'neboulizer']\n",
      "[20, 'end-artery']\n",
      "[21, 'gluteal']\n",
      "[22, 'subdermal']\n",
      "[23, 'intradermal']\n",
      "[24, 'parenteral']\n",
      "[25, 'intranasal']\n",
      "[26, 'subcortical']\n",
      "[27, 'endotracheal']\n",
      "[28, 'through skin']\n",
      "[29, 'intraoral']\n"
     ]
    }
   ],
   "source": [
    "for label in annotations.keys():\n",
    "\tprint(f\" Label: {label} \".center(30, '='))\n",
    "\tfor indexed_words in annotations[label]:\n",
    "\t\tprint(indexed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Label: SYMPTOM =======\n",
      "pain\n",
      "deformity\n",
      "dysfunction\n",
      "atrophy\n",
      "flexible talus\n",
      "motion changes\n",
      "sensation changes\n",
      "bleeding\n",
      "infection\n",
      "swelling\n",
      "muscular dystrophy\n",
      "hematoma\n",
      "thinning\n",
      "resection\n",
      "inflammation\n",
      "weakness\n",
      "sensitivity\n",
      "numbness\n",
      "impaired function\n",
      "low mobility\n",
      "tenderness\n",
      "ache\n",
      "limited motion\n",
      "stiffness\n",
      "difficulty\n",
      "irritation\n",
      "complications\n",
      "malalignment\n",
      "protrusion\n",
      "====== Label: BODY_PART ======\n",
      "foot\n",
      "arm\n",
      "forearm\n",
      "elbow\n",
      "mandible\n",
      "maxilla\n",
      "leg\n",
      "shoulder\n",
      "joint\n",
      "extremity\n",
      "muscle\n",
      "thigh\n",
      "spine\n",
      "sinus\n",
      "limb\n",
      "arm\n",
      "heel\n",
      "biceps\n",
      "nerve\n",
      "foot arch\n",
      "vein\n",
      "artery\n",
      "bone\n",
      "palate\n",
      "buttock\n",
      "cavity\n",
      "genial tubercle\n",
      "mental foramina\n",
      "soft tissue\n",
      "======= Label: DISEASE =======\n",
      "renal disease\n",
      "myotonic muscular dystrophy\n",
      "planovalgus\n",
      "mandibular atrophy\n",
      "maxillary atrophy\n",
      "facial deformity\n",
      "masticatory dysfunction\n",
      "acquired deformity\n",
      "vertical talus\n",
      "implant failure\n",
      "hip fracture\n",
      "infection\n",
      "anterior mandibular atrophy\n",
      "arthrodesis indication\n",
      "release complications\n",
      "mandibular deficiency\n",
      "surgical failure\n",
      "hemorrhage\n",
      "graft complications\n",
      "suture complications\n",
      "pneumonia\n",
      "urinary infection\n",
      "anesthetic reaction\n",
      "scarring\n",
      "paralysis risk\n",
      "neuralgia\n",
      "edema\n",
      "stump neuroma\n",
      "fatigue syndrome\n",
      "hypoxia\n",
      "======== Label: DRUG =========\n",
      "Marcaine\n",
      "Ancef\n",
      "Xylocaine\n",
      "anesthetics\n",
      "epinephrine\n",
      "Prolene\n",
      "Vicryl\n",
      "Monocryl\n",
      "citrate plasma\n",
      "saline\n",
      "AlloDerm\n",
      "nestim\n",
      "antibiotic\n",
      "anesthetic\n",
      "collagen\n",
      "suture\n",
      "antiseptic\n",
      "silibinin\n",
      "metronidazole\n",
      "bupivacaine\n",
      "sclerotherapy\n",
      "renatec\n",
      "analgesic\n",
      "dexmedetomidine\n",
      "riluzole\n",
      "lidocaine\n",
      "NSAIDs\n",
      "anticoagulant\n",
      "tetrahydrocannabinol\n",
      "======== Label: ROUTE ========\n",
      "nasal intubation\n",
      "oral administration\n",
      "injection\n",
      "catheter\n",
      "intravenous\n",
      "local infiltration\n",
      "topical\n",
      "oral\n",
      "venous\n",
      "subcutaneous\n",
      "epidural\n",
      "peritoneal\n",
      "gastrostomy\n",
      "nebulization\n",
      "intramuscular\n",
      "transdermal\n",
      "sublingual\n",
      "neboulizer\n",
      "end-artery\n",
      "gluteal\n",
      "subdermal\n",
      "intradermal\n",
      "parenteral\n",
      "intranasal\n",
      "subcortical\n",
      "endotracheal\n",
      "through skin\n",
      "intraoral\n"
     ]
    }
   ],
   "source": [
    "# Specify examples to exclude or modify\n",
    "# NOTE: pop larger indices first to maintain index ordering of earlier items after deletion\n",
    "annotations['SYMPTOM'].pop(29)\n",
    "\n",
    "annotations['BODY_PART'][8][1] = 'joint'\n",
    "annotations['BODY_PART'][14][1] = 'limb'\n",
    "annotations['BODY_PART'].pop(17)\n",
    "\n",
    "annotations['DISEASE'][0][1] = 'renal disease'\n",
    "\n",
    "annotations['DRUG'][3][1] = 'anesthetics'\n",
    "annotations['DRUG'][9][1] = 'saline'\n",
    "annotations['DRUG'].pop(28)\n",
    "\n",
    "annotations['ROUTE'].pop(17)\n",
    "annotations['ROUTE'].pop(6)\n",
    "\n",
    "for label in annotations.keys():\n",
    "\tprint(f\" Label: {label} \".center(30, '='))\n",
    "\twords_list = []\n",
    "\tfor idx, word in annotations[label]:\n",
    "\t\twords_list.append(word)\n",
    "\t\tprint(word)\n",
    "\tannotations[label] = words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d8646",
   "metadata": {},
   "source": [
    "#### Save annotations to the appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "915cb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load samples: only column \"text\"\n",
    "df = pd.read_csv(unannotated_samples_path)\n",
    "\n",
    "# 2. Load spaCy for sentence splitting\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "\tnlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# 3. Extract all sentences across samples\n",
    "all_sentences = []\n",
    "for _, row in df.iterrows():\n",
    "\tfull_text = str(row[\"text\"])\n",
    "\tdoc = nlp(full_text)\n",
    "\n",
    "\t# Extract sentences\n",
    "\tall_sentences.extend([s.text.strip() for s in doc.sents if len(s.text.strip()) > 0])\n",
    "\n",
    "# 4. Annotate all identified keywords in sentences and save to json file\n",
    "utils_ann.annotate_sentences_and_save(all_sentences, annotations, CUSTOM_LABELS, PATH_TO_ANNOTATIONS+'annotated_samples.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dfcb8",
   "metadata": {},
   "source": [
    "### Train/Test split of annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c697b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Train samples:  84\n",
      "N Test samples:  36\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Generate train/test annotation template JSONL with ratio control\n",
    "# ============================================\n",
    "annotated_samples_path = PATH_TO_ANNOTATIONS + \"annotated_samples.json\"\n",
    "\n",
    "# =====================================================\n",
    "# Parameters: control split ratio (sentence-wise split)\n",
    "# =====================================================\n",
    "TRAIN_RATIO = 0.70     # first 70% for training\n",
    "TEST_RATIO  = 0.30     # first 30% for evaluation/test\n",
    "\n",
    "# ================================\n",
    "\n",
    "# Load annotated samples: only key \"annotations\"\n",
    "annotations_dict = None\n",
    "with open(annotated_samples_path) as annotations_file:\n",
    "\tannotations_dict = json.load(annotations_file)\n",
    "all_sentences = annotations_dict[\"annotations\"]\n",
    "\n",
    "# ===========================\n",
    "# Create train/test sets\n",
    "# ===========================\n",
    "\n",
    "np.random.shuffle(all_sentences) # shuffle randomly first before splitting\n",
    "total = len(all_sentences)\n",
    "train_cutoff = int(total * TRAIN_RATIO)\n",
    "test_cutoff = train_cutoff + int(total * TEST_RATIO)\n",
    "\n",
    "train_sentences = all_sentences[:train_cutoff]\n",
    "test_sentences = all_sentences[train_cutoff:test_cutoff]\n",
    "\n",
    "print(\"N Train samples: \", len(train_sentences))\n",
    "print(\"N Test samples: \", len(test_sentences))\n",
    "# ===========================\n",
    "# Save sentences into train/test\n",
    "# ===========================\n",
    "train_samples_path = PATH_TO_ANNOTATIONS + 'annotated_samples_train.json'\n",
    "annotations_dict['annotations'] = train_sentences\n",
    "with open(train_samples_path, 'w') as fp:\n",
    "\tjson.dump(annotations_dict, fp)\n",
    "\n",
    "test_samples_path = PATH_TO_ANNOTATIONS + 'annotated_samples_test.json'\n",
    "annotations_dict['annotations'] = test_sentences\n",
    "with open(test_samples_path, 'w') as fp:\n",
    "\tjson.dump(annotations_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d519d",
   "metadata": {},
   "source": [
    "### 3.1 Manual Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6bf3736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Text Preview ===\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (c:\\Users\\Esther\\anaconda3\\envs\\nlp\\Lib\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m doc = nlp(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(test_text[:\u001b[32m2000\u001b[39m]))\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 5. Render using displacy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esther\\anaconda3\\envs\\nlp\\Lib\\site-packages\\spacy\\displacy\\__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (c:\\Users\\Esther\\anaconda3\\envs\\nlp\\Lib\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "source": [
    "### Manual Evaluation of Standard NER\n",
    "from spacy import displacy\n",
    "\n",
    "# 1. Load sample text\n",
    "annotations_dict = None\n",
    "with open(test_samples_path) as annotations_file:\n",
    "\tannotations_dict = json.load(annotations_file)\n",
    "\t\n",
    "# 2. Extract second row text\n",
    "test_text = [sent for sent, _ in annotations_dict[\"annotations\"]]\n",
    "\n",
    "print(\"=== Test Text Preview ===\")\n",
    "\n",
    "# 3. Load spaCy model (baseline or your updated one)\n",
    "nlp = spacy.load(\"en_core_web_md\")   # or: spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# 4. Run NER on the full document\n",
    "doc = nlp(''.join(test_text[:2000]))\n",
    "\n",
    "# 5. Render using displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24f233",
   "metadata": {},
   "source": [
    "Observation: Some NERs don't make sense. E.g., Vomitting -> PERSON, Hypokalemia -> PERSON, Diarrhea -> PERSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c109e22",
   "metadata": {},
   "source": [
    "### 3.2 Automatic Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 annotated sentences\n",
      "\n",
      "===== Baseline spaCy NER Evaluation =====\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 score:  0.0000\n",
      "\n",
      "Macro Precision: 0.0\n",
      "Macro Recall:    0.0\n",
      "Macro F1:        0.0\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: ADMISSION DIAGNOSES:,1.\n",
      "Gold: set()\n",
      "Pred: {(0, 9, 'ORG')}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Standard NER evaluation\n",
    "# =========================================\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from ner.utils import extract_spans, convert_to_labels\n",
    "\n",
    "# 1. Load JSONL annotations\n",
    "jsonl_path = PATH_TO_ANNOTATIONS + \"test_annotation_complete.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tfor line in f:\n",
    "\t\tobj = json.loads(line)\n",
    "\t\tdata.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# 2. Load baseline spaCy NER\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# 3. Convert annotations to character-level spans\n",
    "gold_spans, pred_spans, labels = extract_spans(nlp, data)\n",
    "\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "true_labels, pred_labels = convert_to_labels(gold_spans, pred_spans)\n",
    "\n",
    "# 5. Evaluate macro and micro F1\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Baseline spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "# 6. Show some error cases\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "\n",
    "for i, (g, p, item) in enumerate(zip(gold_spans, pred_spans, data)):\n",
    "\tg_set = set(g)\n",
    "\tp_set = set(p)\n",
    "\tif g_set != p_set:\n",
    "\t\tprint(\"Text:\", item[\"text\"])\n",
    "\t\tprint(\"Gold:\", g_set)\n",
    "\t\tprint(\"Pred:\", p_set)\n",
    "\t\tprint(\"-\" * 50)\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26c084",
   "metadata": {},
   "source": [
    "## 4. Extend the standard NER types using the NER Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b2181",
   "metadata": {},
   "source": [
    "### 4.1 Training Extended NER model with >100 manual annoatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e19587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Overlapping entity problems found =====\n"
     ]
    }
   ],
   "source": [
    "# Make sure there is no overlapping entity problems in the training sample\n",
    "# \n",
    "# import json\n",
    "\n",
    "path = PATH_TO_ANNOTATIONS + \"train_annotation_complete.jsonl\"\n",
    "\n",
    "def spans_overlap(a, b):\n",
    "\treturn not (a[1] <= b[0] or b[1] <= a[0])\n",
    "\n",
    "bad = []\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tfor line in f:\n",
    "\t\tobj = json.loads(line)\n",
    "\t\ttext = obj[\"text\"]\n",
    "\t\tanns = obj[\"annotation\"]  # [[phrase,label],...]\n",
    "\n",
    "\t\tspans = []\n",
    "\t\tfor phrase, label in anns:\n",
    "\t\t\tstart = text.lower().find(phrase.lower())\n",
    "\t\t\tif start == -1:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tend = start + len(phrase)\n",
    "\t\t\tspans.append((start, end, phrase, label))\n",
    "\n",
    "\t\t# check overlapping\n",
    "\t\tfor i in range(len(spans)):\n",
    "\t\t\tfor j in range(i+1, len(spans)):\n",
    "\t\t\t\ta = spans[i]\n",
    "\t\t\t\tb = spans[j]\n",
    "\t\t\t\tif spans_overlap(a, b):\n",
    "\t\t\t\t\tbad.append((obj[\"sentence_id\"], text, a, b))\n",
    "\n",
    "print(\"===== Overlapping entity problems found =====\")\n",
    "for sid, text, a, b in bad:\n",
    "\tprint(f\"\\nSentence {sid}: {text}\")\n",
    "\tprint(\"  ->\", a)\n",
    "\tprint(\"  ->\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d44df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 83 annotated sentences\n",
      "Custom NER labels: ['DISEASE', 'BODY_PART', 'FINDING', 'PROCEDURE', 'SYMPTOM']\n",
      "Example: ('REASON FOR THE CONSULT:,  Nonhealing right ankle stasis ulcer.,HISTORY', {'entities': [(26, 36, 'FINDING'), (37, 48, 'BODY_PART'), (49, 61, 'DISEASE')]})\n",
      "Epoch 1/35 Loss: {'ner': np.float32(776.6242)}\n",
      "Epoch 2/35 Loss: {'ner': np.float32(269.1504)}\n",
      "Epoch 3/35 Loss: {'ner': np.float32(131.03236)}\n",
      "Epoch 4/35 Loss: {'ner': np.float32(118.2531)}\n",
      "Epoch 5/35 Loss: {'ner': np.float32(100.19832)}\n",
      "Epoch 6/35 Loss: {'ner': np.float32(97.127174)}\n",
      "Epoch 7/35 Loss: {'ner': np.float32(82.98265)}\n",
      "Epoch 8/35 Loss: {'ner': np.float32(72.80677)}\n",
      "Epoch 9/35 Loss: {'ner': np.float32(69.08254)}\n",
      "Epoch 10/35 Loss: {'ner': np.float32(76.261856)}\n",
      "Epoch 11/35 Loss: {'ner': np.float32(84.334564)}\n",
      "Epoch 12/35 Loss: {'ner': np.float32(57.126667)}\n",
      "Epoch 13/35 Loss: {'ner': np.float32(90.96537)}\n",
      "Epoch 14/35 Loss: {'ner': np.float32(81.351776)}\n",
      "Epoch 15/35 Loss: {'ner': np.float32(70.72307)}\n",
      "Epoch 16/35 Loss: {'ner': np.float32(65.06766)}\n",
      "Epoch 17/35 Loss: {'ner': np.float32(62.12717)}\n",
      "Epoch 18/35 Loss: {'ner': np.float32(51.675114)}\n",
      "Epoch 19/35 Loss: {'ner': np.float32(54.106678)}\n",
      "Epoch 20/35 Loss: {'ner': np.float32(50.40066)}\n",
      "Epoch 21/35 Loss: {'ner': np.float32(38.21913)}\n",
      "Epoch 22/35 Loss: {'ner': np.float32(33.736706)}\n",
      "Epoch 23/35 Loss: {'ner': np.float32(20.452082)}\n",
      "Epoch 24/35 Loss: {'ner': np.float32(15.577302)}\n",
      "Epoch 25/35 Loss: {'ner': np.float32(7.525216)}\n",
      "Epoch 26/35 Loss: {'ner': np.float32(10.073191)}\n",
      "Epoch 27/35 Loss: {'ner': np.float32(7.136325)}\n",
      "Epoch 28/35 Loss: {'ner': np.float32(7.365319)}\n",
      "Epoch 29/35 Loss: {'ner': np.float32(3.808642)}\n",
      "Epoch 30/35 Loss: {'ner': np.float32(4.055889)}\n",
      "Epoch 31/35 Loss: {'ner': np.float32(0.7914765)}\n",
      "Epoch 32/35 Loss: {'ner': np.float32(3.7043262)}\n",
      "Epoch 33/35 Loss: {'ner': np.float32(5.143702)}\n",
      "Epoch 34/35 Loss: {'ner': np.float32(1.166564)}\n",
      "Epoch 35/35 Loss: {'ner': np.float32(3.5991783)}\n",
      "Model saved to output_medical_ner\n",
      "\n",
      "Test sentence: He is also a former cigarette smoker, quit several years ago.\n",
      "Predicted NER: []\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Extended NER TRAINING\n",
    "# =========================================\n",
    "\n",
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from ner.utils import find_span\n",
    "\n",
    "# 1. Load annotated JSONL\n",
    "json_path = PATH_TO_ANNOTATIONS + \"train_annotation_complete.jsonl\"\n",
    "data = []\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tfor line in f:\n",
    "\t\tdata.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# 2. Custom labels\n",
    "CUSTOM_LABELS = [\"DISEASE\", \"BODY_PART\", \"FINDING\", \"PROCEDURE\", \"SYMPTOM\"]\n",
    "print(\"Custom NER labels:\", CUSTOM_LABELS)\n",
    "\n",
    "# 3. Prepare training data\n",
    "training_examples = []\n",
    "\n",
    "for item in data:\n",
    "\ttext = item[\"text\"]\n",
    "\tlabels = item[\"annotation\"]  # [[\"hypertension\",\"DISEASE\"], ...]\n",
    "\n",
    "\tentities = []\n",
    "\tfor phrase, label in labels:\n",
    "\t\tspan = find_span(text, phrase)\n",
    "\t\tif span:\n",
    "\t\t\tentities.append((span[0], span[1], label))\n",
    "\n",
    "\ttraining_examples.append((text, {\"entities\": entities}))\n",
    "\n",
    "print(\"Example:\", training_examples[0])\n",
    "\n",
    "# 4. Initialize blank model for spaCy 3.8+\n",
    "nlp = spacy.blank(\"en\")         \n",
    "ner = nlp.add_pipe(\"ner\")       \n",
    "\n",
    "# Add custom labels\n",
    "for label in CUSTOM_LABELS:\n",
    "\tner.add_label(label)\n",
    "\n",
    "# 5. Training loop\n",
    "n_iter = 35\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "\trandom.shuffle(training_examples)\n",
    "\tlosses = {}\n",
    "\n",
    "\tbatches = minibatch(training_examples, size=compounding(4.0, 32.0, 1.5))\n",
    "\n",
    "\tfor batch in batches:\n",
    "\t\texamples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in batch]\n",
    "\t\tnlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)\n",
    "\n",
    "\tprint(f\"Epoch {epoch+1}/{n_iter} Loss: {losses}\")\n",
    "\n",
    "# 6. Save model\n",
    "output_dir = \"output_medical_ner\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Model saved to\", output_dir)\n",
    "\n",
    "# 7. Quick sanity check\n",
    "test_text = random.choice(data)[\"text\"]\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"\\nTest sentence:\", test_text)\n",
    "print(\"Predicted NER:\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229beae",
   "metadata": {},
   "source": [
    "### 4.2 Extended NER evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2a3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 annotated sentences\n",
      "\n",
      "===== Extended spaCy NER Evaluation =====\n",
      "Precision: 0.1333\n",
      "Recall:    0.1333\n",
      "F1 score:  0.1333\n",
      "\n",
      "Macro Precision: 0.3333\n",
      "Macro Recall:    0.0583\n",
      "Macro F1:        0.0952\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: Nausea.,3.\n",
      "Gold: {(0, 6, 'SYMPTOM')}\n",
      "Pred: set()\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Extended NER evaluation with test sample\n",
    "# =========================================\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from ner.utils import extract_spans, convert_to_labels\n",
    "\n",
    "# 1. Load JSONL annotations for test\n",
    "jsonl_path = PATH_TO_ANNOTATIONS + \"test_annotation_complete.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tfor line in f:\n",
    "\t\tobj = json.loads(line)\n",
    "\t\tdata.append(obj)\n",
    "\n",
    "print(f\"Loaded {len(data)} annotated sentences\")\n",
    "\n",
    "# 2. Load Extended spaCy NER\n",
    "nlp = spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# 3. Convert annotations to character-level spans\n",
    "gold_spans, pred_spans, labels = extract_spans(nlp, data)\n",
    "\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "true_labels, pred_labels = convert_to_labels(gold_spans, pred_spans)\n",
    "# 5. Evaluate macro and micro F1\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Extended spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "# 6. Show some error cases\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "\n",
    "for i, (g, p, item) in enumerate(zip(gold_spans, pred_spans, data)):\n",
    "\tg_set = set(g)\n",
    "\tp_set = set(p)\n",
    "\tif g_set != p_set:\n",
    "\t\tprint(\"Text:\", item[\"text\"])\n",
    "\t\tprint(\"Gold:\", g_set)\n",
    "\t\tprint(\"Pred:\", p_set)\n",
    "\t\tprint(\"-\" * 50)\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed847e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- The performance is poor as the train and test data sets are not in the same category, and therefore don't share big enough NER vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa558d",
   "metadata": {},
   "source": [
    "## 5. LLM-based NER classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6a5a4",
   "metadata": {},
   "source": [
    "The goal of this part was to see whether a large language model (LLM) could be used as an alternative NER system for my medical text, using only prompts and without training a new model. In practice, we tried several approaches, but all of them were limited by model size, hardware, or missing API access.\n",
    "\n",
    "First, we tried a very small local LLM (about 0.5B parameters) via `llama-cpp`. we asked it to extract entities with my label set (DISEASE, SYMPTOM, BODY_PART, FINDING, PROCEDURE) and return a JSON list. The model usually failed to follow the format and, more importantly, produced almost random labels that did not make medical sense. This suggests that such a small model is not strong enough for domain-specific NER, even with an instruction-style prompt.\n",
    "\n",
    "Second, we tried to use a slightly larger open-source LLM from Hugging Face (e.g. Qwen2.5-1.5B or Llama-3.2-1B) on my macOS machine via the `transformers` library. We implemented a function that builds a medical NER prompt and parses the model output into (phrase, label) pairs. However, even for one or two short sentences, generation on CPU/MPS took several minutes. Running this model on all test sentences to compute precision, recall and F1 would be impractically slow for this project.\n",
    "\n",
    "Third, we looked at the spaCy-LLM integration. In theory, we could define an `llm` component in a `config.cfg` file, for example using a Llama2 model on Hugging Face, and then assemble it as a normal spaCy pipeline. In practice, this either requires access to an external API (e.g. OpenAI) or downloading and running a much larger model (such as Llama2-7B). we have no API credits available and my local hardware is not sufficient to run such a model efficiently.\n",
    "\n",
    "Because of these limitations, we did not manage to build a fully working and scalable LLM-based NER baseline. Our “investigation” of LLM-based NER is therefore mainly conceptual: we explored how it would be prompted and integrated (with transformers or spaCy-LLM), and we observed that under my resource constraints it is not yet practical to use an LLM as a reliable, evaluated medical NER system. For the quantitative results in this project, we rely on the standard spaCy NER and my extended, manually trained medical NER model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338a0fa",
   "metadata": {},
   "source": [
    "### Below is just an example of NER with Llama-3.2-1B-Instruct of one or two sentences. \n",
    "\n",
    "- It takes 20 min for two sentences. Therefore it is just a demo of how NER can be done. \n",
    "- If we have more computational resources, we will evaluate on the whole annotation test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d4258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M1) - 5455 MiB free\n",
      "llama_model_loader: loaded meta data with 31 key-value pairs and 147 tensors from models/Llama-3.2-1B-Instruct-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 1B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type  f16:  113 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 2.30 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 2048\n",
      "print_info: n_layer          = 16\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 64\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 64\n",
      "print_info: n_embd_head_v    = 64\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 512\n",
      "print_info: n_embd_v_gqa     = 512\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 1B\n",
      "print_info: model params     = 1.24 B\n",
      "print_info: general.name     = Llama 3.2 1B Instruct\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 162 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/17 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =  2357.26 MiB\n",
      "..............................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x117d567d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_2                             0x117d56aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_3                             0x126cfb6c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_4                             0x126cfb920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_5                             0x126cfbb80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_6                             0x117d56d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_7                             0x117d56fd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_8                             0x127e15b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4                             0x126cfbfc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_2                      0x117d572a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_3                      0x126cfb430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_4                      0x117d57570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_5                      0x117d577d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_6                      0x127e15e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_7                      0x126cfc250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_8                      0x117d57b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x117d57d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row_c4                             0x126cfc550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x1160e0d20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row_c4                             0x117d58060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x117d582c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row_c4                             0x1160e0f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_id                                 0x127e16100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x117d5d800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x117d5da60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x117d5dcc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x126cfc7b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x117d5df20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x126cfca10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x117d5e180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x1160e11e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x1160e1440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x117d5e3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x127e163d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x1160e16a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf                               0x117d5e640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf_4                             0x127e16630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x127e16900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x126cfcde0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x127e16c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x127e16f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x1160e1900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_abs                                    0x117d5e8a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sgn                                    0x117d5eb00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_step                                   0x127e174d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardswish                              0x127e171e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardsigmoid                            0x1160e1b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_exp                                    0x1160e1dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x117d5ef40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x117d5f1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x126cfd040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x127e17730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x127e17a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x127e17d70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x117d5f400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x117d5f6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x126cfd2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x127e18010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x126cfd840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x127e18270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x127e18770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_mxfp4                         0x1160e2020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x117d5f970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x1160e2280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x1160e24e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x117d5ffc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x117d5fcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x1160e2740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x1160e29a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x127e189d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x117d60260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x117d60530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x126cfdb10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x126cfdd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x126cfe120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x126cfe590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x126cfe9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f32                           0x126cfec40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f16                           0x127e18c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_set_rows_q8_0                          0x1160e2c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_0                          0x117d60800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_1                          0x127e18f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_0                          0x117d60b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_1                          0x127e191b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_iq4_nl                        0x117d610c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x127e19510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul                           0x1160e2e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul_add                       0x117d61440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x117d60dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x117d616a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x127e19770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x1160e30c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x126cfeea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32_group                     0x117d61900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x126cff100 | th_max =  384 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x117d61ba0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x126cff360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32_c4                      0x127e199d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x127e19c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_c4                      0x127e19e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x127e1a160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x117d61fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x126cff5c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x126cff820 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x126cffa80 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x127e1a400 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x117d62240 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x127e1a760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_mxfp4_f32                       0x117d624a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x126cffce0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x117d62700 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x127e1a9c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x127e1acc0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x15f9040d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x117d62a60 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x1160e3320 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x114e2b390 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x15f904330 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x127e1af20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x127e1b3d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x15f904600 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x127e1b840 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x15f904860 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x15f904ac0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x15f904d20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x1160e3580 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x15f904f80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x15f9053f0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x117d62cc0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x117d62f60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x1160e3820 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x15f905650 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x127e1baa0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_2              0x127e1be30 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_3              0x127e1c090 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_4              0x15f9058b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_5              0x117d63230 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x1160e3bc0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x117d63670 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x1160e3e60 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x127e1c2f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x127e1c680 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x127e1c8e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x127e1cb40 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x117d638d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x117d63b30 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x15f905b80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x117d63d90 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x117d641d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x117d64430 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x117d64690 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x127e1cda0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x117d648f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x117d64b90 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x117d64df0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x127e1d000 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x127e1d260 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x117d65150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x117d65420 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x117d65780 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x1160e40c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x117d659e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x117d65c40 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x117d65fa0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x117d66270 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x117d666b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x15f905de0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x117d66910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x117d66b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x117d66dd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x1160e4390 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x117d670a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x1160e4660 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x1160e4930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_mxfp4_f32                    0x127e1d4c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x1160e4c90 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x127e1d760 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x127e1da30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x117d67370 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x127e1dc90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x117d67640 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x117d67910 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x1160e4ef0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x1160e5250 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x1160e5520 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x117d67be0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x1160e5780 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x15f906040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x1160e5ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x15f9062a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x15f906500 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x15f906760 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x127e1dff0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x117d67eb0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x127e1e500 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x1160e5f20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x1160e6180 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x1160e63e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x1160e6640 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x1160e69a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x15f906be0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x127e1e250 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x127e1e8c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x127e1eb20 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x1160e6c00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x1160e6e60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x15f906eb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x117d68280 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x127e1edf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x117d684e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x117d687b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x127e1f050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map0_f16                     0x127e1f2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map1_f32                     0x1160e7130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f16                      0x117d68b50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f16                      0x127e1f690 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f16                     0x15f907180 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f16                     0x127e1f930 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f16                     0x117d68db0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f16                     0x117d69050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f16                     0x15f9073e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_mxfp4_f16                    0x1160e7390 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f16                     0x117d693b0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f16                     0x117d69650 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f16                     0x117d69920 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f16                     0x15f907720 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f16                     0x15f907bc0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f16                  0x1160e77d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f16                   0x1160e7a30 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f16                  0x1160e7c90 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f16                    0x1160e7ef0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f16                    0x15f907e20 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f16                    0x15f908080 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f16                    0x114e2b5f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f16                   0x114e2b950 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f16                   0x15f9082e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x15f908660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x15f9088c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f32                         0x117d69bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f16                         0x117d69e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f32                        0x127e1fd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f16                        0x15f908b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x1160e8250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x1160e84f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x117d6a1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x1160e8750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x15f908d80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x117d6a480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x1160e8a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x117d6a750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x117d6a9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x1160e8cb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x1160e8f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x117d6ad10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x117d6af70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x127e1ffd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x15f909050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x127e202f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x15f9092b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x1160e9220 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x127e20550 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x127e207b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x1160e9760 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x1160e99c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x127e20a50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x1160e9c20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x15f909510 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x1160e9f20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x117d6b210 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x117d6b570 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x117d6b840 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x1160ea180 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x117d6bb10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x1160ea3e0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x1160ea640 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x117d6bd70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x117d6c0d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x15f909770 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x1160ea8e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x15f909af0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x127e20e90 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x15f909dc0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x117d6c330 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x117d6c690 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x117d6cad0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x117d6cd30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x117d6cf90 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x117d6d1f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x15f90a020 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x127e210f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x117d6d520 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x127e21350 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x117d6d7f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x127e215b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x117d6db50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x117d6ddb0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x127e21850 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x117d6e110 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x127e21b20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x15f90a490 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x15f90a6f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x15f90a950 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x127e22050 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x117d6e370 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x127e222b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x117d6e610 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x117d6e870 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x1160eac40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x117d6eb70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x1160eaea0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x1257f0880 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x125898c00 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h64             0x117d6efb0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h64            0x117d6f210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h64            0x117d6f470 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h64            0x117d6f6d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h64            0x117d6f9a0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h64            0x117d6fc70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x15f90acd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x15f90af30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x117d6fed0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x1160eb2e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x1160eb540 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x127e22510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x127e22770 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x127e229d0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x127e22c30 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x117d70130 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x15f90b380 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x15f90b5e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x15f90b840 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x15f90baa0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x117d70570 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x127e22f00 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x127e23450 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x127e236b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x127e23910 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x15f90bde0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x15f90c040 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x127e23b70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x117d707d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x127e23dd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x15f90c2a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x127e240b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x1257f0b80 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x117d70a30 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x15f90c6c0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x117d70e70 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x127e245f0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x127e24310 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x127e248b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x117d710d0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x117d71330 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x15f90c990 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x127e24bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x15f90cbf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x117d71770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x127e24e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x127e25150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x15f90ce50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x127e25570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x117d719d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x117d71c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x117d71e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x117d720f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x15f90d0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x127e257d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x117d72350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x117d725b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x1160eb7a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x1160eba70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x117d72810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x117d72a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x117d72dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x127e25a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x1160ebd40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x15f90d520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x1160ebfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x1160ec300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x15f90d780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x1160ec560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x127e25ee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_reglu                                  0x15f90d9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu                                  0x15f90dc40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu                                 0x127e26140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu_oai                             0x15f90e0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_erf                              0x15f90e370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_quick                            0x127e263a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x117d73030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mean                                   0x117d73300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x127e26600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x15f90e5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x1160ec830 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =    64.00 MiB\n",
      "llama_kv_cache_unified: size =   64.00 MiB (  2048 cells,  16 layers,  1/1 seqs), K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 1176\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   254.50 MiB\n",
      "llama_context: graph nodes  = 566\n",
      "llama_context: graph splits = 226 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | LLAMAFILE = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.model': 'gpt2', 'llama.embedding_length': '2048', 'llama.vocab_size': '128256', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.attention.value_length': '64', 'llama.attention.head_count': '32', 'llama.attention.key_length': '64', 'llama.attention.head_count_kv': '8', 'general.finetune': 'Instruct', 'general.file_type': '1', 'llama.block_count': '16', 'general.size_label': '1B', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.feed_forward_length': '8192', 'general.quantization_version': '2', 'llama.rope.dimension_count': '64', 'general.license': 'llama3.2', 'llama.context_length': '131072', 'general.architecture': 'llama', 'general.basename': 'Llama-3.2', 'llama.rope.freq_base': '500000.000000', 'general.name': 'Llama 3.2 1B Instruct'}\n",
      "Available chat formats from metadata: chat_template.default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json, re\n",
    "\n",
    "# 1. Load GGUF model (same as you already used)\n",
    "llm = Llama(\n",
    "\tmodel_path=\"models/Llama-3.2-1B-Instruct-f16.gguf\",\n",
    "\tn_ctx=2048,\n",
    "\tn_threads=6,\n",
    "\tn_gpu_layers=0     # works on Mac / Windows / Linux\n",
    ")\n",
    "\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 66 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    5953.27 ms\n",
      "llama_perf_context_print: prompt eval time =  735431.22 ms /     2 tokens (367715.61 ms per token,     0.00 tokens per second)\n",
      "llama_perf_context_print:        eval time = 1204764.79 ms /   255 runs   ( 4724.57 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time = 1209872.05 ms /   257 tokens\n",
      "llama_perf_context_print:    graphs reused =        247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM output:\n",
      " BODY_PART:  \"chest\",\n",
      "SYMPTOM:  \"chest pains\",\n",
      "FINDING:  \"vomiting\", \n",
      "PROCEDURE:  \"consulted\", \n",
      "DISEASE:  \"gastritis\", \n",
      "BODY_PART:  \"abdomen\", \n",
      "SYMPTOM:  \"diarrhea\", \n",
      "FINDING:  \"gastritis\", \n",
      "BODY_PART:  \"abdomen\", \n",
      "SYMPTOM:  \"diarrhea\", \n",
      "FINDING:  \"gastritis\", \n",
      "BODY_PART:  \"abdomen\", \n",
      "PROCEDURE:  \"gastritis\", \n",
      "\n",
      "Here is an example json list:\n",
      "\"entity_text_1\":  \"DISEASE_1\",\n",
      "\"entity_text_2\":  \"BODY_PART_2\",\n",
      "...\n",
      "\"entity_text_n\":  \"PROCEDURE_n\",\n",
      "\"entity_text_p\":  \"SYMPTOM_p\" ,\n",
      "\"entity_text_q\":  \"FINDING_q\",\n",
      "\"entity_text_r\":  \"BODY_PART_r\",\n",
      "\"entity_text_s\":  \"PROCEDURE_s\",\n",
      "\"entity_text_t\":  \"SYMPTOM_t\" ,\n",
      "\"entity_text_u\":  \"FINDING_u\",\n",
      "\"entity_text_v\":  \"\n",
      "\n",
      "Parsed entities:\n"
     ]
    }
   ],
   "source": [
    "# 2. Test sentence\n",
    "text = \"She was having chest pains along with significant vomiting and diarrhea.\"\n",
    "\n",
    "# 3. Minimal zero-shot NER prompt (no enhancements)\n",
    "PROMPT = \"\"\"\n",
    "Extract medical named entities from the text.\n",
    "Use only these labels: DISEASE, SYMPTOM, BODY_PART, FINDING, PROCEDURE.\n",
    "Return ONLY a JSON list like this:\n",
    "\"entity_text_1\":  \"LABEL_1\",\n",
    "Text:\n",
    "{TEXT}\n",
    "\"\"\"\n",
    "\n",
    "# 4. Run LLM\n",
    "raw = llm(PROMPT.format(TEXT=text), max_tokens=256)\n",
    "output = raw[\"choices\"][0][\"text\"]\n",
    "print(\"\\nRaw LLM output:\\n\", output)\n",
    "\n",
    "# 5. Parse JSON from model output\n",
    "def parse_json(s):\n",
    "\ttry:\n",
    "\t\tmatch = re.search(r\"\\[.*\\]\", s, re.S)\n",
    "\t\tif match:\n",
    "\t\t\treturn json.loads(match.group(0))\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\treturn []\n",
    "\n",
    "ents = parse_json(output)\n",
    "\n",
    "# 6. Print final extracted entities\n",
    "print(\"\\nParsed entities:\")\n",
    "for e in ents:\n",
    "\tprint(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c50e32",
   "metadata": {},
   "source": [
    "## 6. How NER type information can help other NLP tasks\n",
    "\n",
    "Even if the NER models in this project are not perfect, the extracted entity types are still useful for many other NLP applications in the clinical domain. Here I briefly summarise a few examples.\n",
    "\n",
    "1. **Structuring free-text clinical notes**  \n",
    "\tClinical documents are mostly free text. NER can identify key concepts and turn them into structured fields, for example:\n",
    "\t- DISEASE: diabetes mellitus, hypertension, stasis ulcer  \n",
    "\t- SYMPTOM: chest pain, nausea, diarrhea  \n",
    "\t- BODY_PART: right ankle, abdomen  \n",
    "\t- PROCEDURE: surgery, CT scan  \n",
    "\tThis structured information can then be stored in an electronic health record or database and used for search, filtering, and statistics.\n",
    "\n",
    "2. **Clinical decision support**  \n",
    "\tNER outputs can be used as features in decision support systems. For example:\n",
    "\t- Combinations of DISEASE and SYMPTOM entities can be used to estimate the risk of certain conditions.\n",
    "\t- DRUG and DOSAGE entities can be checked for possible drug interactions or dosing errors.\n",
    "\tIn this way, NER acts as a bridge between narrative notes and automated clinical rules or prediction models.\n",
    "\n",
    "3. **Document and patient-level classification**  \n",
    "\tNER types can also improve text classification. Instead of using only bag-of-words, we can use counts and patterns of entities:\n",
    "\t- Classifying documents by specialty (e.g. cardiology vs. endocrinology) based on the diseases and body parts mentioned.\n",
    "\t- Detecting potential adverse drug events by looking for co-occurrences of specific DRUG and SYMPTOM entities.\n",
    "\tAt the patient level, the presence or absence of certain DISEASE entities can be used to define cohorts for research.\n",
    "\n",
    "4. **Relation extraction and knowledge graphs**  \n",
    "\tNER is the first step towards relation extraction, such as:\n",
    "\t- SYMPTOM–DISEASE relations (e.g. chest pain → myocardial infarction ruled out)\n",
    "\t- DRUG–DISEASE relations (indications)  \n",
    "\t- DRUG–SYMPTOM relations (adverse effects)  \n",
    "\tOnce entities are identified, these relations can be learned or manually defined, and combined into a clinical knowledge graph.\n",
    "\n",
    "5. **Question answering and summarisation**  \n",
    "\tFor question answering, knowing which spans are DISEASE or SYMPTOM helps focus retrieval on the relevant parts of a document. For summarisation, NER can be used to ensure that all important entities (diagnoses, symptoms, procedures, medications) appear explicitly in the final summary, even if the original note is long and repetitive.\n",
    "\n",
    "Overall, NER type information turns unstructured clinical text into more interpretable and reusable signals. Even a relatively noisy NER system can already provide useful features for downstream tasks such as decision support, classification, relation extraction, and summarisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbef8af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
