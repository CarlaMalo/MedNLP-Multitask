{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2340435",
   "metadata": {},
   "source": [
    "# Task 2: Data Exploration and Processing\n",
    "\n",
    "## 1. Manual data inspection\n",
    "- Investigate which standard and potential new NER types are most prominent in your data set (i.e., manual data inspection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45545326",
   "metadata": {},
   "source": [
    "Following visual inspection, some of the prominent NERs found are: DATE, BODY_PART, DOSAGE, MEASUREMENT, DRUG and SYMPTOM. \n",
    "\n",
    "Examples:\n",
    " 1. DATE: 12/20/2005, 1/19/96\n",
    " 2. BODY_PART: nose, abdomen, knee\n",
    " 3. DOSAGE:  10/40 mg one a day, 0.25 micrograms a day, 50 mg twice a day, 10 ml\n",
    " 4. MEASUREMENT: 3.98 kg, 8mm, pulse of 84, blood pressure 108/65\n",
    " 5. DRUG:  Vytorin, Rocaltrol, Carvedilol, Cozaar,  Lasix\n",
    " 6. SYMPTOM: erythematous, chest pain, constipated\n",
    "\n",
    "Where, DATE is a **standard NER in spacy** and the remaining ones fall in the medicine domain category. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf5702",
   "metadata": {},
   "source": [
    "## 2. Apply the standard NER classifier of spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4cb76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "## The following import is ignored as the annotations only need to be ran once, and they are already done\n",
    "# import utils.annotations_utils as utils_ann # ChatGPT API called to identify keywords/phrases associated with entities\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af4584a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f457d37",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "392028f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features available\n",
      "['text', 'inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'id', 'metadata', 'status', 'event_timestamp', 'metrics']\n",
      "Format of 'prediction' column\n",
      "List({'label': Value('string'), 'score': Value('float64')})\n",
      "Dataset length:  4966\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1: Load Dataset\n",
    "# ============================\n",
    "dataset = load_dataset(\"argilla/medical-domain\", split=\"train\")\n",
    "print(\"Features available\")\n",
    "print(dataset.column_names)\n",
    "print(\"Format of 'prediction' column\")\n",
    "print(dataset.features['prediction'])\n",
    "print(\"Dataset length: \", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5f52b",
   "metadata": {},
   "source": [
    "### Filter such that we keep only samples pertaining to 'Surgery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a8beaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n"
     ]
    }
   ],
   "source": [
    "dataset_slimmed = dataset.filter(\n",
    "\tlambda row: (\n",
    "\t\tisinstance(row[\"text\"], str)\n",
    "        and row[\"text\"] != ''\n",
    "\t\tand 'Surgery' in str(row[\"prediction\"][0])\n",
    "\t)\n",
    ")\n",
    "dataset = dataset_slimmed\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad783949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our NER schema =  ['SYMPTOM', 'BODY_PART', 'DISEASE', 'DRUG', 'ROUTE']\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 2: Define Entity Schema\n",
    "# ================================================\n",
    "# Our final gold-label schema\n",
    "CUSTOM_LABELS = ['SYMPTOM', 'BODY_PART', 'DISEASE', 'DRUG', 'ROUTE']\n",
    "\n",
    "print(\"Our NER schema = \", CUSTOM_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f45d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unannotated_samples.csv with 4 sentences\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3: Pick N samples manually\n",
    "# =========================================\n",
    "PATH_TO_ANNOTATIONS = \"ner/samples/\"\n",
    "SEED = 42 \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "N_SAMPLES = 4   # select a proper number to contain 100 ground-truth NERs \n",
    "sampled_texts = []\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "\trow = dataset[np.random.randint(0, len(dataset))]\n",
    "\ttext = row[\"text\"]\n",
    "\tsampled_texts.append(text)\n",
    "\n",
    "df_samples = pd.DataFrame({\"text\": sampled_texts})\n",
    "df_samples.to_csv(PATH_TO_ANNOTATIONS + \"unannotated_samples.csv\", index=False)\n",
    "\n",
    "print(\"Saved unannotated_samples.csv with\", len(df_samples), \"sentences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c1289",
   "metadata": {},
   "source": [
    "## 3. Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35f24",
   "metadata": {},
   "source": [
    "### Perform manual annotations, then split into train/test \n",
    "\n",
    " The annotation format is: \n",
    "\n",
    "\t{\n",
    "\t\t\"classes\": List(labels), \n",
    "\t\t\"annotations\": List(\n",
    "\t\t\t[str(text), dict(\"entities\": List(List(start idx, end idx, class)))]\n",
    "\t\t)\n",
    "\t}\n",
    "Where each item in \"annotations\" is a sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78713c24",
   "metadata": {},
   "source": [
    "#### Manual Annotations (with AI assistance)\n",
    "\n",
    "**NOTE: Skipping this section as unannotated_samples.csv, annotatated_samples\\*.json have already been generated.**\n",
    "\n",
    "Additionally, you will need a valid OpenAI API key in your environment variables to run this.\n",
    "\n",
    "Jump to [Train/Test splitting](#traintest-split-of-annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba636a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unannotated_samples_path = PATH_TO_ANNOTATIONS + \"unannotated_samples.csv\"\n",
    "# df = pd.read_csv(unannotated_samples_path, header=0)\n",
    "# text = df['text'].to_list()\n",
    "# num_examples_per_label = 30\n",
    "# annotations = utils_ann.chatgpt_annotate_text(CUSTOM_LABELS, text, num_examples_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7561c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Label: SYMPTOM =======\n",
      "[0, 'pain']\n",
      "[1, 'deformity']\n",
      "[2, 'dysfunction']\n",
      "[3, 'atrophy']\n",
      "[4, 'flexible talus']\n",
      "[5, 'motion changes']\n",
      "[6, 'sensation changes']\n",
      "[7, 'bleeding']\n",
      "[8, 'infection']\n",
      "[9, 'swelling']\n",
      "[10, 'muscular dystrophy']\n",
      "[11, 'hematoma']\n",
      "[12, 'thinning']\n",
      "[13, 'resection']\n",
      "[14, 'inflammation']\n",
      "[15, 'weakness']\n",
      "[16, 'sensitivity']\n",
      "[17, 'numbness']\n",
      "[18, 'impaired function']\n",
      "[19, 'low mobility']\n",
      "[20, 'tenderness']\n",
      "[21, 'ache']\n",
      "[22, 'limited motion']\n",
      "[23, 'stiffness']\n",
      "[24, 'difficulty']\n",
      "[25, 'irritation']\n",
      "[26, 'complications']\n",
      "[27, 'malalignment']\n",
      "[28, 'protrusion']\n",
      "[29, 'increased risk']\n",
      "====== Label: BODY_PART ======\n",
      "[0, 'foot']\n",
      "[1, 'arm']\n",
      "[2, 'forearm']\n",
      "[3, 'elbow']\n",
      "[4, 'mandible']\n",
      "[5, 'maxilla']\n",
      "[6, 'leg']\n",
      "[7, 'shoulder']\n",
      "[8, 'talocalcaneal joint']\n",
      "[9, 'extremity']\n",
      "[10, 'muscle']\n",
      "[11, 'thigh']\n",
      "[12, 'spine']\n",
      "[13, 'sinus']\n",
      "[14, 'upper limb']\n",
      "[15, 'arm']\n",
      "[16, 'heel']\n",
      "[17, 'lower surface']\n",
      "[18, 'biceps']\n",
      "[19, 'nerve']\n",
      "[20, 'foot arch']\n",
      "[21, 'vein']\n",
      "[22, 'artery']\n",
      "[23, 'bone']\n",
      "[24, 'palate']\n",
      "[25, 'buttock']\n",
      "[26, 'cavity']\n",
      "[27, 'genial tubercle']\n",
      "[28, 'mental foramina']\n",
      "[29, 'soft tissue']\n",
      "======= Label: DISEASE =======\n",
      "[0, 'end-stage renal disease']\n",
      "[1, 'myotonic muscular dystrophy']\n",
      "[2, 'planovalgus']\n",
      "[3, 'mandibular atrophy']\n",
      "[4, 'maxillary atrophy']\n",
      "[5, 'facial deformity']\n",
      "[6, 'masticatory dysfunction']\n",
      "[7, 'acquired deformity']\n",
      "[8, 'vertical talus']\n",
      "[9, 'implant failure']\n",
      "[10, 'hip fracture']\n",
      "[11, 'infection']\n",
      "[12, 'anterior mandibular atrophy']\n",
      "[13, 'arthrodesis indication']\n",
      "[14, 'release complications']\n",
      "[15, 'mandibular deficiency']\n",
      "[16, 'surgical failure']\n",
      "[17, 'hemorrhage']\n",
      "[18, 'graft complications']\n",
      "[19, 'suture complications']\n",
      "[20, 'pneumonia']\n",
      "[21, 'urinary infection']\n",
      "[22, 'anesthetic reaction']\n",
      "[23, 'scarring']\n",
      "[24, 'paralysis risk']\n",
      "[25, 'neuralgia']\n",
      "[26, 'edema']\n",
      "[27, 'stump neuroma']\n",
      "[28, 'fatigue syndrome']\n",
      "[29, 'hypoxia']\n",
      "======== Label: DRUG =========\n",
      "[0, 'Marcaine']\n",
      "[1, 'Ancef']\n",
      "[2, 'Xylocaine']\n",
      "[3, 'source anesthetics']\n",
      "[4, 'epinephrine']\n",
      "[5, 'Prolene']\n",
      "[6, 'Vicryl']\n",
      "[7, 'Monocryl']\n",
      "[8, 'citrate plasma']\n",
      "[9, 'normal saline']\n",
      "[10, 'AlloDerm']\n",
      "[11, 'nestim']\n",
      "[12, 'antibiotic']\n",
      "[13, 'anesthetic']\n",
      "[14, 'collagen']\n",
      "[15, 'suture']\n",
      "[16, 'antiseptic']\n",
      "[17, 'silibinin']\n",
      "[18, 'metronidazole']\n",
      "[19, 'bupivacaine']\n",
      "[20, 'sclerotherapy']\n",
      "[21, 'renatec']\n",
      "[22, 'analgesic']\n",
      "[23, 'dexmedetomidine']\n",
      "[24, 'riluzole']\n",
      "[25, 'lidocaine']\n",
      "[26, 'NSAIDs']\n",
      "[27, 'anticoagulant']\n",
      "[28, 'sedation']\n",
      "[29, 'tetrahydrocannabinol']\n",
      "======== Label: ROUTE ========\n",
      "[0, 'nasal intubation']\n",
      "[1, 'oral administration']\n",
      "[2, 'injection']\n",
      "[3, 'catheter']\n",
      "[4, 'intravenous']\n",
      "[5, 'local infiltration']\n",
      "[6, 'isotope']\n",
      "[7, 'topical']\n",
      "[8, 'oral']\n",
      "[9, 'venous']\n",
      "[10, 'subcutaneous']\n",
      "[11, 'epidural']\n",
      "[12, 'peritoneal']\n",
      "[13, 'gastrostomy']\n",
      "[14, 'nebulization']\n",
      "[15, 'intramuscular']\n",
      "[16, 'transdermal']\n",
      "[17, 'sciatic']\n",
      "[18, 'sublingual']\n",
      "[19, 'neboulizer']\n",
      "[20, 'end-artery']\n",
      "[21, 'gluteal']\n",
      "[22, 'subdermal']\n",
      "[23, 'intradermal']\n",
      "[24, 'parenteral']\n",
      "[25, 'intranasal']\n",
      "[26, 'subcortical']\n",
      "[27, 'endotracheal']\n",
      "[28, 'through skin']\n",
      "[29, 'intraoral']\n"
     ]
    }
   ],
   "source": [
    "# for label in annotations.keys():\n",
    "# \tprint(f\" Label: {label} \".center(30, '='))\n",
    "# \tfor indexed_words in annotations[label]:\n",
    "# \t\tprint(indexed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Label: SYMPTOM =======\n",
      "pain\n",
      "deformity\n",
      "dysfunction\n",
      "atrophy\n",
      "flexible talus\n",
      "motion changes\n",
      "sensation changes\n",
      "bleeding\n",
      "infection\n",
      "swelling\n",
      "muscular dystrophy\n",
      "hematoma\n",
      "thinning\n",
      "resection\n",
      "inflammation\n",
      "weakness\n",
      "sensitivity\n",
      "numbness\n",
      "impaired function\n",
      "low mobility\n",
      "tenderness\n",
      "ache\n",
      "limited motion\n",
      "stiffness\n",
      "difficulty\n",
      "irritation\n",
      "complications\n",
      "malalignment\n",
      "protrusion\n",
      "====== Label: BODY_PART ======\n",
      "foot\n",
      "arm\n",
      "forearm\n",
      "elbow\n",
      "mandible\n",
      "maxilla\n",
      "leg\n",
      "shoulder\n",
      "joint\n",
      "extremity\n",
      "muscle\n",
      "thigh\n",
      "spine\n",
      "sinus\n",
      "limb\n",
      "arm\n",
      "heel\n",
      "biceps\n",
      "nerve\n",
      "foot arch\n",
      "vein\n",
      "artery\n",
      "bone\n",
      "palate\n",
      "buttock\n",
      "cavity\n",
      "genial tubercle\n",
      "mental foramina\n",
      "soft tissue\n",
      "======= Label: DISEASE =======\n",
      "renal disease\n",
      "myotonic muscular dystrophy\n",
      "planovalgus\n",
      "mandibular atrophy\n",
      "maxillary atrophy\n",
      "facial deformity\n",
      "masticatory dysfunction\n",
      "acquired deformity\n",
      "vertical talus\n",
      "implant failure\n",
      "hip fracture\n",
      "infection\n",
      "anterior mandibular atrophy\n",
      "arthrodesis indication\n",
      "release complications\n",
      "mandibular deficiency\n",
      "surgical failure\n",
      "hemorrhage\n",
      "graft complications\n",
      "suture complications\n",
      "pneumonia\n",
      "urinary infection\n",
      "anesthetic reaction\n",
      "scarring\n",
      "paralysis risk\n",
      "neuralgia\n",
      "edema\n",
      "stump neuroma\n",
      "fatigue syndrome\n",
      "hypoxia\n",
      "======== Label: DRUG =========\n",
      "Marcaine\n",
      "Ancef\n",
      "Xylocaine\n",
      "anesthetics\n",
      "epinephrine\n",
      "Prolene\n",
      "Vicryl\n",
      "Monocryl\n",
      "citrate plasma\n",
      "saline\n",
      "AlloDerm\n",
      "nestim\n",
      "antibiotic\n",
      "anesthetic\n",
      "collagen\n",
      "suture\n",
      "antiseptic\n",
      "silibinin\n",
      "metronidazole\n",
      "bupivacaine\n",
      "sclerotherapy\n",
      "renatec\n",
      "analgesic\n",
      "dexmedetomidine\n",
      "riluzole\n",
      "lidocaine\n",
      "NSAIDs\n",
      "anticoagulant\n",
      "tetrahydrocannabinol\n",
      "======== Label: ROUTE ========\n",
      "nasal intubation\n",
      "oral administration\n",
      "injection\n",
      "catheter\n",
      "intravenous\n",
      "local infiltration\n",
      "topical\n",
      "oral\n",
      "venous\n",
      "subcutaneous\n",
      "epidural\n",
      "peritoneal\n",
      "gastrostomy\n",
      "nebulization\n",
      "intramuscular\n",
      "transdermal\n",
      "sublingual\n",
      "neboulizer\n",
      "end-artery\n",
      "gluteal\n",
      "subdermal\n",
      "intradermal\n",
      "parenteral\n",
      "intranasal\n",
      "subcortical\n",
      "endotracheal\n",
      "through skin\n",
      "intraoral\n"
     ]
    }
   ],
   "source": [
    "# # Specify examples to exclude or modify\n",
    "# # NOTE: pop larger indices first to maintain index ordering of earlier items after deletion\n",
    "# annotations['SYMPTOM'].pop(29)\n",
    "\n",
    "# annotations['BODY_PART'][8][1] = 'joint'\n",
    "# annotations['BODY_PART'][14][1] = 'limb'\n",
    "# annotations['BODY_PART'].pop(17)\n",
    "\n",
    "# annotations['DISEASE'][0][1] = 'renal disease'\n",
    "\n",
    "# annotations['DRUG'][3][1] = 'anesthetics'\n",
    "# annotations['DRUG'][9][1] = 'saline'\n",
    "# annotations['DRUG'].pop(28)\n",
    "\n",
    "# annotations['ROUTE'].pop(17)\n",
    "# annotations['ROUTE'].pop(6)\n",
    "\n",
    "# for label in annotations.keys():\n",
    "# \tprint(f\" Label: {label} \".center(30, '='))\n",
    "# \twords_list = []\n",
    "# \tfor idx, word in annotations[label]:\n",
    "# \t\twords_list.append(word)\n",
    "# \t\tprint(word)\n",
    "# \tannotations[label] = words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d8646",
   "metadata": {},
   "source": [
    "#### Save annotations to the appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Load samples: only column \"text\"\n",
    "# df = pd.read_csv(unannotated_samples_path)\n",
    "\n",
    "# # 2. Load spaCy for sentence splitting\n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "# if \"sentencizer\" not in nlp.pipe_names:\n",
    "# \tnlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# # 3. Extract all sentences across samples\n",
    "# all_sentences = []\n",
    "# for _, row in df.iterrows():\n",
    "# \tfull_text = str(row[\"text\"])\n",
    "# \tdoc = nlp(full_text)\n",
    "\n",
    "# \t# Extract sentences\n",
    "# \tall_sentences.extend([s.text.strip() for s in doc.sents if len(s.text.strip()) > 0])\n",
    "\n",
    "# # 4. Annotate all identified keywords in sentences and save to json file\n",
    "# utils_ann.annotate_sentences_and_save(all_sentences, annotations, CUSTOM_LABELS, PATH_TO_ANNOTATIONS+'annotated_samples.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dfcb8",
   "metadata": {},
   "source": [
    "### Train/Test split of annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c697b5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Train samples:  84\n",
      "N Test samples:  36\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Generate train/test annotation template JSONL with ratio control\n",
    "# ============================================\n",
    "annotated_samples_path = PATH_TO_ANNOTATIONS + \"annotated_samples.json\"\n",
    "\n",
    "# =====================================================\n",
    "# Parameters: control split ratio (sentence-wise split)\n",
    "# =====================================================\n",
    "TRAIN_RATIO = 0.70     # first 70% for training\n",
    "TEST_RATIO  = 0.30     # first 30% for evaluation/test\n",
    "\n",
    "# ================================\n",
    "\n",
    "# Load annotated samples: only key \"annotations\"\n",
    "annotations_dict = None\n",
    "with open(annotated_samples_path) as annotations_file:\n",
    "\tannotations_dict = json.load(annotations_file)\n",
    "all_sentences = annotations_dict[\"annotations\"]\n",
    "\n",
    "# ===========================\n",
    "# Create train/test sets\n",
    "# ===========================\n",
    "\n",
    "np.random.shuffle(all_sentences) # shuffle randomly first before splitting\n",
    "total = len(all_sentences)\n",
    "train_cutoff = int(total * TRAIN_RATIO)\n",
    "test_cutoff = train_cutoff + int(total * TEST_RATIO)\n",
    "\n",
    "train_sentences = all_sentences[:train_cutoff]\n",
    "test_sentences = all_sentences[train_cutoff:test_cutoff]\n",
    "\n",
    "print(\"N Train samples: \", len(train_sentences))\n",
    "print(\"N Test samples: \", len(test_sentences))\n",
    "# ===========================\n",
    "# Save sentences into train/test\n",
    "# ===========================\n",
    "train_samples_path = PATH_TO_ANNOTATIONS + 'annotated_samples_train.json'\n",
    "annotations_dict['annotations'] = train_sentences\n",
    "with open(train_samples_path, 'w') as fp:\n",
    "\tjson.dump(annotations_dict, fp)\n",
    "\n",
    "test_samples_path = PATH_TO_ANNOTATIONS + 'annotated_samples_test.json'\n",
    "annotations_dict['annotations'] = test_sentences\n",
    "with open(test_samples_path, 'w') as fp:\n",
    "\tjson.dump(annotations_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d519d",
   "metadata": {},
   "source": [
    "### 3.1 Manual Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Text Preview ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">All sponges were counted encountered for as were sutures.This was sutured using \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "-0The tissues were stretched with tissue scissors and then a high speed instrumentation was used to decorticate the anterior mandible using a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1.6 mm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " twist drill and a pear shaped bur was used in the posterior region to begin original exploratory phenomenon of repair.He is to follow up in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the next 10 days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " for a check.,PROCEDURE: , Bilateral Crawford subtalar arthrodesis with open \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Achilles Z\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "-lengthening and bilateral long-leg cast.X and company accompanied the patient to OR #\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " at 7:30 a.m.1% \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Xylocaine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1:100,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " epinephrine was infiltrated in the labial mucosa 5 cc were given.The hard palate was directly observed.Once the foot was reduced a \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steinman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " pin was used to hold it in position.The patient was subsequently was taken to Recovery in stable condition.The contents of the neurovascular canal from the greater \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    palatine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " foramina were identified.The wound was irrigated with normal saline.Release incisions were made in the posterior region of the maxilla.Particulate bone was then injected into the posterior tunnels bilaterally.Bilateral long-leg casts were then placed with the foot in neutral with some moulding of his medial plantar arch.Acquired facial deformity.Bilateral nonsterile tourniquets were placed on each thigh.,SPECIMENS: , None.,HARDWARE,POSTOPERATIVE PLAN: , The patient will be hospitalized \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    overnight\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " for pain as per parents' request.PREOPERATIVE DIAGNOSES:,1.A block of bone was inserted between the mental foramina and fixative with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three 16 cm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " screws \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " with a twist drill then followed with self-tapping \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2 mm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " diameter titanium screws.The ankle was taken through a range of motion with noted improvement in the reduction of the talocalcaneal alignment with the foot in plantar flexion on the lateral view.All questions were answered and the mother agreed to the above plan.,PROCEDUREA similar procedure was done on the contralateral side.The estimated blood loss in the intraoral procedure was \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    220\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cc.  Total blood loss for the procedure \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    320\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cc.DIAGNOSIS,End-stage renal disease.The wound was cleaned and dried, dressed with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steri-Strips\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Xeroform\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " x \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Webril\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".USED: , \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Staple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    7/8 inch\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " x1 on each side.,PROCEDURE,\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Venogram\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " of the left arm and creation of left brachiocephalic arteriovenous fistula.He has been having significant feet pain with significant planovalgus deformity.A primary incision was made between the mental foramina and the residual crest of the ridge and reflected \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " to the lingual area observing the superior genial tubercle in the facial area degloving the mentalis muscle and exposing the anterior body.A piece of \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AlloDerm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " mixed with \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Croften\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and patient's platelet-rich plasma, which was centrifuged from drawing \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    20\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cc of blood was then mixed together and placed over the lateral aspect of the block.A primary incision was made in the maxilla starting on the patient's left tuberosity region along the crest of the residual ridge to the contralateral side in similar fashion.The urine out 180.,3.Xylocaine \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1:100,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " epinephrine \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    7 ml\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " was infiltrated into the labial and palatal mucosa.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Manual Evaluation of Standard NER\n",
    "from spacy import displacy\n",
    "\n",
    "# !python -m spacy download en_core_web_sm # NOTE run if needed\n",
    "\n",
    "# If we jump here directly, we need a definition of test_samples_path\n",
    "test_samples_path = PATH_TO_ANNOTATIONS + 'annotated_samples_test.json'\n",
    "\n",
    "# 1. Load sample text\n",
    "annotations_dict = None\n",
    "with open(test_samples_path) as annotations_file:\n",
    "\tannotations_dict = json.load(annotations_file)\n",
    "\t\n",
    "# 2. Extract second row text\n",
    "test_text = [sent for sent, _ in annotations_dict[\"annotations\"]]\n",
    "\n",
    "print(\"=== Test Text Preview ===\")\n",
    "\n",
    "# 3. Load spaCy model (baseline or your updated one)\n",
    "nlp = spacy.load(\"en_core_web_md\")   # or: spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# 4. Run NER on the full document\n",
    "doc = nlp(''.join(test_text[:2000]))\n",
    "\n",
    "# 5. Render using displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24f233",
   "metadata": {},
   "source": [
    "Observation: Some NERs don't make sense. E.g., Vomitting -> PERSON, Hypokalemia -> PERSON, Diarrhea -> PERSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c109e22",
   "metadata": {},
   "source": [
    "### 3.2 Automatic Evaluation of Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f0360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36 annotated sentences\n",
      "True labels\n",
      " ['DRUG', 'DRUG', 'NONE', 'BODY_PART', 'NONE', 'NONE', 'BODY_PART', 'NONE', 'NONE', 'NONE', 'DRUG', 'DRUG', 'NONE', 'NONE', 'BODY_PART', 'BODY_PART', 'NONE', 'NONE', 'DRUG', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'DISEASE', 'BODY_PART', 'SYMPTOM', 'NONE', 'BODY_PART', 'BODY_PART', 'NONE', 'NONE', 'NONE', 'BODY_PART', 'ROUTE', 'NONE', 'NONE', 'DISEASE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'ROUTE', 'NONE', 'SYMPTOM', 'DISEASE', 'SYMPTOM', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'NONE', 'DRUG', 'NONE', 'NONE', 'BODY_PART', 'NONE', 'NONE', 'DRUG', 'DRUG', 'NONE', 'NONE', 'NONE']\n",
      "pred\n",
      " ['NONE', 'NONE', 'CARDINAL', 'NONE', 'QUANTITY', 'DATE', 'NONE', 'PERSON', 'MONEY', 'TIME', 'PERSON', 'NONE', 'PERCENT', 'CARDINAL', 'NONE', 'NONE', 'PERSON', 'GPE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'TIME', 'NONE', 'NONE', 'QUANTITY', 'ORDINAL', 'QUANTITY', 'NONE', 'NONE', 'CARDINAL', 'CARDINAL', 'NONE', 'ORG', 'GPE', 'CARDINAL', 'CARDINAL', 'DATE', 'ORG', 'QUANTITY', 'NONE', 'ORG', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'ORDINAL', 'PRODUCT', 'PERSON', 'CARDINAL', 'NONE', 'CARDINAL', 'CARDINAL', 'PERSON', 'NONE', 'PERCENT', 'CARDINAL', 'QUANTITY']\n",
      "sent ids\n",
      " [0, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 6, 6, 7, 8, 8, 10, 11, 12, 13, 14, 14, 15, 16, 18, 18, 20, 20, 20, 20, 20, 21, 24, 24, 24, 25, 26, 26, 26, 26, 26, 27, 27, 28, 28, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 32, 33, 34, 35, 35, 35, 35, 35]\n",
      "\n",
      "===== Baseline spaCy NER Evaluation =====\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 score:  0.0000\n",
      "\n",
      "Macro Precision: 0.0\n",
      "Macro Recall:    0.0\n",
      "Macro F1:        0.0\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: All sponges were counted encountered for as were sutures.\n",
      "Gold: [[49, 55, 'DRUG']]\n",
      "Pred: []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Standard NER evaluation\n",
    "# =========================================\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from ner.utils import extract_spans, get_label_lists, remove_overlapping_spans\n",
    "\n",
    "# 1. Load JSON annotations\n",
    "test_annotations_path = PATH_TO_ANNOTATIONS + \"annotated_samples_test.json\"\n",
    "\n",
    "sentences = None # will become a list of sentences\n",
    "gold_spans = None # will become a nested list of 1 list per sentence, containing a list of [start, end, label]\n",
    "with open(test_annotations_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tannotations_dict = json.load(f)\n",
    "\tsentences = [sent for sent, _ in annotations_dict[\"annotations\"]]\n",
    "\tgold_spans = [entities_dict[\"entities\"] for _, entities_dict in annotations_dict[\"annotations\"]]\n",
    "\n",
    "# Remove overlapping spans in gold if any\n",
    "gold_spans = remove_overlapping_spans(gold_spans)\n",
    "print(f\"Loaded {len(sentences)} annotated sentences\")\n",
    "\n",
    "# 2. Load baseline spaCy NER\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# 3. Convert annotations to character-level spans\n",
    "pred_spans = extract_spans(nlp, sentences)\n",
    "\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "true_labels, pred_labels, associated_sentence_idx = get_label_lists(gold_spans, pred_spans)\n",
    "\n",
    "# 5. Evaluate macro and micro F1\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Baseline spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "# 6. Show some error cases\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "for sent_id, (g, p) in enumerate(zip(gold_spans, pred_spans)):\n",
    "    if g != p:\n",
    "        print(\"Text:\", sentences[sent_id])\n",
    "        print(\"Gold:\", g)\n",
    "        print(\"Pred:\", p)\n",
    "        print(\"-\" * 50)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26c084",
   "metadata": {},
   "source": [
    "## 4. Extend the standard NER types using the NER Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b2181",
   "metadata": {},
   "source": [
    "### 4.1 Training Extended NER model with >100 manual annoatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5d44df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 84 annotated sentences\n",
      "Custom NER labels: ['SYMPTOM', 'BODY_PART', 'DISEASE', 'DRUG', 'ROUTE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/cm24m059/.conda/envs/task3-nlp/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Then, CAT scan models were used to find tune and a...\" with entities \"[[89, 96, 'BODY_PART']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/cm24m059/.conda/envs/task3-nlp/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The tissues were expanded then with a tissue Metze...\" with entities \"[[205, 211, 'DRUG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/cm24m059/.conda/envs/task3-nlp/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The sinus tarsi was then identified using a U-shap...\" with entities \"[[4, 9, 'BODY_PART'], [66, 72, 'BODY_PART']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/cm24m059/.conda/envs/task3-nlp/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The wound was closed in layers with PDS sutures.\" with entities \"[[40, 46, 'DRUG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/cm24m059/.conda/envs/task3-nlp/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The periosteal flap was sutured over the staple us...\" with entities \"[[24, 30, 'DRUG'], [58, 64, 'DRUG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/cm24m059/.conda/envs/task3-nlp/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Nasal trachea intubation was performed per routine...\" with entities \"[[8, 12, 'SYMPTOM']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35 Loss: {'ner': np.float32(1041.892)}\n",
      "Epoch 2/35 Loss: {'ner': np.float32(225.54295)}\n",
      "Epoch 3/35 Loss: {'ner': np.float32(137.1597)}\n",
      "Epoch 4/35 Loss: {'ner': np.float32(123.322716)}\n",
      "Epoch 5/35 Loss: {'ner': np.float32(109.891365)}\n",
      "Epoch 6/35 Loss: {'ner': np.float32(90.60601)}\n",
      "Epoch 7/35 Loss: {'ner': np.float32(65.43597)}\n",
      "Epoch 8/35 Loss: {'ner': np.float32(49.277184)}\n",
      "Epoch 9/35 Loss: {'ner': np.float32(41.314453)}\n",
      "Epoch 10/35 Loss: {'ner': np.float32(30.830793)}\n",
      "Epoch 11/35 Loss: {'ner': np.float32(34.150513)}\n",
      "Epoch 12/35 Loss: {'ner': np.float32(28.016462)}\n",
      "Epoch 13/35 Loss: {'ner': np.float32(20.584805)}\n",
      "Epoch 14/35 Loss: {'ner': np.float32(11.637852)}\n",
      "Epoch 15/35 Loss: {'ner': np.float32(9.644718)}\n",
      "Epoch 16/35 Loss: {'ner': np.float32(4.12778)}\n",
      "Epoch 17/35 Loss: {'ner': np.float32(2.430256)}\n",
      "Epoch 18/35 Loss: {'ner': np.float32(1.5563459)}\n",
      "Epoch 19/35 Loss: {'ner': np.float32(0.48532856)}\n",
      "Epoch 20/35 Loss: {'ner': np.float32(1.9009217)}\n",
      "Epoch 21/35 Loss: {'ner': np.float32(1.1920818)}\n",
      "Epoch 22/35 Loss: {'ner': np.float32(0.011981303)}\n",
      "Epoch 23/35 Loss: {'ner': np.float32(0.0010854391)}\n",
      "Epoch 24/35 Loss: {'ner': np.float32(0.8581937)}\n",
      "Epoch 25/35 Loss: {'ner': np.float32(0.017427096)}\n",
      "Epoch 26/35 Loss: {'ner': np.float32(0.10523638)}\n",
      "Epoch 27/35 Loss: {'ner': np.float32(0.00014758238)}\n",
      "Epoch 28/35 Loss: {'ner': np.float32(0.0004286189)}\n",
      "Epoch 29/35 Loss: {'ner': np.float32(0.10573649)}\n",
      "Epoch 30/35 Loss: {'ner': np.float32(0.00030589692)}\n",
      "Epoch 31/35 Loss: {'ner': np.float32(0.0076977457)}\n",
      "Epoch 32/35 Loss: {'ner': np.float32(0.00021868089)}\n",
      "Epoch 33/35 Loss: {'ner': np.float32(1.3976159e-05)}\n",
      "Epoch 34/35 Loss: {'ner': np.float32(0.5803483)}\n",
      "Epoch 35/35 Loss: {'ner': np.float32(0.00044752576)}\n",
      "Model saved to output_medical_ner\n",
      "\n",
      "Test sentence: Once the foot was reduced a Steinman pin was used to hold it in position.\n",
      "Predicted NER: [('foot', 'BODY_PART')]\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Extended NER TRAINING\n",
    "# =========================================\n",
    "\n",
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# 1. Load annotated JSONL\n",
    "json_path = PATH_TO_ANNOTATIONS + \"annotated_samples_train.json\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tannotations_dict = json.load(f)\n",
    "\ttraining_examples = annotations_dict[\"annotations\"]\n",
    "\t\n",
    "# Remove overlapping spans in training examples\n",
    "training_examples = remove_overlapping_spans(training_examples, is_annotations_list=True)\n",
    "print(f\"Loaded {len(training_examples)} annotated sentences\")\n",
    "\n",
    "# 2. Custom labels\n",
    "CUSTOM_LABELS = [\"SYMPTOM\", \"BODY_PART\", \"DISEASE\", \"DRUG\", \"ROUTE\"]\n",
    "assert annotations_dict['classes'] == CUSTOM_LABELS\n",
    "print(\"Custom NER labels:\", CUSTOM_LABELS)\n",
    "\n",
    "# 3. Initialize blank model for spaCy 3.8+\n",
    "nlp = spacy.blank(\"en\")         \n",
    "ner = nlp.add_pipe(\"ner\")       \n",
    "\n",
    "# Add custom labels\n",
    "for label in CUSTOM_LABELS:\n",
    "\tner.add_label(label)\n",
    "\n",
    "# 5. Training loop\n",
    "n_iter = 35\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "\trandom.shuffle(training_examples)\n",
    "\tlosses = {}\n",
    "\n",
    "\tbatches = minibatch(training_examples, size=compounding(4.0, 32.0, 1.5))\n",
    "\n",
    "\tfor batch in batches:\n",
    "\t\texamples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in batch]\n",
    "\t\tnlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)\n",
    "\n",
    "\tprint(f\"Epoch {epoch+1}/{n_iter} Loss: {losses}\")\n",
    "\n",
    "# 6. Save model\n",
    "output_dir = \"output_medical_ner\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Model saved to\", output_dir)\n",
    "\n",
    "# 7. Quick sanity check\n",
    "test_text = random.choice(sentences)\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"\\nTest sentence:\", test_text)\n",
    "print(\"Predicted NER:\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229beae",
   "metadata": {},
   "source": [
    "### 4.2 Extended NER Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36d2a3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36 annotated sentences\n",
      "True labels\n",
      " ['DRUG', 'DRUG', 'BODY_PART', 'BODY_PART', 'DRUG', 'DRUG', 'BODY_PART', 'BODY_PART', 'DRUG', 'BODY_PART', 'NONE', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'DISEASE', 'BODY_PART', 'SYMPTOM', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'ROUTE', 'DISEASE', 'ROUTE', 'SYMPTOM', 'DISEASE', 'SYMPTOM', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'DRUG', 'BODY_PART', 'DRUG', 'DRUG']\n",
      "pred\n",
      " ['NONE', 'NONE', 'BODY_PART', 'BODY_PART', 'DRUG', 'NONE', 'NONE', 'BODY_PART', 'NONE', 'BODY_PART', 'ROUTE', 'BODY_PART', 'BODY_PART', 'BODY_PART', 'DISEASE', 'NONE', 'NONE', 'BODY_PART', 'NONE', 'BODY_PART', 'ROUTE', 'DISEASE', 'NONE', 'NONE', 'DISEASE', 'NONE', 'NONE', 'NONE', 'NONE', 'DRUG', 'BODY_PART', 'NONE', 'NONE']\n",
      "sent ids\n",
      " [0, 1, 2, 4, 6, 6, 7, 8, 11, 12, 12, 13, 14, 14, 15, 16, 18, 20, 20, 21, 24, 25, 28, 29, 29, 29, 30, 30, 30, 31, 32, 35, 35]\n",
      "\n",
      "===== Extended spaCy NER Evaluation =====\n",
      "Precision: 0.9412\n",
      "Recall:    0.5000\n",
      "F1 score:  0.6531\n",
      "\n",
      "Macro Precision: 0.7\n",
      "Macro Recall:    0.475\n",
      "Macro F1:        0.5338\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: All sponges were counted encountered for as were sutures.\n",
      "Gold: [[49, 55, 'DRUG']]\n",
      "Pred: []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  Extended NER evaluation with test sample\n",
    "# =========================================\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from ner.utils import extract_spans, get_label_lists, remove_overlapping_spans\n",
    "\n",
    "# 1. Load JSONL annotations for test\n",
    "test_annotations_path = PATH_TO_ANNOTATIONS + \"annotated_samples_test.json\"\n",
    "\n",
    "sentences = None # will become a list of sentences\n",
    "gold_spans = None # will become a nested list of 1 list per sentence, containing a list of [start, end, label]\n",
    "with open(test_annotations_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\tannotations_dict = json.load(f)\n",
    "\tsentences = [sent for sent, _ in annotations_dict[\"annotations\"]]\n",
    "\tgold_spans = [entities_dict[\"entities\"] for _, entities_dict in annotations_dict[\"annotations\"]]\n",
    "\n",
    "# Remove overlapping spans in gold if any\n",
    "gold_spans = remove_overlapping_spans(gold_spans)\n",
    "print(f\"Loaded {len(sentences)} annotated sentences\")\n",
    "\n",
    "# 2. Load Extended spaCy NER\n",
    "nlp = spacy.load(\"output_medical_ner\")\n",
    "\n",
    "# 3. Convert annotations to character-level spans\n",
    "pred_spans = extract_spans(nlp, sentences)\n",
    "\n",
    "# 4. Convert spans to entity sets for evaluation\n",
    "true_labels, pred_labels, associated_sentence_idx = get_label_lists(gold_spans, pred_spans)\n",
    "# 5. Evaluate macro and micro F1\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, labels=CUSTOM_LABELS, average=\"micro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n===== Extended spaCy NER Evaluation =====\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "\ttrue_labels, pred_labels, labels=CUSTOM_LABELS, average=\"macro\", zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nMacro Precision:\", round(prec_m, 4))\n",
    "print(\"Macro Recall:   \", round(rec_m, 4))\n",
    "print(\"Macro F1:       \", round(f1_m, 4))\n",
    "\n",
    "# 6. Show some error cases\n",
    "print(\"\\n===== Examples of WRONG predictions =====\\n\")\n",
    "\n",
    "for sent_id, (g, p) in enumerate(zip(gold_spans, pred_spans)):\n",
    "    if g != p:\n",
    "        print(\"Text:\", sentences[sent_id])\n",
    "        print(\"Gold:\", g)\n",
    "        print(\"Pred:\", p)\n",
    "        print(\"-\" * 50)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed847e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- The performance is poor as the train and test data sets are not in the same category, and therefore don't share big enough NER vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f3059d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Checking Exact Leakage =====\n",
      "EXACT LEAKAGE FOUND:\n",
      " - Acquired facial deformity.\n",
      " - ,3.\n",
      "\n",
      "===== Checking Substring Leakage =====\n",
      "SUBSTRING LEAKAGE FOUND:\n",
      " - Acquired facial deformity.\n",
      " - DIAGNOSIS,End-stage renal disease.\n",
      " - ,3.\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "#  DETECT TRAIN/TEST DATA LEAKAGE\n",
    "# =========================================\n",
    "\n",
    "# Load train sentences\n",
    "train_json = PATH_TO_ANNOTATIONS + \"annotated_samples_train.json\"\n",
    "with open(train_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "train_sentences = [text for text, _ in train_data[\"annotations\"]]\n",
    "\n",
    "# Load test sentences\n",
    "test_json = PATH_TO_ANNOTATIONS + \"annotated_samples_test.json\"\n",
    "with open(test_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "test_sentences = [text for text, _ in test_data[\"annotations\"]]\n",
    "\n",
    "# Exact-match leakage\n",
    "print(\"\\n===== Checking Exact Leakage =====\")\n",
    "leak_exact = []\n",
    "for t in test_sentences:\n",
    "    if t in train_sentences:\n",
    "        leak_exact.append(t)\n",
    "\n",
    "if leak_exact:\n",
    "    print(\"EXACT LEAKAGE FOUND:\")\n",
    "    for s in leak_exact:\n",
    "        print(\" -\", s)\n",
    "else:\n",
    "    print(\"No exact leakage.\")\n",
    "\n",
    "\n",
    "# Substring leakage (weaker but still harmful)\n",
    "print(\"\\n===== Checking Substring Leakage =====\")\n",
    "leak_sub = []\n",
    "for test_s in test_sentences:\n",
    "    for train_s in train_sentences:\n",
    "        if test_s.strip() in train_s.strip() or train_s.strip() in test_s.strip():\n",
    "            leak_sub.append(test_s)\n",
    "            break\n",
    "\n",
    "if leak_sub:\n",
    "    print(\"SUBSTRING LEAKAGE FOUND:\")\n",
    "    for s in leak_sub:\n",
    "        print(\" -\", s)\n",
    "else:\n",
    "    print(\"No substring leakage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa558d",
   "metadata": {},
   "source": [
    "## 5. LLM-based NER classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6a5a4",
   "metadata": {},
   "source": [
    "The goal of this part was to see whether a large language model (LLM) could be used as an alternative NER system for my medical text, using only prompts and without training a new model. In practice, we tried several approaches, but all of them were limited by model size, hardware, or missing API access.\n",
    "\n",
    "First, we tried a very small local LLM (about 0.5B parameters) via `llama-cpp`. we asked it to extract entities with my label set (DISEASE, SYMPTOM, BODY_PART, FINDING, PROCEDURE) and return a JSON list. The model usually failed to follow the format and, more importantly, produced almost random labels that did not make medical sense. This suggests that such a small model is not strong enough for domain-specific NER, even with an instruction-style prompt.\n",
    "\n",
    "Second, we tried to use a slightly larger open-source LLM from Hugging Face (e.g. Qwen2.5-1.5B or Llama-3.2-1B) on my macOS machine via the `transformers` library. We implemented a function that builds a medical NER prompt and parses the model output into (phrase, label) pairs. However, even for one or two short sentences, generation on CPU/MPS took several minutes. Running this model on all test sentences to compute precision, recall and F1 would be impractically slow for this project.\n",
    "\n",
    "Third, we looked at the spaCy-LLM integration. In theory, we could define an `llm` component in a `config.cfg` file, for example using a Llama2 model on Hugging Face, and then assemble it as a normal spaCy pipeline. In practice, this either requires access to an external API (e.g. OpenAI) or downloading and running a much larger model (such as Llama2-7B). we have no API credits available and my local hardware is not sufficient to run such a model efficiently.\n",
    "\n",
    "Because of these limitations, we did not manage to build a fully working and scalable LLM-based NER baseline. Our investigation of LLM-based NER is therefore mainly conceptual: we explored how it would be prompted and integrated (with transformers or spaCy-LLM), and we observed that under my resource constraints it is not yet practical to use an LLM as a reliable, evaluated medical NER system. For the quantitative results in this project, we rely on the standard spaCy NER and my extended, manually trained medical NER model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338a0fa",
   "metadata": {},
   "source": [
    "### 5.1 Example of NER with Llama-3.2-1B-Instruct on CPU\n",
    "\n",
    "**Skip this section if run on GPU**\n",
    "\n",
    "- It takes 20 min for two sentences. Therefore it is just a demo of how NER can be done. \n",
    "- If we have more computational resources, we will evaluate on the whole annotation test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d4258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M1) - 5455 MiB free\n",
      "llama_model_loader: loaded meta data with 31 key-value pairs and 147 tensors from models/Llama-3.2-1B-Instruct-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 1B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\" \", \" \", \" \", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type  f16:  113 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 2.30 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 2048\n",
      "print_info: n_layer          = 16\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 64\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 64\n",
      "print_info: n_embd_head_v    = 64\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 512\n",
      "print_info: n_embd_v_gqa     = 512\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 1B\n",
      "print_info: model params     = 1.24 B\n",
      "print_info: general.name     = Llama 3.2 1B Instruct\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 ''\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 162 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/17 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =  2357.26 MiB\n",
      "..............................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x117d567d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_2                             0x117d56aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_3                             0x126cfb6c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_4                             0x126cfb920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_5                             0x126cfbb80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_6                             0x117d56d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_7                             0x117d56fd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_8                             0x127e15b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4                             0x126cfbfc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_2                      0x117d572a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_3                      0x126cfb430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_4                      0x117d57570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_5                      0x117d577d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_6                      0x127e15e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_7                      0x126cfc250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_8                      0x117d57b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x117d57d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row_c4                             0x126cfc550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x1160e0d20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row_c4                             0x117d58060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x117d582c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row_c4                             0x1160e0f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_id                                 0x127e16100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x117d5d800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x117d5da60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x117d5dcc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x126cfc7b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x117d5df20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x126cfca10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x117d5e180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x1160e11e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x1160e1440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x117d5e3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x127e163d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x1160e16a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf                               0x117d5e640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf_4                             0x127e16630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x127e16900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x126cfcde0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x127e16c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x127e16f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x1160e1900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_abs                                    0x117d5e8a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sgn                                    0x117d5eb00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_step                                   0x127e174d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardswish                              0x127e171e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardsigmoid                            0x1160e1b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_exp                                    0x1160e1dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x117d5ef40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x117d5f1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x126cfd040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x127e17730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x127e17a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x127e17d70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x117d5f400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x117d5f6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x126cfd2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x127e18010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x126cfd840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x127e18270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x127e18770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_mxfp4                         0x1160e2020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x117d5f970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x1160e2280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x1160e24e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x117d5ffc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x117d5fcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x1160e2740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x1160e29a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x127e189d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x117d60260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x117d60530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x126cfdb10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x126cfdd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x126cfe120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x126cfe590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x126cfe9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f32                           0x126cfec40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f16                           0x127e18c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_set_rows_q8_0                          0x1160e2c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_0                          0x117d60800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_1                          0x127e18f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_0                          0x117d60b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_1                          0x127e191b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_iq4_nl                        0x117d610c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x127e19510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul                           0x1160e2e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul_add                       0x117d61440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x117d60dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x117d616a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x127e19770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x1160e30c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x126cfeea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32_group                     0x117d61900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x126cff100 | th_max =  384 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x117d61ba0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x126cff360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32_c4                      0x127e199d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x127e19c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_c4                      0x127e19e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x127e1a160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x117d61fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x126cff5c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x126cff820 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x126cffa80 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x127e1a400 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x117d62240 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x127e1a760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_mxfp4_f32                       0x117d624a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x126cffce0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x117d62700 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x127e1a9c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x127e1acc0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x15f9040d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x117d62a60 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x1160e3320 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x114e2b390 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x15f904330 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x127e1af20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x127e1b3d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x15f904600 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x127e1b840 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x15f904860 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x15f904ac0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x15f904d20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x1160e3580 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x15f904f80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x15f9053f0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x117d62cc0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x117d62f60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x1160e3820 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x15f905650 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x127e1baa0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_2              0x127e1be30 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_3              0x127e1c090 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_4              0x15f9058b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_5              0x117d63230 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x1160e3bc0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x117d63670 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x1160e3e60 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x127e1c2f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x127e1c680 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x127e1c8e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x127e1cb40 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x117d638d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x117d63b30 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x15f905b80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x117d63d90 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x117d641d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x117d64430 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x117d64690 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x127e1cda0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x117d648f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x117d64b90 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x117d64df0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x127e1d000 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x127e1d260 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x117d65150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x117d65420 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x117d65780 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x1160e40c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x117d659e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x117d65c40 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x117d65fa0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x117d66270 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x117d666b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x15f905de0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x117d66910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x117d66b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x117d66dd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x1160e4390 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x117d670a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x1160e4660 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x1160e4930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_mxfp4_f32                    0x127e1d4c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x1160e4c90 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x127e1d760 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x127e1da30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x117d67370 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x127e1dc90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x117d67640 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x117d67910 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x1160e4ef0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x1160e5250 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x1160e5520 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x117d67be0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x1160e5780 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x15f906040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x1160e5ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x15f9062a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x15f906500 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x15f906760 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x127e1dff0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x117d67eb0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x127e1e500 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x1160e5f20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x1160e6180 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x1160e63e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x1160e6640 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x1160e69a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x15f906be0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x127e1e250 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x127e1e8c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x127e1eb20 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x1160e6c00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x1160e6e60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x15f906eb0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x117d68280 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x127e1edf0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x117d684e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x117d687b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x127e1f050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map0_f16                     0x127e1f2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map1_f32                     0x1160e7130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f16                      0x117d68b50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f16                      0x127e1f690 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f16                     0x15f907180 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f16                     0x127e1f930 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f16                     0x117d68db0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f16                     0x117d69050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f16                     0x15f9073e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_mxfp4_f16                    0x1160e7390 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f16                     0x117d693b0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f16                     0x117d69650 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f16                     0x117d69920 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f16                     0x15f907720 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f16                     0x15f907bc0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f16                  0x1160e77d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f16                   0x1160e7a30 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f16                  0x1160e7c90 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f16                    0x1160e7ef0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f16                    0x15f907e20 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f16                    0x15f908080 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f16                    0x114e2b5f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f16                   0x114e2b950 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f16                   0x15f9082e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x15f908660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x15f9088c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f32                         0x117d69bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f16                         0x117d69e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f32                        0x127e1fd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f16                        0x15f908b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x1160e8250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x1160e84f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x117d6a1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x1160e8750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x15f908d80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x117d6a480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x1160e8a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x117d6a750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x117d6a9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x1160e8cb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x1160e8f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x117d6ad10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x117d6af70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x127e1ffd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x15f909050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x127e202f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x15f9092b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x1160e9220 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x127e20550 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x127e207b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x1160e9760 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x1160e99c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x127e20a50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x1160e9c20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x15f909510 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x1160e9f20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x117d6b210 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x117d6b570 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x117d6b840 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x1160ea180 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x117d6bb10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x1160ea3e0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x1160ea640 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x117d6bd70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x117d6c0d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x15f909770 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x1160ea8e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x15f909af0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x127e20e90 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x15f909dc0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x117d6c330 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x117d6c690 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x117d6cad0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x117d6cd30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x117d6cf90 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x117d6d1f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x15f90a020 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x127e210f0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x117d6d520 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x127e21350 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x117d6d7f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x127e215b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x117d6db50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x117d6ddb0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x127e21850 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x117d6e110 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x127e21b20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x15f90a490 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x15f90a6f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x15f90a950 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x127e22050 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x117d6e370 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x127e222b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x117d6e610 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x117d6e870 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x1160eac40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x117d6eb70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x1160eaea0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x1257f0880 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x125898c00 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h64             0x117d6efb0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h64            0x117d6f210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h64            0x117d6f470 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h64            0x117d6f6d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h64            0x117d6f9a0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h64            0x117d6fc70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x15f90acd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x15f90af30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x117d6fed0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x1160eb2e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x1160eb540 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x127e22510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x127e22770 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x127e229d0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x127e22c30 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x117d70130 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x15f90b380 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x15f90b5e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x15f90b840 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x15f90baa0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x117d70570 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x127e22f00 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x127e23450 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x127e236b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x127e23910 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x15f90bde0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x15f90c040 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x127e23b70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x117d707d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x127e23dd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x15f90c2a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x127e240b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x1257f0b80 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x117d70a30 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x15f90c6c0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x117d70e70 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x127e245f0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x127e24310 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x127e248b0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x117d710d0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x117d71330 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x15f90c990 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x127e24bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x15f90cbf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x117d71770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x127e24e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x127e25150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x15f90ce50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x127e25570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x117d719d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x117d71c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x117d71e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x117d720f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x15f90d0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x127e257d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x117d72350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x117d725b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x1160eb7a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x1160eba70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x117d72810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x117d72a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x117d72dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x127e25a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x1160ebd40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x15f90d520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x1160ebfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x1160ec300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x15f90d780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x1160ec560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x127e25ee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_reglu                                  0x15f90d9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu                                  0x15f90dc40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu                                 0x127e26140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu_oai                             0x15f90e0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_erf                              0x15f90e370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_quick                            0x127e263a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x117d73030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mean                                   0x117d73300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x127e26600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x15f90e5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x1160ec830 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =    64.00 MiB\n",
      "llama_kv_cache_unified: size =   64.00 MiB (  2048 cells,  16 layers,  1/1 seqs), K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 1176\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   254.50 MiB\n",
      "llama_context: graph nodes  = 566\n",
      "llama_context: graph splits = 226 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | DOTPROD = 1 | LLAMAFILE = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.model': 'gpt2', 'llama.embedding_length': '2048', 'llama.vocab_size': '128256', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.attention.value_length': '64', 'llama.attention.head_count': '32', 'llama.attention.key_length': '64', 'llama.attention.head_count_kv': '8', 'general.finetune': 'Instruct', 'general.file_type': '1', 'llama.block_count': '16', 'general.size_label': '1B', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.feed_forward_length': '8192', 'general.quantization_version': '2', 'llama.rope.dimension_count': '64', 'general.license': 'llama3.2', 'llama.context_length': '131072', 'general.architecture': 'llama', 'general.basename': 'Llama-3.2', 'llama.rope.freq_base': '500000.000000', 'general.name': 'Llama 3.2 1B Instruct'}\n",
      "Available chat formats from metadata: chat_template.default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# from llama_cpp import Llama\n",
    "# import json, re\n",
    "\n",
    "# # 1. Load GGUF model (same as you already used)\n",
    "# llm = Llama(\n",
    "# \tmodel_path=\"models/Llama-3.2-1B-Instruct-f16.gguf\",\n",
    "# \tn_ctx=2048,\n",
    "# \tn_threads=6,\n",
    "# \tn_gpu_layers=0     # works on Mac / Windows / Linux\n",
    "# )\n",
    "\n",
    "# print(\"Model loaded.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 66 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    5953.27 ms\n",
      "llama_perf_context_print: prompt eval time =  735431.22 ms /     2 tokens (367715.61 ms per token,     0.00 tokens per second)\n",
      "llama_perf_context_print:        eval time = 1204764.79 ms /   255 runs   ( 4724.57 ms per token,     0.21 tokens per second)\n",
      "llama_perf_context_print:       total time = 1209872.05 ms /   257 tokens\n",
      "llama_perf_context_print:    graphs reused =        247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw LLM output:\n",
      " BODY_PART:  \"chest\",\n",
      "SYMPTOM:  \"chest pains\",\n",
      "FINDING:  \"vomiting\", \n",
      "PROCEDURE:  \"consulted\", \n",
      "DISEASE:  \"gastritis\", \n",
      "BODY_PART:  \"abdomen\", \n",
      "SYMPTOM:  \"diarrhea\", \n",
      "FINDING:  \"gastritis\", \n",
      "BODY_PART:  \"abdomen\", \n",
      "SYMPTOM:  \"diarrhea\", \n",
      "FINDING:  \"gastritis\", \n",
      "BODY_PART:  \"abdomen\", \n",
      "PROCEDURE:  \"gastritis\", \n",
      "\n",
      "Here is an example json list:\n",
      "\"entity_text_1\":  \"DISEASE_1\",\n",
      "\"entity_text_2\":  \"BODY_PART_2\",\n",
      "...\n",
      "\"entity_text_n\":  \"PROCEDURE_n\",\n",
      "\"entity_text_p\":  \"SYMPTOM_p\" ,\n",
      "\"entity_text_q\":  \"FINDING_q\",\n",
      "\"entity_text_r\":  \"BODY_PART_r\",\n",
      "\"entity_text_s\":  \"PROCEDURE_s\",\n",
      "\"entity_text_t\":  \"SYMPTOM_t\" ,\n",
      "\"entity_text_u\":  \"FINDING_u\",\n",
      "\"entity_text_v\":  \"\n",
      "\n",
      "Parsed entities:\n"
     ]
    }
   ],
   "source": [
    "# # 2. Test sentence\n",
    "# text = \"She was having chest pains along with significant vomiting and diarrhea.\"\n",
    "\n",
    "# # 3. Minimal zero-shot NER prompt (no enhancements)\n",
    "# PROMPT = \"\"\"\n",
    "# Extract medical named entities from the text.\n",
    "# Use only these labels: DISEASE, SYMPTOM, BODY_PART, FINDING, PROCEDURE.\n",
    "# Return ONLY a JSON list like this:\n",
    "# \"entity_text_1\":  \"LABEL_1\",\n",
    "# Text:\n",
    "# {TEXT}\n",
    "# \"\"\"\n",
    "\n",
    "# # 4. Run LLM\n",
    "# raw = llm(PROMPT.format(TEXT=text), max_tokens=256)\n",
    "# output = raw[\"choices\"][0][\"text\"]\n",
    "# print(\"\\nRaw LLM output:\\n\", output)\n",
    "\n",
    "# # 5. Parse JSON from model output\n",
    "# def parse_json(s):\n",
    "# \ttry:\n",
    "# \t\tmatch = re.search(r\"\\[.*\\]\", s, re.S)\n",
    "# \t\tif match:\n",
    "# \t\t\treturn json.loads(match.group(0))\n",
    "# \texcept:\n",
    "# \t\tpass\n",
    "# \treturn []\n",
    "\n",
    "# ents = parse_json(output)\n",
    "\n",
    "# # 6. Print final extracted entities\n",
    "# print(\"\\nParsed entities:\")\n",
    "# for e in ents:\n",
    "# \tprint(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a26c1e",
   "metadata": {},
   "source": [
    "## 5.2 Sanity Check of LLM Behavior with a Minimal n-Shot Prompt\n",
    "\n",
    "Before relying on spaCy-LLMs built-in NER prompting strategy, it is important to understand how the base LLM behaves under a transparent and fully interpretable prompt. This sanity check serves several purposes:\n",
    "\n",
    "- LLMs are prone to hallucination, especially when forced to choose from a restricted label set. Observing their raw behavior helps identify systematic failure modes such as over-labeling or speculative predictions.\n",
    "- The default spaCy-LLM prompts are highly engineered and not fully documented. Since we cannot see their internal design decisions, it is useful to test a simple and fully understandable prompt for comparison.\n",
    "- Our custom few-shot examples do not (and should not) follow spaCy-LLMs templating rules. The purpose here is not to replace spaCy-LLM, but to benchmark the raw LLMs baseline behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950a8cb",
   "metadata": {},
   "source": [
    "### 5.2.1 Log of simple-prompt llm-based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047ef38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|| 3/3 [00:06<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36 test examples.\n",
      "================================================================================\n",
      "Example 1/36\n",
      "TEXT:\n",
      "This was also checked with fluoroscopy.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'hydrocoele' | DISEASE\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'hydrocoele' | DISEASE\n",
      "- 'testicular tumor' | DISEASE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large right inguinal hernia.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large right inguinal hernia with a small right hydrocoele.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "- \"hydrocoele\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large right inguinal hernia with a small right hydrocoele and a right testicular tumor.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "- \"hydrocoele\" | DISEASE\n",
      "- \"testicular tumor\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large right inguinal hernia with a small right\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 2/36\n",
      "TEXT:\n",
      "Masticatory dysfunction.,POSTOPERATIVE DIAGNOSES:,1.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Masticatory dysfunction' | SYMPTOM\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'dysfunction' | SYMPTOM\n",
      "- 'masticatory' | N\n",
      "- 'dysfunction' | SYMPTOM\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Masticatory dysfunction.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"dysfunction\" | SYMPTOM\n",
      "- \"masticatory\" | None (not a medical term)\n",
      "\n",
      "So the answer for the given text is:\n",
      "\n",
      "Output:\n",
      "- \"dysfunction\" | SYMPTOM\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 3/36\n",
      "TEXT:\n",
      "A posterior tunnel was done first on the left side along the mylohyoid ridge and then under retromolar pad to the external oblique and the ridge was then degloved.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'mylohyoid ridge' | BODY_PART\n",
      "- 'retromolar pad' | BODY_PART\n",
      "- 'external oblique' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'mylohyoid ridge' | BODY_PART\n",
      "- 'retromolar pad' | BODY_PART\n",
      "- 'external oblique' | BODY_PART\n",
      "- 'degloved' | SYMPTOM\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"A posterior tunnel was done first on the left side along the mylohyoid ridge and then under retromolar pad to the external oblique and the ridge was then degloved.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"mylohyoid ridge\" | BODY_PART\n",
      "- \"retromolar pad\" | BODY_PART\n",
      "- \"external oblique\" | BODY_PART\n",
      "- \"degloved\" | SYMPTOM (only if \"degloving\" is interpreted as a symptom, which is not the case here)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 4/36\n",
      "TEXT:\n",
      "Surgical team scrubbed and gowned in usual fashion and the patient was draped.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- 'drained' | ROUTE\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- 'needle' | DRUG\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh, which was drained.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "- \"drained\" | ROUTE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh, which was drained with a 14 gauge needle.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "- \"needle\" | DRUG (in a medical sense, a needle is considered a medical\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 5/36\n",
      "TEXT:\n",
      "Maxillary atrophy.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Maxillary' | BODY_PART\n",
      "- 'atrophy' | SYMPTOM\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'maxillary cyst' | DISEASE\n",
      "- 'maxillary atrophy' | DISEASE\n",
      "- 'maxillary cyst' | DISEASE\n",
      "- 'bone loss' | SYMPTOM\n",
      "- 'maxillary cyst' | DISE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large maxillary cyst.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"maxillary cyst\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large maxillary atrophy.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"maxillary atrophy\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large maxillary cyst with significant bone loss.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"maxillary cyst\" | DISEASE\n",
      "- \"bone loss\" | SYMPTOM\n",
      "\n",
      "Input Text: \"The patient was noted to have a large maxillary cyst with significant bone loss and significant pain.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"maxillary cyst\" | DISE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 6/36\n",
      "TEXT:\n",
      ",The clamps were removed establishing flow through the fistula.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'fistula' | DISEASE\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \",The clamps were removed establishing flow through the fistula.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "None.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 7/36\n",
      "TEXT:\n",
      "Once the bone was harvested, surgical templets were used to recontour initially the maxillary graft and the mandibular graft.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'bone' | BODY_PART\n",
      "- 'maxillar' | BODY_PART\n",
      "- 'mandibula' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'maxillary graft' | BODY_PART\n",
      "- 'mandibular graft' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Once the bone was harvested, surgical templets were used to recontour initially the maxillary graft and the mandibular graft.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"maxillary graft\" | BODY_PART\n",
      "- \"mandibular graft\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 8/36\n",
      "TEXT:\n",
      "The ankle was taken through a range of motion with noted improvement in the reduction of the talocalcaneal alignment with the foot in plantar flexion on the lateral view.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'ankle' | BODY_PART\n",
      "- 'foot' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'plantar flexion' | SYMPTOM\n",
      "- 'talocalcaneal alignment' | DISEASE\n",
      "- 'foot' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The ankle was taken through a range of motion with noted improvement in the reduction of the talocalcaneal alignment with the foot in plantar flexion on the lateral view.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"plantar flexion\" | SYMPTOM\n",
      "- \"talocalcaneal alignment\" | DISEASE\n",
      "- \"foot\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 9/36\n",
      "TEXT:\n",
      "Intended incision was marked on the skin.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- '14-gauge' | ROUTE\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh, which was drained with a 14-gauge needle.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "- \"14-gauge\" | ROUTE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh, which was drained with a 14-gauge needle and packed with gauze.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "-\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 10/36\n",
      "TEXT:\n",
      "Risks of surgery include risks of anesthesia, infection, bleeding, changes in sensation and motion of the extremity, hardware failure, need for other surgical procedures, need to be nonweightbearing for some time.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'infection' | SYMPTOM\n",
      "- 'bleeding' | SYMPTOM\n",
      "- ' extremity' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'right thigh' | BODY_PART\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'right thigh' | BODY_PART\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'right thigh' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large hematoma in the right thigh.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"right thigh\" | BODY_PART\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the right thigh after the procedure.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"right thigh\" | BODY_PART\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the right thigh after the procedure.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"right thigh\" | BODY_PART\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the right thigh after the procedure.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE,\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 11/36\n",
      "TEXT:\n",
      "The fluid administered 300 cc.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'cc' | ROUTE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: The fluid administered 300 cc.\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"cc\" | ROUTE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 12/36\n",
      "TEXT:\n",
      ",2.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 13/36\n",
      "TEXT:\n",
      "This was explained to the mother in detail.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY_PART\n",
      "- '14-gauge' | ROUTE\n",
      "- 'hematoma' | SYMPTOM\n",
      "- 'left thigh' | BODY\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh, which was drained with a 14-gauge needle.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY_PART\n",
      "- \"14-gauge\" | ROUTE\n",
      "\n",
      "Input Text: \"The patient was noted to have a large hematoma in the left thigh, which was drained with a 14-gauge needle and 10 cc of blood was collected.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hematoma\" | SYMPTOM\n",
      "- \"left thigh\" | BODY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 14/36\n",
      "TEXT:\n",
      "The periosteal flap was sutured over the staple using 2-0 Vicryl.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'periosteal flap' | BODY_PART\n",
      "- 'Vicryl' | DRUG\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'staple' | BODY_PART\n",
      "- 'periosteal flap' | BODY_PART\n",
      "- 'using' | N\n",
      "- '2-0 Vicryl' | DRUG\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The periosteal flap was sutured over the staple using 2-0 Vicryl.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"staple\" | BODY_PART\n",
      "- \"periosteal flap\" | BODY_PART\n",
      "- \"using\" | None\n",
      "- \"2-0 Vicryl\" | DRUG\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 15/36\n",
      "TEXT:\n",
      "The tissues were stretched with tissue scissors and then a high speed instrumentation was used to decorticate the anterior mandible using a 1.6 mm twist drill and a pear shaped bur was used in the posterior region to begin original exploratory phenomenon of repair.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'mandible' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'anterior mandible' | BODY_PART\n",
      "- 'posterior region' | BODY_PART\n",
      "- 'high speed instrumentation' | TOOL\n",
      "- 'decorticate' | PROCEDURE\n",
      "- '1.6 mm twist drill' | TOOL\n",
      "- 'pear shaped bur' | TOOL\n",
      "- 'original exploratory phenomenon of repair' | PROCEDURE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The tissues were stretched with tissue scissors and then a high speed instrumentation was used to decorticate the anterior mandible using a 1.6 mm twist drill and a pear shaped bur was used in the posterior region to begin original exploratory phenomenon of repair.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"anterior mandible\" | BODY_PART\n",
      "- \"posterior region\" | BODY_PART\n",
      "- \"high speed instrumentation\" | TOOL\n",
      "- \"decorticate\" | PROCEDURE\n",
      "- \"1.6 mm twist drill\" | TOOL\n",
      "- \"pear shaped bur\" | TOOL\n",
      "- \"original exploratory phenomenon of repair\" | PROCEDURE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 16/36\n",
      "TEXT:\n",
      "Once the foot was reduced a Steinman pin was used to hold it in position.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'foot' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'pin' | DRUG\n",
      "- 'position' | N\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Once the foot was reduced a Steinman pin was used to hold it in position.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"pin\" | DRUG (only if \"Steinman\" is a brand name for the pin)\n",
      "- \"position\" | None\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 17/36\n",
      "TEXT:\n",
      "Incision was then made over the left lateral aspect of the hind foot to expose the talocalcaneal joint.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'hind foot' | BODY_PART\n",
      "- 'talocalcaneal joint' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'hind foot' | BODY_PART\n",
      "- 'talocalcaneal joint' | BODY_PART\n",
      "- 'morphine' | DRUG\n",
      "- 'intravenously' | ROUTE\n",
      "- 'morphine' | DRUG\n",
      "- 'intravenously' | ROUTE\n",
      "- 'pain' | SYMPTOM\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Incision was then made over the left lateral aspect of the hind foot to expose the talocalcaneal joint.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"hind foot\" | BODY_PART\n",
      "- \"talocalcaneal joint\" | BODY_PART\n",
      "\n",
      "\n",
      "Input Text: \"The patient was given 10 mg of morphine intravenously for pain control.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"morphine\" | DRUG\n",
      "- \"intravenously\" | ROUTE\n",
      "\n",
      "Input Text: \"The patient was given 10 mg of morphine intravenously for pain control.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"morphine\" | DRUG\n",
      "- \"intravenously\" | ROUTE\n",
      "- \"pain\" | SYMPTOM\n",
      "\n",
      "Input Text: \"The patient was given 10 mg of morphine intraven\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 18/36\n",
      "TEXT:\n",
      "PREOPERATIVE DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.,POSTOPERATIVE\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'myotonic muscular dystrophy' | DISEASE\n",
      "- 'planovalgus' | DISEASE\n",
      "- 'feet' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'planovalgus' | DISEASE\n",
      "- 'feet' | BODY_PART\n",
      "- 'congenital myotonic muscular dystrophy' | DISEASE\n",
      "- 'planovalgus' | DISEASE\n",
      "- 'feet' | BODY_PART\n",
      "- 'congenital myotonic muscular dystrophy' | DISEASE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was diagnosed with congenital myotonic muscular dystrophy with bilateral planovalgus feet.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"planovalgus\" | DISEASE\n",
      "- \"feet\" | BODY_PART\n",
      "- \"congenital myotonic muscular dystrophy\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was diagnosed with congenital myotonic muscular dystrophy and underwent a surgical correction of bilateral planovalgus feet.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"planovalgus\" | DISEASE\n",
      "- \"feet\" | BODY_PART\n",
      "- \"congenital myotonic muscular dystrophy\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was diagnosed with congenital myotonic muscular dystrophy and underwent a surgical correction of bilateral planovalgus feet using a medial closing wedge\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 19/36\n",
      "TEXT:\n",
      "The incision was then extended posteriorly to allow for visualization of the Achilles, which was Z-lengthened with the release of the lateral distal half.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Achilles' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'Achilles' | BODY_PART\n",
      "- 'Z-lengthened' | PROCEDURE\n",
      "- 'release' | PROCEDURE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The incision was then extended posteriorly to allow for visualization of the Achilles, which was Z-lengthened with the release of the lateral distal half.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"Achilles\" | BODY_PART\n",
      "- \"Z-lengthened\" | PROCEDURE (not a label, but I'll add it for completeness)\n",
      "- \"release\" | PROCEDURE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 20/36\n",
      "TEXT:\n",
      "The cephalic vein was divided, and the proximal end was anastomosed to the artery in an end-to-side fashion with a running 6-0 Prolene suture.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'cephalic vein' | BODY_PART\n",
      "- 'artery' | BODY_PART\n",
      "- 'Prolene' | DRUG\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'Prolene' | DRUG\n",
      "- 'end-to-side' | ROUTE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The cephalic vein was divided, and the proximal end was anastomosed to the artery in an end-to-side fashion with a running 6-0 Prolene suture.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"Prolene\" | DRUG\n",
      "- \"end-to-side\" | ROUTE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 21/36\n",
      "TEXT:\n",
      "#3-0 Gore-Tex.  Attention was brought then to the mandible.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'mandible' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'mandible' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: #3-0 Gore-Tex.  Attention was brought then to the mandible.\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"mandible\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 22/36\n",
      "TEXT:\n",
      "The patient received 6 mL of 0.25% Marcaine local anesthetic on each side.,TOURNIQUET\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Marcaine' | DRUG\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'Marcaine' | DRUG\n",
      "- '6 mL' | ROUTE\n",
      "- 'each side' | N\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: The patient received 6 mL of 0.25% Marcaine local anesthetic on each side.\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"Marcaine\" | DRUG\n",
      "- \"6 mL\" | ROUTE\n",
      "- \"each side\" | None\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 23/36\n",
      "TEXT:\n",
      "Bilateral long-leg casts were then placed with the foot in neutral with some moulding of his medial plantar arch.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'foot' | BODY_PART\n",
      "- 'medial plantar arch' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'foot' | BODY_PART\n",
      "- 'neutral' | SYMPTOM\n",
      "- 'moulding' | SYMPTOM\n",
      "- 'medial plantar arch' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Bilateral long-leg casts were then placed with the foot in neutral with some moulding of his medial plantar arch.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"foot\" | BODY_PART\n",
      "- \"neutral\" | SYMPTOM\n",
      "- \"moulding\" | SYMPTOM\n",
      "- \"medial plantar arch\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 24/36\n",
      "TEXT:\n",
      "Severe mandibular atrophy.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Severe ' | SYMPTOM\n",
      "- 'andibular' | BODY_PART\n",
      "- 'atrophy' | SYMPTOM\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'atrophy' | SYMPTOM\n",
      "- 'mandibular' | BODY_PART\n",
      "- 'severe' | N\n",
      "- 'atrophy' | DISEASE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Severe mandibular atrophy.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"atrophy\" | SYMPTOM\n",
      "- \"mandibular\" | BODY_PART\n",
      "- \"severe\" | None\n",
      "- \"atrophy\" | DISEASE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 25/36\n",
      "TEXT:\n",
      "Hemostasis was obtained.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Hemostasis was obtained.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "None.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 26/36\n",
      "TEXT:\n",
      "Acquired facial deformity.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Acquired' | SYMPTOM\n",
      "- 'facial' | BODY_PART\n",
      "- 'deformity' | SYMPTOM\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'large' | SYMPTOM\n",
      "- 'left' | SYMPTOM\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'reducible mass' | SYMPTOM\n",
      "- 'large' | SYMPTOM\n",
      "- 'left' | SYMPTOM\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'reducible mass' | SYMPTOM\n",
      "- 'small' | SYMPTOM\n",
      "- 'right' | SYMPTOM\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a large left inguinal hernia with a reducible mass.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"large\" | SYMPTOM\n",
      "- \"left\" | SYMPTOM\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "- \"reducible mass\" | SYMPTOM\n",
      "\n",
      "Input Text: \"The patient was noted to have a large left inguinal hernia with a reducible mass and a small right inguinal hernia.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"large\" | SYMPTOM\n",
      "- \"left\" | SYMPTOM\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "- \"reducible mass\" | SYMPTOM\n",
      "- \"small\" | SYMPTOM\n",
      "- \"right\" | SYMPTOM\n",
      "\n",
      "Input Text: \"The patient was noted to have a large left inguinal hernia with a reducible mass and a small right inguinal hernia. The left hernia was\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 27/36\n",
      "TEXT:\n",
      "The block of bone was further re-contoured in situ.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'bone' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The block of bone was further re-contoured in situ.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "None.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 28/36\n",
      "TEXT:\n",
      "TIME:  ,Tourniquet time was 53 minutes on the left and 45 minutes on the right.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'hernia defect' | SYMPTOM\n",
      "- 'inguinal hernia' | DISEASE\n",
      "- 'hernia defect' | SYMPTOM\n",
      "- 'hydrocele' | DISEASE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The patient was noted to have a left-sided inguinal hernia.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a left-sided inguinal hernia with a 2 cm hernia defect.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "- \"hernia defect\" | SYMPTOM\n",
      "\n",
      "Input Text: \"The patient was noted to have a left-sided inguinal hernia with a 2 cm hernia defect and a 1 cm hydrocele.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"inguinal hernia\" | DISEASE\n",
      "- \"hernia defect\" | SYMPTOM\n",
      "- \"hydrocele\" | DISEASE\n",
      "\n",
      "Input Text: \"The patient was noted to have a left-sided\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 29/36\n",
      "TEXT:\n",
      ",3.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 30/36\n",
      "TEXT:\n",
      "A tunnel was formed in the posterior region separating the mental nerve artery and vein from the flap and exposing that aspect of the body of the mandible.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'mental nerve' | BODY_PART\n",
      "- 'artery' | BODY_PART\n",
      "- 'vein' | BODY_PART\n",
      "- 'mandible' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'mandible' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"A tunnel was formed in the posterior region separating the mental nerve artery and vein from the flap and exposing that aspect of the body of the mandible.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"mandible\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 31/36\n",
      "TEXT:\n",
      "The facial tissues were then reflected exposing the lateral aspect of the maxilla, the zygomatic arch, the infraorbital nerve, artery and vein, the lateral piriform rim, the inferior piriform rim, and the remaining issue of the nasal spine.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'maxilla' | BODY_PART\n",
      "- 'zygomatic arch' | BODY_PART\n",
      "- 'infraorbital nerve' | BODY_PART\n",
      "- 'lateral piriform rim' | BODY_PART\n",
      "- 'inferior piriform rim' | BODY_PART\n",
      "- 'nasal spine' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'maxilla' | BODY_PART\n",
      "- 'zygomatic arch' | BODY_PART\n",
      "- 'infraorbital nerve' | NERVE\n",
      "- 'artery' | BODY_PART\n",
      "- 'vein' | BODY_PART\n",
      "- 'lateral piriform rim' | BODY_PART\n",
      "- 'inferior piriform rim' | BODY_PART\n",
      "- 'nasal spine' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The facial tissues were then reflected exposing the lateral aspect of the maxilla, the zygomatic arch, the infraorbital nerve, artery and vein, the lateral piriform rim, the inferior piriform rim, and the remaining issue of the nasal spine.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"maxilla\" | BODY_PART\n",
      "- \"zygomatic arch\" | BODY_PART\n",
      "- \"infraorbital nerve\" | NERVE\n",
      "- \"artery\" | BODY_PART\n",
      "- \"vein\" | BODY_PART\n",
      "- \"lateral piriform rim\" | BODY_PART\n",
      "- \"inferior piriform rim\" | BODY_PART\n",
      "- \"nasal spine\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 32/36\n",
      "TEXT:\n",
      "Xylocaine 1%, 1:100,000 epinephrine 7 ml was infiltrated into the labial and palatal mucosa.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'Xylocaine' | DRUG\n",
      "- 'epinephrine' | DRUG\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'mucosa' | BODY_PART\n",
      "- 'Xylocaine' | DRUG\n",
      "- 'epinephrine' | DRUG\n",
      "- 'infiltrated' | ROUTE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Xylocaine 1%, 1:100,000 epinephrine 7 ml was infiltrated into the labial and palatal mucosa.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"mucosa\" | BODY_PART\n",
      "- \"Xylocaine\" | DRUG\n",
      "- \"epinephrine\" | DRUG\n",
      "- \"infiltrated\" | ROUTE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 33/36\n",
      "TEXT:\n",
      "Both the extremities were then prepped and draped in standard surgical fashion.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'extremities' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"Both the extremities were then prepped and draped in standard surgical fashion.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "None.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 34/36\n",
      "TEXT:\n",
      "The IV catheter was inserted into the vein on the lower surface of the left forearm.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'IV' | ROUTE\n",
      "- 'vein' | BODY_PART\n",
      "- 'forearm' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'left forearm' | BODY_PART\n",
      "- 'vein' | BODY_PART\n",
      "- 'IV' | ROUTE\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"The IV catheter was inserted into the vein on the lower surface of the left forearm.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"left forearm\" | BODY_PART\n",
      "- \"vein\" | BODY_PART\n",
      "- \"IV\" | ROUTE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 35/36\n",
      "TEXT:\n",
      "The area was re-contoured with rongeurs.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- None\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- None\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: The area was re-contoured with rongeurs.\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "None.\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Example 36/36\n",
      "TEXT:\n",
      "DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.\n",
      "\n",
      "GOLD ENTITIES (string level):\n",
      "- 'myotonic muscular dystrophy' | DISEASE\n",
      "- 'planovalgus' | DISEASE\n",
      "- 'feet' | BODY_PART\n",
      "\n",
      "LLM PREDICTIONS (parsed):\n",
      "- 'planovalgus' | DISEASE\n",
      "- 'feet' | BODY_PART\n",
      "\n",
      "RAW LLM OUTPUT (for debugging):\n",
      "Input Text: \"DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.\"\n",
      "Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
      "Output:\n",
      "- \"planovalgus\" | DISEASE\n",
      "- \"feet\" | BODY_PART\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Log written to: ner/sanity_check_llm/mistral_ner_log.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# # ============== CONFIG ==============\n",
    "\n",
    "# TEST_JSON_PATH = \"ner/samples/annotated_samples_test_1.json\"\n",
    "# MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# LOG_PATH = \"ner/sanity_check_llm/mistral_ner_log.txt\"  # new: log file\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# # Few-shot examples\n",
    "# # ----- Few-shot examples (use your current best EXAMPLES) -----\n",
    "# EXAMPLES = \"\"\"\n",
    "\n",
    "# Input Text: \",The estimated blood loss in the harvest of the hip was 100 cc.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# None\n",
    "\n",
    "# Input Text: \"He has been having significant feet pain with significant planovalgus deformity.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"pain\" | SYMPTOM\n",
    "# - \"deformity\" | SYMPTOM\n",
    "# - \"planovalgus\" | DISEASE\n",
    "\n",
    "# Input Text: \"A surgical mallet then compressed this bone further into the region.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"bone\" | BODY_PART\n",
    "\n",
    "# Input Text: \"A primary incision was made between the mental foramina and the residual crest of the ridge and reflected first to the lingual area observing the superior genial tubercle in the facial area degloving the mentalis muscle and exposing the anterior body.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"mental foramina\" | BODY_PART\n",
    "# - \"genial tubercle\" | BODY_PART\n",
    "\n",
    "# Input Text: \"The patient was noted to have flexible vertical talus.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"vertical talus\" | DISEASE\n",
    "\n",
    "# Input Text: \"A piece of AlloDerm mixed with Croften and patient's platelet-rich plasma, which was centrifuged from drawing 20 cc of blood was then mixed together and placed over the lateral aspect of the block.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"AlloDerm\" | DRUG\n",
    "\n",
    "# Input Text: \"The area was injected with 6 mL of 0.25% Marcaine local anesthetic.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"Marcaine\" | DRUG\n",
    "\n",
    "# Input Text: \"The estimated blood loss in the intraoral procedure was 220 cc.\"\n",
    "# Labels: SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE\n",
    "# Output:\n",
    "# - \"intraoral\" | ROUTE\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# PROMPT_TEMPLATE = f\"\"\"\n",
    "# Here is a Text:\n",
    "# {{TEXT}}\n",
    "\n",
    "# Check whether or not there are medical words in the Text that can be labelled\n",
    "# and ONLY labeled as one of the labels SYMPTOM, BODY_PART, DISEASE, DRUG, ROUTE in a medical sense.\n",
    "# If not, confidently report None.\n",
    "# If so, report following the format below: \n",
    "# - \"actual word in the input Text\" | LABEL\n",
    "\n",
    "# Use the strict definitions for the labels as follows.\n",
    "# SYMPTOM: Phrases that describe what the patient feels or observable clinical signs \n",
    "#          (e.g. pain, swelling, dysfunction, shortness of breath).\n",
    "\n",
    "\n",
    "# BODY_PART: Names of anatomical body structures or regions \n",
    "#          (e.g. bone, mandible, forearm, Achilles tendon).\n",
    "\n",
    "# DISEASE: Official disease or diagnosis terms, usually multi-word or technical names \n",
    "#          (e.g. congenital myotonic muscular dystrophy, planovalgus).\n",
    "\n",
    "# DRUG: Names of medications, anesthetics, or pharmacological agents \n",
    "#       (e.g. Marcaine, Xylocaine, morphine).\n",
    "\n",
    "# ROUTE: Words that describe the route of administration into the body \n",
    "#        (e.g. IV, intraoral, intramuscular, intravenously).\n",
    "\n",
    "\n",
    "# NEVER mention any word that is not in the raw Text.\n",
    "\n",
    "# Learn from some examples below.\n",
    "\n",
    "# {EXAMPLES}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# # Load model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     torch_dtype=torch_dtype,\n",
    "#     device_map=\"auto\" if device == \"cuda\" else None,\n",
    "# )\n",
    "\n",
    "\n",
    "# # ============== Helper: LLM NER prediction ==============\n",
    "\n",
    "# def llm_ner_predict(text, max_new_tokens=256):\n",
    "#     prompt = PROMPT_TEMPLATE.format(TEXT=text)\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output_ids = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=max_new_tokens,\n",
    "#             do_sample=False,\n",
    "#             pad_token_id=tokenizer.eos_token_id,\n",
    "#         )\n",
    "\n",
    "#     output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "#     answer = output_text[len(prompt):].strip()\n",
    "\n",
    "#     pattern = r'-\\s*\"([^\"]+)\"\\s*\\|\\s*([A-Z_]+)'\n",
    "#     matches = re.findall(pattern, answer)\n",
    "#     preds = [(t, lab) for t, lab in matches]\n",
    "\n",
    "#     return preds, answer\n",
    "\n",
    "\n",
    "# # ============== Load test dataset ==============\n",
    "\n",
    "# with open(TEST_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# annotations = data[\"annotations\"]\n",
    "# test_count = len(annotations)\n",
    "\n",
    "# print(f\"Loaded {test_count} test examples.\")\n",
    "\n",
    "# os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)\n",
    "\n",
    "# # ============== Write log header ==============\n",
    "\n",
    "# with open(LOG_PATH, \"w\", encoding=\"utf-8\") as log_f:\n",
    "#     log_f.write(f\"Loaded {test_count} test examples.\\n\\n\")\n",
    "\n",
    "#     log_f.write(\"===== MODEL & DATA INFO =====\\n\")\n",
    "#     log_f.write(f\"MODEL_ID: {MODEL_ID}\\n\")\n",
    "#     log_f.write(f\"TEST_JSON_PATH: {TEST_JSON_PATH}\\n\\n\")\n",
    "\n",
    "#     log_f.write(\"===== PROMPT TEMPLATE =====\\n\")\n",
    "#     log_f.write(PROMPT_TEMPLATE)\n",
    "#     log_f.write(\"\\n\\n===== START EXAMPLES =====\\n\\n\")\n",
    "\n",
    "#     # ============== Iterate over test samples ==============\n",
    "\n",
    "#     for idx, (sent, ann_dict) in enumerate(annotations):\n",
    "#         gold_spans = ann_dict.get(\"entities\", [])\n",
    "\n",
    "#         gold_entities = []\n",
    "#         for start, end, label in gold_spans:\n",
    "#             gold_entities.append((sent[start:end], label))\n",
    "\n",
    "#         preds, raw_output = llm_ner_predict(sent)\n",
    "\n",
    "#         block = []\n",
    "#         block.append(\"=\" * 80 + \"\\n\")\n",
    "#         block.append(f\"Example {idx+1}/{test_count}\\n\")\n",
    "#         block.append(f\"TEXT:\\n{sent}\\n\\n\")\n",
    "\n",
    "#         block.append(\"GOLD ENTITIES (string level):\\n\")\n",
    "#         if gold_entities:\n",
    "#             for text_span, lab in gold_entities:\n",
    "#                 block.append(f\"- '{text_span}' | {lab}\\n\")\n",
    "#         else:\n",
    "#             block.append(\"- None\\n\")\n",
    "\n",
    "#         block.append(\"\\nLLM PREDICTIONS (parsed):\\n\")\n",
    "#         if preds:\n",
    "#             for t, lab in preds:\n",
    "#                 block.append(f\"- '{t}' | {lab}\\n\")\n",
    "#         else:\n",
    "#             block.append(\"- None\\n\")\n",
    "\n",
    "#         block.append(\"\\nRAW LLM OUTPUT (for debugging):\\n\")\n",
    "#         block.append(raw_output + \"\\n\")\n",
    "#         block.append(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "#         block_str = \"\".join(block)\n",
    "\n",
    "#         # Print to console\n",
    "#         print(block_str, end=\"\")\n",
    "\n",
    "#         # Write to log\n",
    "#         log_f.write(block_str)\n",
    "\n",
    "# print(f\"\\nLog written to: {LOG_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b27c0",
   "metadata": {},
   "source": [
    "### 5.2.2 Evaluation of simple-prompt llm-based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50710fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LLM NER Evaluation =====\n",
      "Micro Precision: 0.3043\n",
      "Micro Recall:    0.3043\n",
      "Micro F1 score:  0.3043\n",
      "\n",
      "Macro Precision: 0.22\n",
      "Macro Recall:    0.2838\n",
      "Macro F1:        0.2228\n"
     ]
    }
   ],
   "source": [
    "# # =========================================\n",
    "# #  LLM NER Evaluation: Precision/Recall/F1\n",
    "# # =========================================\n",
    "\n",
    "import re\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# def find_span_in_text(text, substring):\n",
    "#     \"\"\"\n",
    "#     Return (start, end) of the first exact match of substring in text.\n",
    "#     If not found, return None.\n",
    "#     Case-sensitive.\n",
    "#     \"\"\"\n",
    "#     pattern = re.escape(substring)\n",
    "#     match = re.search(pattern, text)\n",
    "#     if not match:\n",
    "#         return None\n",
    "#     return match.start(), match.end()\n",
    "\n",
    "\n",
    "# # Convert gold spans into evaluation form\n",
    "# gold_eval = []  # list of lists: [ [(start,end,label), ...], ... ]\n",
    "# for sent, ann in annotations:\n",
    "#     spans = []\n",
    "#     for start, end, label in ann[\"entities\"]:\n",
    "#         spans.append((start, end, label))\n",
    "#     gold_eval.append(spans)\n",
    "\n",
    "\n",
    "# # Convert LLM preds (string spans) into character spans\n",
    "# pred_eval = []  # same structure as gold_eval\n",
    "# for idx, (sent, ann) in enumerate(annotations):\n",
    "#     preds, _ = llm_ner_predict(sent)\n",
    "#     sent_pred_spans = []\n",
    "\n",
    "#     for ent_text, label in preds:\n",
    "#         span = find_span_in_text(sent, ent_text)\n",
    "#         if span is None:\n",
    "#             continue  # skip unmatched spans\n",
    "#         start, end = span\n",
    "#         sent_pred_spans.append((start, end, label))\n",
    "\n",
    "#     pred_eval.append(sent_pred_spans)\n",
    "\n",
    "\n",
    "# # ========== Construct label lists for PRF computation ==========\n",
    "\n",
    "# true_labels = []\n",
    "# pred_labels = []\n",
    "\n",
    "# for gold_spans, pred_spans in zip(gold_eval, pred_eval):\n",
    "\n",
    "#     gold_set = {(s, e, l) for (s, e, l) in gold_spans}\n",
    "#     pred_set = {(s, e, l) for (s, e, l) in pred_spans}\n",
    "\n",
    "#     # True positives\n",
    "#     for span in gold_set.intersection(pred_set):\n",
    "#         true_labels.append(span[2])\n",
    "#         pred_labels.append(span[2])\n",
    "\n",
    "#     # False negatives\n",
    "#     for span in gold_set - pred_set:\n",
    "#         true_labels.append(span[2])\n",
    "#         pred_labels.append(\"NONE\")\n",
    "\n",
    "#     # False positives\n",
    "#     for span in pred_set - gold_set:\n",
    "#         true_labels.append(\"NONE\")\n",
    "#         pred_labels.append(span[2])\n",
    " \n",
    "  \n",
    "# # ========== Compute micro/macro F1 ==========\n",
    "\n",
    "# prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "#     true_labels, pred_labels,labels=CUSTOM_LABELS, average=\"micro\", zero_division=0\n",
    "# )\n",
    "# prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "#     true_labels, pred_labels, labels=CUSTOM_LABELS, average=\"macro\", zero_division=0\n",
    "# )\n",
    "\n",
    "# print(\"\\n===== LLM NER Evaluation =====\")\n",
    "# print(f\"Micro Precision: {prec_micro:.4f}\")\n",
    "# print(f\"Micro Recall:    {rec_micro:.4f}\")\n",
    "# print(f\"Micro F1 score:  {f1_micro:.4f}\")\n",
    "\n",
    "# print(\"\\nMacro Precision:\", round(prec_macro, 4))\n",
    "# print(\"Macro Recall:   \", round(rec_macro, 4))\n",
    "# print(\"Macro F1:       \", round(f1_macro, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f2434",
   "metadata": {},
   "source": [
    "### Summary of minimal n-shot prompt results\n",
    "\n",
    "Despite including clear and relevant examples, the raw LLM under a simple n-shot prompt achieved only:\n",
    "\n",
    "Micro F1 score:  0.3043\n",
    "Macro F1:        0.2228\n",
    "\n",
    "This confirms that unconstrained prompting is not sufficient for reliable NER, and that hallucination control and output normalization require more structure than a minimal prompt can provide.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712059a",
   "metadata": {},
   "source": [
    "## 5.3 Evaluation of the spaCy-LLM Pipeline\n",
    "\n",
    "The spaCy-LLM framework adds an essential layer of structure around the base LLM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346f137",
   "metadata": {},
   "source": [
    "### NER2\n",
    "\n",
    "The NER2 template from spacy-llm supports the following features as part of the prompt:\n",
    "* Label description.\n",
    "    For instance:\n",
    "    ```python \n",
    "    \"BODY_PART is defined as any anatomical location, tissue, or organ.\" \n",
    "    ```\n",
    "\n",
    "* Few-shot.The examples provided can be found here: <br>\n",
    "    ner/spacy_llm/ner_examples_ner2_balanced_1.json <br>\n",
    "    For instance:\n",
    "```json\n",
    "{\n",
    "  \"text\": \"He has been having significant feet pain with significant planovalgus deformity.\",\n",
    "  \"entities\": {\n",
    "    \"BODY_PART\": [\"feet\"],\n",
    "    \"SYMPTOM\": [\"pain\"],\n",
    "    \"DISEASE\": [\"planovalgus deformity\"]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0ae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:00<00:00, 115.24it/s]\n",
      "Model saved to /storage/homefs/kw24z021/NLP_LLM/group_project/MedNLP-Multitask/ner/spacy_llm/models/output_mistral-7b_ner\n",
      "Loaded 36 annotated test sentences.\n",
      "Loading model...mistral-7b\n",
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:00<00:00, 112.45it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Prediction completed in 16.04 seconds for 36 sentences.\n",
      "\n",
      "==== Micro-Averaged Metrics ====\n",
      "Precision: 0.1972\n",
      "Recall:    0.1972\n",
      "F1-score:  0.1972\n",
      "\n",
      "Macro Precision: 0.2220\n",
      "Macro Recall:   0.1636\n",
      "Macro F1:       0.1710\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: A posterior tunnel was done first on the left side along the mylohyoid ridge and then under retromolar pad to the external oblique and the ridge was then degloved.\n",
      "Gold: [[61, 76, 'BODY_PART'], [92, 106, 'BODY_PART'], [114, 130, 'BODY_PART']]\n",
      "Pred: [[61, 76, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Surgical team scrubbed and gowned in usual fashion and the patient was draped.\n",
      "Gold: []\n",
      "Pred: [[0, 13, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Maxillary atrophy.\n",
      "Gold: [[0, 9, 'BODY_PART'], [10, 17, 'SYMPTOM']]\n",
      "Pred: [[0, 17, 'DISEASE']]\n",
      "--------------------------------------------------\n",
      "Text: Once the bone was harvested, surgical templets were used to recontour initially the maxillary graft and the mandibular graft.\n",
      "Gold: [[9, 13, 'BODY_PART'], [84, 92, 'BODY_PART'], [108, 117, 'BODY_PART']]\n",
      "Pred: [[29, 46, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: The ankle was taken through a range of motion with noted improvement in the reduction of the talocalcaneal alignment with the foot in plantar flexion on the lateral view.\n",
      "Gold: [[4, 9, 'BODY_PART'], [126, 130, 'BODY_PART']]\n",
      "Pred: [[4, 9, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Intended incision was marked on the skin.\n",
      "Gold: []\n",
      "Pred: [[9, 17, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Risks of surgery include risks of anesthesia, infection, bleeding, changes in sensation and motion of the extremity, hardware failure, need for other surgical procedures, need to be nonweightbearing for some time.\n",
      "Gold: [[46, 55, 'SYMPTOM'], [57, 65, 'SYMPTOM'], [105, 115, 'BODY_PART']]\n",
      "Pred: [[9, 16, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The fluid administered 300 cc.\n",
      "Gold: []\n",
      "Pred: [[4, 9, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: This was explained to the mother in detail.\n",
      "Gold: []\n",
      "Pred: [[26, 32, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The periosteal flap was sutured over the staple using 2-0 Vicryl.\n",
      "Gold: [[4, 19, 'BODY_PART'], [58, 64, 'DRUG']]\n",
      "Pred: [[4, 19, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The tissues were stretched with tissue scissors and then a high speed instrumentation was used to decorticate the anterior mandible using a 1.6 mm twist drill and a pear shaped bur was used in the posterior region to begin original exploratory phenomenon of repair.\n",
      "Gold: [[123, 131, 'BODY_PART']]\n",
      "Pred: [[4, 11, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Incision was then made over the left lateral aspect of the hind foot to expose the talocalcaneal joint.\n",
      "Gold: [[59, 68, 'BODY_PART'], [83, 102, 'BODY_PART']]\n",
      "Pred: [[59, 68, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: PREOPERATIVE DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.,POSTOPERATIVE\n",
      "Gold: [[37, 64, 'DISEASE'], [80, 91, 'DISEASE'], [92, 96, 'BODY_PART']]\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: The cephalic vein was divided, and the proximal end was anastomosed to the artery in an end-to-side fashion with a running 6-0 Prolene suture.\n",
      "Gold: [[4, 17, 'BODY_PART'], [75, 81, 'BODY_PART'], [127, 134, 'DRUG']]\n",
      "Pred: [[4, 17, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Bilateral long-leg casts were then placed with the foot in neutral with some moulding of his medial plantar arch.\n",
      "Gold: [[51, 55, 'BODY_PART'], [93, 112, 'BODY_PART']]\n",
      "Pred: [[19, 24, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: Severe mandibular atrophy.\n",
      "Gold: [[0, 7, 'SYMPTOM'], [8, 17, 'BODY_PART'], [18, 25, 'SYMPTOM']]\n",
      "Pred: [[7, 25, 'DISEASE']]\n",
      "--------------------------------------------------\n",
      "Text: Hemostasis was obtained.\n",
      "Gold: []\n",
      "Pred: [[0, 10, 'SYMPTOM']]\n",
      "--------------------------------------------------\n",
      "Text: Acquired facial deformity.\n",
      "Gold: [[0, 8, 'SYMPTOM'], [9, 15, 'BODY_PART'], [16, 25, 'SYMPTOM']]\n",
      "Pred: [[9, 25, 'DISEASE']]\n",
      "--------------------------------------------------\n",
      "Text: The block of bone was further re-contoured in situ.\n",
      "Gold: [[13, 17, 'BODY_PART']]\n",
      "Pred: [[4, 9, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: TIME:  ,Tourniquet time was 53 minutes on the left and 45 minutes on the right.\n",
      "Gold: []\n",
      "Pred: [[8, 23, 'SYMPTOM']]\n",
      "--------------------------------------------------\n",
      "Text: A tunnel was formed in the posterior region separating the mental nerve artery and vein from the flap and exposing that aspect of the body of the mandible.\n",
      "Gold: [[59, 71, 'BODY_PART'], [72, 78, 'BODY_PART'], [83, 87, 'BODY_PART'], [146, 154, 'BODY_PART']]\n",
      "Pred: [[2, 8, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The facial tissues were then reflected exposing the lateral aspect of the maxilla, the zygomatic arch, the infraorbital nerve, artery and vein, the lateral piriform rim, the inferior piriform rim, and the remaining issue of the nasal spine.\n",
      "Gold: [[74, 81, 'BODY_PART'], [87, 101, 'BODY_PART'], [107, 125, 'BODY_PART'], [148, 168, 'BODY_PART'], [174, 195, 'BODY_PART'], [228, 239, 'BODY_PART']]\n",
      "Pred: [[74, 81, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Xylocaine 1%, 1:100,000 epinephrine 7 ml was infiltrated into the labial and palatal mucosa.\n",
      "Gold: [[0, 9, 'DRUG'], [24, 35, 'DRUG']]\n",
      "Pred: [[0, 9, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: The IV catheter was inserted into the vein on the lower surface of the left forearm.\n",
      "Gold: [[4, 6, 'ROUTE'], [38, 42, 'BODY_PART'], [76, 83, 'BODY_PART']]\n",
      "Pred: [[4, 6, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: The area was re-contoured with rongeurs.\n",
      "Gold: []\n",
      "Pred: [[31, 39, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.\n",
      "Gold: [[24, 51, 'DISEASE'], [67, 78, 'DISEASE'], [79, 83, 'BODY_PART']]\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "\n",
      "===== Examples of CORRECT predictions =====\n",
      "\n",
      "Text: This was also checked with fluoroscopy.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: Masticatory dysfunction.,POSTOPERATIVE DIAGNOSES:,1.\n",
      "Gold: [[0, 23, 'SYMPTOM']]\n",
      "Pred: [[0, 23, 'SYMPTOM']]\n",
      "--------------------------------------------------\n",
      "Text: ,The clamps were removed establishing flow through the fistula.\n",
      "Gold: [[55, 62, 'DISEASE']]\n",
      "Pred: [[55, 62, 'DISEASE']]\n",
      "--------------------------------------------------\n",
      "Text: ,2.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: Once the foot was reduced a Steinman pin was used to hold it in position.\n",
      "Gold: [[9, 13, 'BODY_PART']]\n",
      "Pred: [[9, 13, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The incision was then extended posteriorly to allow for visualization of the Achilles, which was Z-lengthened with the release of the lateral distal half.\n",
      "Gold: [[77, 85, 'BODY_PART']]\n",
      "Pred: [[77, 85, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: #3-0 Gore-Tex.  Attention was brought then to the mandible.\n",
      "Gold: [[50, 58, 'BODY_PART']]\n",
      "Pred: [[50, 58, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The patient received 6 mL of 0.25% Marcaine local anesthetic on each side.,TOURNIQUET\n",
      "Gold: [[35, 43, 'DRUG']]\n",
      "Pred: [[35, 43, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: ,3.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: Both the extremities were then prepped and draped in standard surgical fashion.\n",
      "Gold: [[9, 20, 'BODY_PART']]\n",
      "Pred: [[9, 20, 'BODY_PART']]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model names avaible: dolly-v2-3b Llama-2-13b-hf mistral-7b\n",
    "!python -m ner.spacy_llm.load_model --model  mistral-7b-ner2\n",
    "!python -m ner.spacy_llm.evaluate --model mistral-7b-ner2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817a8c7",
   "metadata": {},
   "source": [
    "**NER2** <br>\n",
    "Micro Precision: 0.6296 <br>\n",
    "Micro Recall:    0.5862 <br>\n",
    "Micro F1 score:  0.6071 <br>\n",
    "<br>\n",
    "Macro Precision: 0.5816 <br>\n",
    "Macro Recall:    0.4937 <br>\n",
    "Macro F1:        0.4281 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6fae2",
   "metadata": {},
   "source": [
    "### NER3\n",
    "\n",
    "\n",
    "The NER3 template from spacy-llm on top of what NER2 offers it additionally provides CoT (Chain of Thought) in the prompt. <br>\n",
    "\n",
    "The few shot can be found in: <br>\n",
    "    ner/spacy_llm/ner_examples_cot_balanced_1.json\n",
    "\n",
    "Each example has to provide a reason/explanation as to why a label corresponds to an entity.\n",
    "For instance:\n",
    "```json\n",
    "    \"spans\": [\n",
    "      {\n",
    "        \"text\": \"feet\",\n",
    "        \"is_entity\": true,\n",
    "        \"label\": \"BODY_PART\",\n",
    "        \"reason\": \"Refers to a specific anatomical location of the body (the patient's feet).\"\n",
    "      }]     \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0bd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:00<00:00, 105.35it/s]\n",
      "Model saved to /storage/homefs/kw24z021/NLP_LLM/group_project/MedNLP-Multitask/ner/spacy_llm/models/output_mistral-7b_ner\n",
      "Loaded 36 annotated test sentences.\n",
      "Loading model...mistral-7b\n",
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/storage/homefs/kw24z021/miniconda3/envs/nlp-task2/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:00<00:00, 104.55it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Prediction completed in 16.40 seconds for 36 sentences.\n",
      "\n",
      "==== Micro-Averaged Metrics ====\n",
      "Precision: 0.2429\n",
      "Recall:    0.2429\n",
      "F1-score:  0.2429\n",
      "\n",
      "Macro Precision: 0.4889\n",
      "Macro Recall:   0.3388\n",
      "Macro F1:       0.3388\n",
      "\n",
      "===== Examples of WRONG predictions =====\n",
      "\n",
      "Text: A posterior tunnel was done first on the left side along the mylohyoid ridge and then under retromolar pad to the external oblique and the ridge was then degloved.\n",
      "Gold: [[61, 76, 'BODY_PART'], [92, 106, 'BODY_PART'], [114, 130, 'BODY_PART']]\n",
      "Pred: [[41, 50, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Surgical team scrubbed and gowned in usual fashion and the patient was draped.\n",
      "Gold: []\n",
      "Pred: [[0, 13, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Maxillary atrophy.\n",
      "Gold: [[0, 9, 'BODY_PART'], [10, 17, 'SYMPTOM']]\n",
      "Pred: [[0, 9, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Once the bone was harvested, surgical templets were used to recontour initially the maxillary graft and the mandibular graft.\n",
      "Gold: [[9, 13, 'BODY_PART'], [84, 92, 'BODY_PART'], [108, 117, 'BODY_PART']]\n",
      "Pred: [[29, 46, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: The ankle was taken through a range of motion with noted improvement in the reduction of the talocalcaneal alignment with the foot in plantar flexion on the lateral view.\n",
      "Gold: [[4, 9, 'BODY_PART'], [126, 130, 'BODY_PART']]\n",
      "Pred: [[4, 9, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Intended incision was marked on the skin.\n",
      "Gold: []\n",
      "Pred: [[36, 40, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Risks of surgery include risks of anesthesia, infection, bleeding, changes in sensation and motion of the extremity, hardware failure, need for other surgical procedures, need to be nonweightbearing for some time.\n",
      "Gold: [[46, 55, 'SYMPTOM'], [57, 65, 'SYMPTOM'], [105, 115, 'BODY_PART']]\n",
      "Pred: [[34, 44, 'SYMPTOM']]\n",
      "--------------------------------------------------\n",
      "Text: This was explained to the mother in detail.\n",
      "Gold: []\n",
      "Pred: [[26, 32, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The periosteal flap was sutured over the staple using 2-0 Vicryl.\n",
      "Gold: [[4, 19, 'BODY_PART'], [58, 64, 'DRUG']]\n",
      "Pred: [[4, 19, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The tissues were stretched with tissue scissors and then a high speed instrumentation was used to decorticate the anterior mandible using a 1.6 mm twist drill and a pear shaped bur was used in the posterior region to begin original exploratory phenomenon of repair.\n",
      "Gold: [[123, 131, 'BODY_PART']]\n",
      "Pred: [[4, 11, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Once the foot was reduced a Steinman pin was used to hold it in position.\n",
      "Gold: [[9, 13, 'BODY_PART']]\n",
      "Pred: [[28, 40, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: Incision was then made over the left lateral aspect of the hind foot to expose the talocalcaneal joint.\n",
      "Gold: [[59, 68, 'BODY_PART'], [83, 102, 'BODY_PART']]\n",
      "Pred: [[59, 68, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: PREOPERATIVE DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.,POSTOPERATIVE\n",
      "Gold: [[37, 64, 'DISEASE'], [80, 91, 'DISEASE'], [92, 96, 'BODY_PART']]\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: The cephalic vein was divided, and the proximal end was anastomosed to the artery in an end-to-side fashion with a running 6-0 Prolene suture.\n",
      "Gold: [[4, 17, 'BODY_PART'], [75, 81, 'BODY_PART'], [127, 134, 'DRUG']]\n",
      "Pred: [[4, 17, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Bilateral long-leg casts were then placed with the foot in neutral with some moulding of his medial plantar arch.\n",
      "Gold: [[51, 55, 'BODY_PART'], [93, 112, 'BODY_PART']]\n",
      "Pred: [[10, 24, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Severe mandibular atrophy.\n",
      "Gold: [[0, 7, 'SYMPTOM'], [8, 17, 'BODY_PART'], [18, 25, 'SYMPTOM']]\n",
      "Pred: [[7, 17, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Hemostasis was obtained.\n",
      "Gold: []\n",
      "Pred: [[0, 10, 'SYMPTOM']]\n",
      "--------------------------------------------------\n",
      "Text: Acquired facial deformity.\n",
      "Gold: [[0, 8, 'SYMPTOM'], [9, 15, 'BODY_PART'], [16, 25, 'SYMPTOM']]\n",
      "Pred: [[9, 15, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The block of bone was further re-contoured in situ.\n",
      "Gold: [[13, 17, 'BODY_PART']]\n",
      "Pred: [[4, 17, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: TIME:  ,Tourniquet time was 53 minutes on the left and 45 minutes on the right.\n",
      "Gold: []\n",
      "Pred: [[8, 23, 'ROUTE']]\n",
      "--------------------------------------------------\n",
      "Text: A tunnel was formed in the posterior region separating the mental nerve artery and vein from the flap and exposing that aspect of the body of the mandible.\n",
      "Gold: [[59, 71, 'BODY_PART'], [72, 78, 'BODY_PART'], [83, 87, 'BODY_PART'], [146, 154, 'BODY_PART']]\n",
      "Pred: [[27, 36, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The facial tissues were then reflected exposing the lateral aspect of the maxilla, the zygomatic arch, the infraorbital nerve, artery and vein, the lateral piriform rim, the inferior piriform rim, and the remaining issue of the nasal spine.\n",
      "Gold: [[74, 81, 'BODY_PART'], [87, 101, 'BODY_PART'], [107, 125, 'BODY_PART'], [148, 168, 'BODY_PART'], [174, 195, 'BODY_PART'], [228, 239, 'BODY_PART']]\n",
      "Pred: [[74, 81, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: Xylocaine 1%, 1:100,000 epinephrine 7 ml was infiltrated into the labial and palatal mucosa.\n",
      "Gold: [[0, 9, 'DRUG'], [24, 35, 'DRUG']]\n",
      "Pred: [[0, 9, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: The IV catheter was inserted into the vein on the lower surface of the left forearm.\n",
      "Gold: [[4, 6, 'ROUTE'], [38, 42, 'BODY_PART'], [76, 83, 'BODY_PART']]\n",
      "Pred: [[4, 15, 'ROUTE']]\n",
      "--------------------------------------------------\n",
      "Text: DIAGNOSIS: , Congenital myotonic muscular dystrophy with bilateral planovalgus feet.\n",
      "Gold: [[24, 51, 'DISEASE'], [67, 78, 'DISEASE'], [79, 83, 'BODY_PART']]\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "\n",
      "===== Examples of CORRECT predictions =====\n",
      "\n",
      "Text: This was also checked with fluoroscopy.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: Masticatory dysfunction.,POSTOPERATIVE DIAGNOSES:,1.\n",
      "Gold: [[0, 23, 'SYMPTOM']]\n",
      "Pred: [[0, 23, 'SYMPTOM']]\n",
      "--------------------------------------------------\n",
      "Text: ,The clamps were removed establishing flow through the fistula.\n",
      "Gold: [[55, 62, 'DISEASE']]\n",
      "Pred: [[55, 62, 'DISEASE']]\n",
      "--------------------------------------------------\n",
      "Text: The fluid administered 300 cc.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: ,2.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: The incision was then extended posteriorly to allow for visualization of the Achilles, which was Z-lengthened with the release of the lateral distal half.\n",
      "Gold: [[77, 85, 'BODY_PART']]\n",
      "Pred: [[77, 85, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: #3-0 Gore-Tex.  Attention was brought then to the mandible.\n",
      "Gold: [[50, 58, 'BODY_PART']]\n",
      "Pred: [[50, 58, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The patient received 6 mL of 0.25% Marcaine local anesthetic on each side.,TOURNIQUET\n",
      "Gold: [[35, 43, 'DRUG']]\n",
      "Pred: [[35, 43, 'DRUG']]\n",
      "--------------------------------------------------\n",
      "Text: ,3.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n",
      "Text: Both the extremities were then prepped and draped in standard surgical fashion.\n",
      "Gold: [[9, 20, 'BODY_PART']]\n",
      "Pred: [[9, 20, 'BODY_PART']]\n",
      "--------------------------------------------------\n",
      "Text: The area was re-contoured with rongeurs.\n",
      "Gold: []\n",
      "Pred: []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model names avaible: dolly-v2-3b Llama-2-13b-hf mistral-7b \n",
    "!python -m ner.spacy_llm.load_model --model  mistral-7b\n",
    "!python -m ner.spacy_llm.evaluate --model mistral-7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bbddc",
   "metadata": {},
   "source": [
    "**NER3** <br>\n",
    "Micro Precision: 0.5667 <br>\n",
    "Micro Recall:    0.2931 <br>\n",
    "Micro F1 score:  0.3864 <br>\n",
    "<br>\n",
    "Macro Precision: 0.4065 <br>\n",
    "Macro Recall:    0.4066 <br>\n",
    "Macro F1:        0.4066 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1b041",
   "metadata": {},
   "source": [
    "\n",
    "### Summary\n",
    "- The comparison between minimal raw prompting and spaCy-LLM confirms the importance of architectural constraints and structured prompt design for LLM-based NER.\n",
    "\n",
    "When evaluated on the same test dataset, spacy-LLM (NER2) achieved a better overall performance:\n",
    "\n",
    "Micro F1 = 0.6071 \n",
    "Macro F1 = 0.4281\n",
    "\n",
    "Although performance is still modest, these results are significantly better than the minimal n-shot prompt baseline. This demonstrates that structured prompting, template enforcement, and standardized output parsing reduce hallucinations and improve entity extraction reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367f6d8",
   "metadata": {},
   "source": [
    "## 6. How NER type information can help other NLP tasks\n",
    "\n",
    "Even if the NER models in this project are not perfect, the extracted entity types are still useful for many other NLP applications in the clinical domain. Here I briefly summarise a few examples.\n",
    "\n",
    "1. **Structuring free-text clinical notes**  \n",
    "\tClinical documents are mostly free text. NER can identify key concepts and turn them into structured fields, for example:\n",
    "\t- DISEASE: diabetes mellitus, hypertension, stasis ulcer  \n",
    "\t- SYMPTOM: chest pain, nausea, diarrhea  \n",
    "\t- BODY_PART: right ankle, abdomen  \n",
    "\t- PROCEDURE: surgery, CT scan  \n",
    "\tThis structured information can then be stored in an electronic health record or database and used for search, filtering, and statistics.\n",
    "\n",
    "2. **Clinical decision support**  \n",
    "\tNER outputs can be used as features in decision support systems. For example:\n",
    "\t- Combinations of DISEASE and SYMPTOM entities can be used to estimate the risk of certain conditions.\n",
    "\t- DRUG and DOSAGE entities can be checked for possible drug interactions or dosing errors.\n",
    "\tIn this way, NER acts as a bridge between narrative notes and automated clinical rules or prediction models.\n",
    "\n",
    "3. **Document and patient-level classification**  \n",
    "\tNER types can also improve text classification. Instead of using only bag-of-words, we can use counts and patterns of entities:\n",
    "\t- Classifying documents by specialty (e.g. cardiology vs. endocrinology) based on the diseases and body parts mentioned.\n",
    "\t- Detecting potential adverse drug events by looking for co-occurrences of specific DRUG and SYMPTOM entities.\n",
    "\tAt the patient level, the presence or absence of certain DISEASE entities can be used to define cohorts for research.\n",
    "\n",
    "4. **Relation extraction and knowledge graphs**  \n",
    "\tNER is the first step towards relation extraction, such as:\n",
    "\t- SYMPTOMDISEASE relations (e.g. chest pain  myocardial infarction ruled out)\n",
    "\t- DRUGDISEASE relations (indications)  \n",
    "\t- DRUGSYMPTOM relations (adverse effects)  \n",
    "\tOnce entities are identified, these relations can be learned or manually defined, and combined into a clinical knowledge graph.\n",
    "\n",
    "5. **Question answering and summarisation**  \n",
    "\tFor question answering, knowing which spans are DISEASE or SYMPTOM helps focus retrieval on the relevant parts of a document. For summarisation, NER can be used to ensure that all important entities (diagnoses, symptoms, procedures, medications) appear explicitly in the final summary, even if the original note is long and repetitive.\n",
    "\n",
    "Overall, NER type information turns unstructured clinical text into more interpretable and reusable signals. Even a relatively noisy NER system can already provide useful features for downstream tasks such as decision support, classification, relation extraction, and summarisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384ec1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbbef8af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
