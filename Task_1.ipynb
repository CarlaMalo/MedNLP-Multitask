{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2340435",
   "metadata": {},
   "source": [
    "# Task 1: Data Exploration and Processing\n",
    "\n",
    "Explore your specific dataset by calculating basic statistics number of samples and number of samples per class: is your dataset balanced? min / avg / max length of text reading through 100+ samples: noteworthy style, vocabulary, idioms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e23757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Available splits: ['train']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "def load_medical_domain_dataset():\n",
    "    \"\"\"\n",
    "    Load the medical domain dataset from Hugging Face\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        dataset = load_dataset(\"argilla/medical-domain\")\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(f\"Available splits: {list(dataset.keys())}\")\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "    \n",
    "dataset = load_medical_domain_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of samples: 4966\n",
      "  Features: ['text', 'inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'id', 'metadata', 'status', 'event_timestamp', 'metrics']\n",
      " Text length:\n",
      "     Min: 11, Avg: 3052.314337494966, Max: 18425\n",
      "\n",
      "Analyzing class distribution:\n",
      "\n",
      "Class distribution:\n",
      "   Gastroenterology: 224 samples (4.51%)\n",
      "   Surgery: 1088 samples (21.91%)\n",
      "   Radiology: 273 samples (5.50%)\n",
      "   SOAP / Chart / Progress Notes: 166 samples (3.34%)\n",
      "   Letters: 23 samples (0.46%)\n",
      "   Lab Medicine - Pathology: 8 samples (0.16%)\n",
      "   Consult - History and Phy.: 516 samples (10.39%)\n",
      "   Podiatry: 47 samples (0.95%)\n",
      "   General Medicine: 259 samples (5.22%)\n",
      "   Psychiatry / Psychology: 53 samples (1.07%)\n",
      "   Cardiovascular / Pulmonary: 371 samples (7.47%)\n",
      "   Urology: 156 samples (3.14%)\n",
      "   Ophthalmology: 83 samples (1.67%)\n",
      "   Physical Medicine - Rehab: 21 samples (0.42%)\n",
      "   Neurology: 223 samples (4.49%)\n",
      "   Autopsy: 8 samples (0.16%)\n",
      "   Orthopedic: 355 samples (7.15%)\n",
      "   Hematology - Oncology: 90 samples (1.81%)\n",
      "   Allergy / Immunology: 7 samples (0.14%)\n",
      "   Pediatrics - Neonatal: 70 samples (1.41%)\n",
      "   Dentistry: 27 samples (0.54%)\n",
      "   Neurosurgery: 94 samples (1.89%)\n",
      "   Pain Management: 61 samples (1.23%)\n",
      "   Nephrology: 81 samples (1.63%)\n",
      "   Emergency Room Reports: 75 samples (1.51%)\n",
      "   Obstetrics / Gynecology: 155 samples (3.12%)\n",
      "   Speech - Language: 9 samples (0.18%)\n",
      "   Diets and Nutritions: 10 samples (0.20%)\n",
      "   Endocrinology: 19 samples (0.38%)\n",
      "   IME-QME-Work Comp etc.: 16 samples (0.32%)\n",
      "   Cosmetic / Plastic Surgery: 27 samples (0.54%)\n",
      "   Discharge Summary: 108 samples (2.17%)\n",
      "   ENT - Otolaryngology: 96 samples (1.93%)\n",
      "   Chiropractic: 14 samples (0.28%)\n",
      "   Office Notes: 50 samples (1.01%)\n",
      "   Dermatology: 29 samples (0.58%)\n",
      "   Sleep Medicine: 20 samples (0.40%)\n",
      "   Rheumatology: 10 samples (0.20%)\n",
      "   Hospice - Palliative Care: 6 samples (0.12%)\n",
      "   Bariatrics: 18 samples (0.36%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_statistics(dataset):\n",
    "    \"\"\"\n",
    "    Analyze the length of text and distribution of samples across different classes in the dataset\n",
    "    \"\"\"\n",
    "    for split_name, split_data in dataset.items():\n",
    "        \n",
    "        # Display number of samples\n",
    "        print(f\"\\nNumber of samples: {len(split_data)}\")\n",
    "        print(f\"  Features: {list(split_data.features.keys())}\")\n",
    "        #print(f\"  First sample: {split_data[1]}\")\n",
    "        if len(split_data) > 0:\n",
    "            # Calculate Min, Avg, Max length of text\n",
    "            text_lengths = [len(sample['text']) for sample in split_data if 'text' in sample]\n",
    "            if text_lengths:\n",
    "                min_length = min(text_lengths)\n",
    "                avg_length = sum(text_lengths) / len(text_lengths)\n",
    "                max_length = max(text_lengths)\n",
    "                print(f\" Text length:\\n     Min: {min_length}, Avg: {avg_length:.2f}, Max: {max_length}\")\n",
    "        \n",
    "        print(\"\\nAnalyzing class distribution:\")\n",
    "        # Count samples per class\n",
    "        class_counts = {}\n",
    "        total_samples = len(split_data)\n",
    "        \n",
    "        for sample in split_data:\n",
    "            if 'prediction' in sample and isinstance(sample['prediction'], list):\n",
    "                for label in sample['prediction']:\n",
    "                    if 'label' in label:\n",
    "                        prediction = label['label']\n",
    "                        class_counts[prediction] = class_counts.get(prediction, 0) + 1\n",
    "        \n",
    "        # Display results\n",
    "        if class_counts:\n",
    "            print(\"\\nClass distribution:\")\n",
    "            for class_name, count in class_counts.items():\n",
    "                percentage = (count / total_samples) * 100\n",
    "                print(f\"  {class_name}: {count} samples ({percentage:.2f}%)\")\n",
    "        else:\n",
    "            print(\"No prediction labels found in this split\")\n",
    "\n",
    "if dataset:\n",
    "    analyze_dataset_statistics(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f47769",
   "metadata": {},
   "source": [
    "Establish a structured and flexible (configurable) processing pipeline with steps for reading documents from file tokenizing normalizing (lowercase, lemmatize/stem, …) filtering (stop words, …)\n",
    "Use the script clustering.py as a template for clustering your text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ac331",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
